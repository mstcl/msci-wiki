[
  {
    "objectID": "literature_notes/run-and-tumble.html",
    "href": "literature_notes/run-and-tumble.html",
    "title": "Run-and-tumble dynamics in a crowded environment: PEP for swimmers",
    "section": "",
    "text": "The model is asynchronous and stochastic.\nParticles in the run phase characterised by direction:\n\n(left,right) in 1D\n(left,right,up,down) in 2D\n\nA total number of particles M=œïNM = \\phi N where œï\\phi is the particle concentration and NN is the total number of sites.\nEach particle moves in a random direction, with probability Œ±\\alpha to undergo tumbling.\nIf the neighbouring site that it‚Äôs pointing towards (the value of the director) is not fully occupied, it moves into this new position.\nAt each step, particles can be chosen more than once, and MM particles are chosen on average.\nNon-equilibrium feature (in the limit of infinite dilution): each particle stays in run mode for periods of time that are geometrically distributed with an average of Œ±‚àí1\\alpha^{-1}, then undergoes a tumble.\nJamming happens when two particles moving on the same track but in opposite directions. This creates a cluster seed.\nEffects at Œ±=0\\alpha = 0\n\nAll particles become jammed.\nParticles cluster together until there are no more isolated particles.\n\nEffects at Œ±‚â†0\\alpha \\neq 0\n\nThe system forms clusters that coexist.\nThe clusters stay immobile, so there is no merging or splitting.\nThere is now cluster dynamics with the following processes:\n\nFormation of cluster by two particle colliding\nAbsorption of moving particles at cluster boundaries\nParticle evaporation at the boundaries"
  },
  {
    "objectID": "literature_notes/run-and-tumble.html#the-model",
    "href": "literature_notes/run-and-tumble.html#the-model",
    "title": "Run-and-tumble dynamics in a crowded environment: PEP for swimmers",
    "section": "",
    "text": "The model is asynchronous and stochastic.\nParticles in the run phase characterised by direction:\n\n(left,right) in 1D\n(left,right,up,down) in 2D\n\nA total number of particles M=œïNM = \\phi N where œï\\phi is the particle concentration and NN is the total number of sites.\nEach particle moves in a random direction, with probability Œ±\\alpha to undergo tumbling.\nIf the neighbouring site that it‚Äôs pointing towards (the value of the director) is not fully occupied, it moves into this new position.\nAt each step, particles can be chosen more than once, and MM particles are chosen on average.\nNon-equilibrium feature (in the limit of infinite dilution): each particle stays in run mode for periods of time that are geometrically distributed with an average of Œ±‚àí1\\alpha^{-1}, then undergoes a tumble.\nJamming happens when two particles moving on the same track but in opposite directions. This creates a cluster seed.\nEffects at Œ±=0\\alpha = 0\n\nAll particles become jammed.\nParticles cluster together until there are no more isolated particles.\n\nEffects at Œ±‚â†0\\alpha \\neq 0\n\nThe system forms clusters that coexist.\nThe clusters stay immobile, so there is no merging or splitting.\nThere is now cluster dynamics with the following processes:\n\nFormation of cluster by two particle colliding\nAbsorption of moving particles at cluster boundaries\nParticle evaporation at the boundaries"
  },
  {
    "objectID": "literature_notes/active-brownian-particles.html",
    "href": "literature_notes/active-brownian-particles.html",
    "title": "Active Brownian particles: from collective phenomona to fundamental physics",
    "section": "",
    "text": "Janus particles\nActive Brownian particles (ABPs)\nColloidal particles\nWhat‚Äôs common to both propulsion mechanisms is that they are break detailed balance (irreversible?) by receiving an input of free energy that eventually gets dissipated into the environment."
  },
  {
    "objectID": "literature_notes/active-brownian-particles.html#concepts",
    "href": "literature_notes/active-brownian-particles.html#concepts",
    "title": "Active Brownian particles: from collective phenomona to fundamental physics",
    "section": "",
    "text": "Janus particles\nActive Brownian particles (ABPs)\nColloidal particles\nWhat‚Äôs common to both propulsion mechanisms is that they are break detailed balance (irreversible?) by receiving an input of free energy that eventually gets dissipated into the environment."
  },
  {
    "objectID": "literature_notes/active-brownian-particles.html#mips",
    "href": "literature_notes/active-brownian-particles.html#mips",
    "title": "Active Brownian particles: from collective phenomona to fundamental physics",
    "section": "MIPS",
    "text": "MIPS\n\nMotility-induced phase separation\nSelf-propelled particles aggregate into clusters even in the absence of cohensive forces.\n\nThe mechanism is dynamic feedback between speed and density\n\nExploiting the directed motion of synthetic active particles to convert chemical free energy (released by hydrogen peroxide) into mechanical work."
  },
  {
    "objectID": "misc.html",
    "href": "misc.html",
    "title": "Misc",
    "section": "",
    "text": "Run-and-tumble dynamics in a crowded environment: PEP for swimmers\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2023\n\n\nSoto, Golestanian\n\n\n\n\n\n\n\n\n\n\n\n\nActive Brownian particles: from collective phenomona to fundamental physics\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2023\n\n\nGompper, Winkler\n\n\n\n\n\n\n\n\n\n\n\n\n2020 Motile Active Matter Introduction\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2023\n\n\nGompper, Winkler\n\n\n\n\n\n\n\n\n\n\n\n\nCluster information\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLink to colab notebook\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMinimal cluster analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeadline information\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUseful Commands and Information for Shared Github Activity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepository information\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "writing/landing.html",
    "href": "writing/landing.html",
    "title": "Writing",
    "section": "",
    "text": "What is active matter and why do we study it?\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2024\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nPrepratory work, discussion, and plan for the future\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2024\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nInterim report: Dissipation Learning in Active Matter\n\n\n\n\n\nActive matter forms a class of systems with self-propelled units that departs from reversible and equilibrium physics. To capture essential aspects of such systems, models are deployed to make connections between various characterisation such as structure and activity. Here, one of our aims is to produce predictions of the driving forces of the system with only static configurations. For this we use a lattice-based, run-and-tumble, implementation of PEP as the model and a convolutional neural network as the tool for learning dissipation from static snapshots. So far, we have a model working with some properties measured: cluster quantity and size distribution, which corresponds well to a previous work from other authors. From this, we discuss ways in which we can move forward with our plan. This report aims to produce a brief literature review of the field in terms of the modelling of active matter, in addition to a discussion of the work we have accomplished so far. \n\n\n\n\n\nNP\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "writing/interim.html",
    "href": "writing/interim.html",
    "title": "Interim report: Dissipation Learning in Active Matter",
    "section": "",
    "text": "An active matter system is characterised by its constituents undergoing active motion, which is caused by some internal self-propelling and self-directional mechanisms. The special characteristic of active motion is the capability to extract and dissipate energy, with dissipation being the breaking of detailed balance that gives rise to irreversibility and non-equilibrium¬†¬†[cates_active_2019?]. The cause of these mechanisms can range from natural (biological or catalytic), to synthetic (with micro-engines like nanorobots)¬†¬†[romanczuk_active_2012?], and the results of which are complex, behaviours¬†¬†[1]. Numerous examples of active systems can be found in biological systems at all scales, from school of fish¬†¬†[2] and birds in a flock, to algae, bacteria, proteins¬†¬†[3] and actin and microtubules in subcellular domains¬†¬†[1]. The general and intriguing features of active systems are typically large-scale emergent collective phenomena, such as clustering, synchronous dynamics¬†¬†[3], order-disorder transitions¬†¬†[4], pattern formation¬†¬†[romanczuk_active_2012?], swarming, and lots more.\nNon-equilibrium regimes are ubiquitous in the biological world, yet they are not fully understood in physical theories. Non-equilibrium emerges when energy exchanges and dissipation at the level of individual particles‚Äô contribution lead to irreversibility within¬†¬†[5,6]. This is contrasted with equilibrium systems, where energy effects are found at the system‚Äôs boundaries¬†¬†[1]. Whereas we use the laws of thermodynamics and statistical mechanics to describe reversible, equilibrium systems, where there we have obvious definitions of thermodynamic potentials (e.g.‚ÄÜfree energy) and statistical likelihood (e.g.‚ÄÜthe Boltzmann distribution), it is not clear for systems that depart from time-reversal symmetries. The difficulty lies in constructing analogues to these theories using quantities equivalent free energies. With new theoretical analogues, we can gain better understanding of this regime.\nIn addition to the bottom-up study of non-equilibrium behaviours, one challenge is to address the inverse problem; to determine the structural rules that lead to a desired collective state¬†¬†[7]. In this domain, powerful tools like machine learning can be deployed to connect activity with structure (expanded in Section¬†3). With the ability to control and quantify both, we might be able to build a robust framework analogous to equilibrium statistical thermodynamics, but one which ultimately can provide fundamental (or at least more generalised) insight into microscopic-emergent connections¬†¬†[8]. The possibility and robustness of such a generalisation of dynamical features is already hinted at by the vast and continuously increasing body of publications around these systems, despite the heterogeneous nature of individual units, from subcellular motors to desert locusts¬†¬†[romanczuk_active_2012?].\nWhat‚Äôs more, concepts of the field are very transferable to practical applications, where we might want to borrow or mimic strategies from biological systems, with the goal of creating new synthetic materials, devices, robotics and medicine¬†¬†[5], as well as experimental techniques, such as automated digital tracking¬†¬†[romanczuk_active_2012?]. Here, models of active matter is an integral tool to provide insight and predictions. For this, the models are performed both in vitro (nanomachines) and in silico (numerical modelling). An brief overview of the latter can be found in Section¬†2. Real-world active and living systems have high complexity; they are controlled by numerous parameters and exhibit many features and behaviours at different scales¬†¬†[1,9]. Through modelling, we can seek to capture essential aspect and general trends that are independent of the scale of its constituents, and to connect with the broader framework of nonequilibrium thermodynamics.\nFor instance, a good minimal approximation would be a model by Viscek et. al.¬†¬†[4,10]. Here, clustering is induced through a combination of self-propulsion and self-orientation in response to its neighbours. The system evolves with a two-step iteration process, and the whole system is controlled by 3 parameters. Yet, its central prediction shows phase transition from disordered, individual motion to ordered, collective motion, dictated through its minimal set of parameters¬†¬†[4].\nWhile it cannot be assumed that the models used in vitro translate directly to what is observed in reality, they are still crucial components that when combined with more sophisticated rules or understanding from other fields, would enable useful real-world applications, an example being controlling insect pest outbreaks¬†¬†[4]."
  },
  {
    "objectID": "writing/interim.html#sec:intro",
    "href": "writing/interim.html#sec:intro",
    "title": "Interim report: Dissipation Learning in Active Matter",
    "section": "",
    "text": "An active matter system is characterised by its constituents undergoing active motion, which is caused by some internal self-propelling and self-directional mechanisms. The special characteristic of active motion is the capability to extract and dissipate energy, with dissipation being the breaking of detailed balance that gives rise to irreversibility and non-equilibrium¬†¬†[cates_active_2019?]. The cause of these mechanisms can range from natural (biological or catalytic), to synthetic (with micro-engines like nanorobots)¬†¬†[romanczuk_active_2012?], and the results of which are complex, behaviours¬†¬†[1]. Numerous examples of active systems can be found in biological systems at all scales, from school of fish¬†¬†[2] and birds in a flock, to algae, bacteria, proteins¬†¬†[3] and actin and microtubules in subcellular domains¬†¬†[1]. The general and intriguing features of active systems are typically large-scale emergent collective phenomena, such as clustering, synchronous dynamics¬†¬†[3], order-disorder transitions¬†¬†[4], pattern formation¬†¬†[romanczuk_active_2012?], swarming, and lots more.\nNon-equilibrium regimes are ubiquitous in the biological world, yet they are not fully understood in physical theories. Non-equilibrium emerges when energy exchanges and dissipation at the level of individual particles‚Äô contribution lead to irreversibility within¬†¬†[5,6]. This is contrasted with equilibrium systems, where energy effects are found at the system‚Äôs boundaries¬†¬†[1]. Whereas we use the laws of thermodynamics and statistical mechanics to describe reversible, equilibrium systems, where there we have obvious definitions of thermodynamic potentials (e.g.‚ÄÜfree energy) and statistical likelihood (e.g.‚ÄÜthe Boltzmann distribution), it is not clear for systems that depart from time-reversal symmetries. The difficulty lies in constructing analogues to these theories using quantities equivalent free energies. With new theoretical analogues, we can gain better understanding of this regime.\nIn addition to the bottom-up study of non-equilibrium behaviours, one challenge is to address the inverse problem; to determine the structural rules that lead to a desired collective state¬†¬†[7]. In this domain, powerful tools like machine learning can be deployed to connect activity with structure (expanded in Section¬†3). With the ability to control and quantify both, we might be able to build a robust framework analogous to equilibrium statistical thermodynamics, but one which ultimately can provide fundamental (or at least more generalised) insight into microscopic-emergent connections¬†¬†[8]. The possibility and robustness of such a generalisation of dynamical features is already hinted at by the vast and continuously increasing body of publications around these systems, despite the heterogeneous nature of individual units, from subcellular motors to desert locusts¬†¬†[romanczuk_active_2012?].\nWhat‚Äôs more, concepts of the field are very transferable to practical applications, where we might want to borrow or mimic strategies from biological systems, with the goal of creating new synthetic materials, devices, robotics and medicine¬†¬†[5], as well as experimental techniques, such as automated digital tracking¬†¬†[romanczuk_active_2012?]. Here, models of active matter is an integral tool to provide insight and predictions. For this, the models are performed both in vitro (nanomachines) and in silico (numerical modelling). An brief overview of the latter can be found in Section¬†2. Real-world active and living systems have high complexity; they are controlled by numerous parameters and exhibit many features and behaviours at different scales¬†¬†[1,9]. Through modelling, we can seek to capture essential aspect and general trends that are independent of the scale of its constituents, and to connect with the broader framework of nonequilibrium thermodynamics.\nFor instance, a good minimal approximation would be a model by Viscek et. al.¬†¬†[4,10]. Here, clustering is induced through a combination of self-propulsion and self-orientation in response to its neighbours. The system evolves with a two-step iteration process, and the whole system is controlled by 3 parameters. Yet, its central prediction shows phase transition from disordered, individual motion to ordered, collective motion, dictated through its minimal set of parameters¬†¬†[4].\nWhile it cannot be assumed that the models used in vitro translate directly to what is observed in reality, they are still crucial components that when combined with more sophisticated rules or understanding from other fields, would enable useful real-world applications, an example being controlling insect pest outbreaks¬†¬†[4]."
  },
  {
    "objectID": "writing/interim.html#sec:method_models",
    "href": "writing/interim.html#sec:method_models",
    "title": "Interim report: Dissipation Learning in Active Matter",
    "section": "Methodology and concepts in the modelling of active matter",
    "text": "Methodology and concepts in the modelling of active matter\nActive matter models can be classified into either ‚Äúdry‚Äù or ‚Äúwet‚Äù models ¬†¬†[1]; dry models deal with the particles exclusively (limited to its equations of motion), whereas wet models consider the particles with the addition of a solvent. While the use of dry models is to model real ‚Äúdry‚Äù systems, they can be used as minimal systems where the solvent is only treated as a thermal bath (the cause of random fluctuations)¬†¬†[hecht_introduction_2021?]. Here, the presence of random fluctuations amongst individual units is central to the modelling of these systems. These stochastic processes can be realized with many different mechanisms; the specific implementation being the nature of the noise and how it is accompanied by driving forces¬†¬†[romanczuk_active_2012?]. This introduces the concept of active Brownian particles (ABP), which forms a class of systems that behave like Brownian particles (passive stochastic collisions, i.e.‚ÄÜthe thermal bath, which are typically passive colloids orders of magnitude smaller than the particles of the system¬†¬†[hecht_introduction_2021?]), but instead generalised to non-equilibrium regimes. In other words, these particles (normally modelled as spheres, but also as rods¬†¬†[peruani_nonequilibrium_2006?]) undergo repulsive self-propelled motion with overdamped dissipative dynamics¬†¬†[marchetti_minimal_2016?], where dissipation dominates over inertial effects¬†¬†[hecht_introduction_2021?,haunggi_colored_2007?].\nIn simple ABP models, the system can be controlled by two parameters, density œï\\phi, and the ratio of persistence length l0l_0 to particle size œÉ\\sigma¬†¬†[11]. Overall, ABP has been quantitatively found to deviate from mere passive systems at individual-level dynamics (e.g., diffusion) in their stationary velocity and speed distributions¬†¬†[romanczuk_brownian_2011?] as well as by exhibiting at collective-level a phenomenon called motility-induced phase separation (MIPS)¬†¬†[hecht_introduction_2021?], which resembles liquid-gas phase transitions in equilibrium systems. There is distinctive phase transition for liquid-gas at low activity as well as an ordered transition to crystallization at increasing activity and densely packed regimes¬†¬†[11,12].\nIn addition to ABP, there is a variety of alternatives: there is the run-and-tumble (RTP) model, which rationalises the behaviour of certain bacteria like E. coli¬†¬†[13,hecht_introduction_2021?,thompson_lattice_2011?], where MIPS has also been observed¬†¬†[cates_when_2013?]. At coarse-grained scales and single-particle scale, RTP and ABP models show strict equivalence in some cases, with overall minor differences¬†¬†[cates_when_2013?]. Another model, the active Ornstein-Uhlenbeck particle (AOUP) model, uses stochastic differential equations for fluctuations. Here, self-propulsion is specifically, generated by coloured Gaussian noise (time-correlated noise with a well-defined characteristic time at the scale of the system itself¬†¬†[haunggi_colored_2007?]). At large scales, MIPS is observed¬†¬†[fodor_how_2016?], but the model diverges significantly at single-particle level when compared to ABP and RTP¬†¬†[hecht_introduction_2021?].\nBesides particle-based models, there exist numerous field-based, or continuum theories, which are constructed using PDEs for parameter fields that are stochastic and active by removing them from field-based constraints of time-reversal symmetry (constraints involving the existence of free energy, the Botlzmann distribution, steady states, etc.¬†¬†[cates_active_2019?]). Overall, a continuum theory can be constructed bottom-up by coarse-graining microscopic details, or top-down by imposing symmetry and conservation laws on the equations, with noise added. While these are mostly general models in the sense they do not require specific mechanisms, continuum theories can generate phenomenological models for specific cases, such as in bacterial turbulence. Otherwise, they are deployed to also explicitly account for hydrodynamical (or ‚Äúwet‚Äù) interactions at low density¬†¬†[hecht_introduction_2021?].\nWhile off-lattice (continuous) models provide an edge when the studies concerned are phenomenological, such as the run-and-tumble strategies of E. coli and other bacteria. However, for more fundamental studies of general non-equilibrium physics, lattice models are appropriate tools, as they are computationally cheaper, and easier to extend to higher dimensions¬†¬†[thompson_lattice_2011?] when compared to off-lattice models, which are not as efficient when particle interactions are involved. For lattice models, implemented with discrete timesteps, interactions concerning hopping from site to site can be characterised in a number of different ways. One very simple way is to implement a zero-range interaction, or process (ZRP), where the rate of a given particle to hop from its departure site to one of its direct-neighbours is a function of the total number of particles at the departure site. There is no dependence on the arrival site¬†¬†[thompson_lattice_2011?].\nThis is contrasted with exclusion processes, where the rate of hopping depends on the occupation of the arrival site, where occupation is defined as having a certain maximum number of particles. If the destination is occupied, the particle remains at its departure site until it either orients away or the arrival site becomes free¬†¬†[thompson_lattice_2011?,zhang_persistent_2019?]. In our work, we consider an exclusion process.\n\n An overview on persistent exclusion process\nThe persistent exclusion process (PEP) model is lattice-based with run-and-tumble dynamics (see Section¬†2), where persistent motion (the inverse of the tumbling rate, Œ±\\alpha, for a particle to ‚Äútumble‚Äù, i.e.¬†randomise its direction) characterises non-equilibrium behaviour¬†¬†[13,thompson_lattice_2011?]. In such model, its robustness is controlled by the lattice size, as well as Œ±\\alpha. In our version of PEP (as well as in¬†¬†[13,14]), the lattice is a two-dimensional realization with size Lx√óLyL_x\\times L_y, measured in lattice sizes. Naturally, this gives total number of particles N=œïLxLyN = \\phi L_x L_y. In our work, the density œï\\phi is tweaked instead of the lattice sizes as the image size will need to be controlled during the machine learning process. For each particle, an orientation ùê¨\\mathbf{s} dictates the direction to which it points. In each iteration (time evolves in a discrete manner), each particle either remains in its ‚Äòrun‚Äô state, and moves to the neighbour it points at if the site is vacant, or in the case where it undergoes a tumble, it changes its orientation to a new ùê¨‚Ä≤\\mathbf{s}\\prime, which is drawn at random and independent of the original value¬†¬†[14]. To impose particle exclusion (or excluded volume), each lattice site has maximum occupancy, and thus aggregation, or clustering, is seen to happen when two particles ‚Äújam‚Äù (collide head-first) in the single- occupancy case. When jammed, particles create a cluster seed. Besides cluster formation, there are various significant cluster dynamics to note (in non-equilibrium conditions, i.e.‚ÄÜ when Œ±‚â†1\\alpha \\neq 1): absorption of particles at cluster boundaries, where particles get stopped by existing clusters, and evaporation of particles at cluster boundaries, where particles tumble to point away from clusters and leave.\nThere are three timescales to consider for a PEP model: first, the ‚Äòupdate time‚Äô, or the time it takes for a particle to cross a site œÑ\\tau. Second, the mean ‚Äòflight time‚Äô¬†¬†[14], which is the mean time spent in the run state, and finally, with tumbling introduced, a timescale of Œ±‚àí1\\alpha^{-1} is introduced, or persistence, which we control directly, and ought to be compared to the first two. Tumbling duration is assumed to be instantaneous in this model."
  },
  {
    "objectID": "writing/interim.html#sec:plan",
    "href": "writing/interim.html#sec:plan",
    "title": "Interim report: Dissipation Learning in Active Matter",
    "section": "Progress, discussion, and plans",
    "text": "Progress, discussion, and plans\nOver the initial 7 weeks of the project, we have worked through the in-house code package¬†¬†[15] (referred to as the PEP code here onwards), annotating and documenting what it does step by step. The code is a Python implementation (with ctypes) of the PEP process (see Section¬†[sec:pep]). In short, it is a stochastic, lattice implementation where every particle has 4 isotropic degrees of freedom (up, down, left, right), similar to what is described in¬†¬†[13]. The PEP code was validated and tested at a range of values for each of Œ±\\alpha and œï\\phi. Specifically, Œ±\\alpha was chosen to be within the range 2n,n‚àà[‚àí6..‚àí1]2^{n},\\, n\n\\in [-6 \\mathrel{{.}\\,{.}} -1], and œï\\phi was chosen to be within the range 0.05m,m‚àà[1..10]0.05 m,\\, m \\in [1 \\mathrel{{.}\\,{.}} 10]. At each step, all particles are updated in random order, where each particle attempts to move to their destination, and then has a chance of tumbling. Cluster formation was seen to occur, as seen in Fig.¬†1; here it is clear that after 20 timesteps, the system evolved from homogeneity to small groups of cluster, and after 200 timesteps, a percolation transition can be seen to have taken place. Clusters are smaller and more spread out at œÑ=0\\tau=0, compared to œÑ=200\\tau=200, where clusters are much bigger and form networks. Here, steady-state is observed, with constant evaporation happening at cluster borders, but also constant clusters formation that maintain the overall percolation appearance.\n\n\n\nGreyscale panels show system evolution at three distinct timesteps: œÑ‚àà{0,20,200}\\tau \\in \\{0, 20, 200\\}, starting from top to bottom. Different shades of grey represent particle orientation. The coloured panels show labelled clusters, using scipy.ndimage(), for œÑ=0\\tau=0 (top) and œÑ=200\\tau=200 (bottom). Particle connections are established for neighbours in the up, down, left, right directions. For this system, Œ±=0.023\\alpha=0.023, and œï=0.45\\phi=0.45.\n\n\nTwo quantities have been measured: the cluster size distributions, and the number of cluster, all at different values of (œï,Œ±)(\\phi, \\alpha). Cluster size distributions, as seen in Fig.‚ÄÜ[fig:csize_avg] seem to mirror the appearance in¬†¬†[13] (fitting ought to be performed to validate the results seen in the aforementioned work). Nonetheless, the cluster sizes do seem to correspond well to the expected behaviour: larger clusters are observed only at higher densities, with the largest sizes exclusive to systems that display percolation transition (as seen in the top and middle right panel). The middle column (œï=0.25\\phi=0.25) displays the clearest effects of Œ±\\alpha on cluster formation. Higher Œ±\\alpha corresponds to more frequent tumbles (and lower persistence times), and thus interaction looks closer to the equilibrium case of passive Brownian particles, where local densities are more homogeneous (in fact, the equilibrium limit is Œ±=0\\alpha=0). Below certain thresholds of (œï,Œ±)(\\phi, \\alpha), particle concentration is sufficiently low to not display any steady-state at all. These thresholds ought to be determined, and restrict our systems to values above such thresholds.\n\n\n\n\nimage\n\n\n\nFor this, we can look at the number of clusters, as seen in Fig.¬†2, where the behaviour also appears to match the expectations. The number of clusters increases as Œ±\\alpha increases, with the exception of the lowest density, œï=0.05\\phi=0.05, where it looks almost uniform (more data would be needed to confirm). This is expected as at such low concentrations, increasing tumbling might increase the rate at which clusters form, but clusters don‚Äôt necessarily absorb more as there are so few particles around, thus clusters are likely to be more ephemeral as the centre of the clusters are not trapped by its boundaries, so can freely move away. What is also expected is that a higher œï\\phi would give more clusters, but above a certain threshold of œï\\phi, tight packing and percolation starts happening and clusters become big and fewer in number. This is seen when contrasting between œï=0.25\\phi=0.25 and œï=0.45\\phi=0.45. Overall, more data ought to improve this characterisation; we expect to find a threshold œï\\phi for which the number of clusters start to decrease, and the range of Œ±\\alpha for which this is seen.\n\n\n\nThe number of distinct clusters identified (where distinction is made separated by having neighbours not directly up, down, left, or right) as tumbling rate Œ±\\alpha increases. Each solid line represents a different density, with three values, œï={0.05,0.25,0.45}\\phi = \\{0.05, 0.25, 0.45\\} shown here. Here, the number of clusters is averaged over 1000 iterations for each data point (represented as symbols), with the distance between successive iteration scaled with Œ±‚àí1\\alpha^{-1}.\n\n\nWe have identified other characterisations to potentially implement (as additional asides to investigate): particle orientation and cluster seed formation (head-on collisions) over time. The strategy for the former would be to look at the frequency of a given orientation over time (instead of the system‚Äôs mean orientation). For the latter, the simplest implementation would be to track the number of aborted move attempts during data sampling. In addition to this, the pair correlation function (or radial distribution function, which, for a particle, describes particle density as a function of radial distance) could be implemented to add to the overall structural characterisation. In brief, beyond these few additional things to look into, so far, the model was updated and revised at places, and the important characterisations were implemented, and looks to correspond well with¬†¬†[13].\n\nGoals and plans\nThe goal, ultimately, is to train a convolution neural network to predict, from purely static, structural information, the dissipation of the system, which we take here to be defined as the ratio between the mass transfer time and the diffusion time, i.e.¬†P√©clet number, PEP_E. This relates to the speed, vv, the diffusion coefficient D=œÑ‚àí1D =\n\\tau^{-1}¬†¬†[13], and the interaction range œÉ\\sigma¬†¬†[8], which is unity. This gives PE‚àùŒ±‚àí1P_E\\propto \\alpha^{-1}. Related work was done in in¬†¬†[8]; using a convolutional neural network (CNN), the static structural configuration of an AOUP system (taken to be the pair correlations) was linked to dissipation (which was taken to be the active work per particle), without any knowledge of the underlying dynamics. It is our goal to investigate, in a similar vein, but with a lattice-based PEP implementation, and with fewer assumptions. Here, static structural configuration can be single snapshots of cluster properties and distribution, with and without orientation characterisations, and see if dissipation in terms of PEP_E can be linked, as well as inspect the convolutional network for relevant structural weights. We will implement this in Keras (Tensorflow), and the plan is to tune the neural network to get a configuration that is not too computationally expensive, using minimal data, but able to retain accuracy (using pair correlations and other features we implement) and some robustness (beyond the standard variations in Œ±\\alpha and œï\\phi). This means devising pipelines to test how well it can scale (up or down), how well does it perform for inputs of the system before it enters steady-state, and as previously mentioned, how it performs if we exclude orientation, or change the degrees of freedom or exclusion threshold in the model.\nFrom this, the next steps would be to get to grips with CNNs and finesse our in-house code to have all the characterisations to prepare the dataset for training, before we can start implementing a simple model with minimal layers for the CNN. Then, we can proceed to evaluating the model, at this stage, if good predictions for dissipation are obtained, we can look into trying out different layers, optimizers and other features in order better accuracy, as well as build novel situations to test and increase robustness.\n\n\n\n\n[1] M. C. Marchetti, J. F. Joanny, S. Ramaswamy, T. B. Liverpool, J. Prost, M. Rao, and R. A. Simha, Hydrodynamics of Soft Active Matter, Reviews of Modern Physics 85, 1143 (2013).\n\n\n[2] Y. Yang, F. Turci, E. Kague, C. L. Hammond, J. Russo, and C. P. Royall, Dominating Lengthscales of Zebrafish Collective Behaviour, PLOS Computational Biology 18, e1009394 (2022).\n\n\n[3] S. Decamp, What Is Active Matter?, Stephen j. Decamp (n.d.).\n\n\n[4] J. Buhl, D. J. T. Sumpter, I. D. Couzin, J. J. Hale, E. Despland, E. R. Miller, and S. J. Simpson, From Disorder to Order in Marching Locusts, Science 312, 1402 (2006).\n\n\n[5] C. Bechinger, R. Di Leonardo, H. L√∂wen, C. Reichhardt, G. Volpe, and G. Volpe, Active Particles in Complex and Crowded Environments, Reviews of Modern Physics 88, 045006 (2016).\n\n\n[6] S. Ramaswamy, The Mechanics and Statistics of Active Matter, Annual Review of Condensed Matter Physics 1, 323 (2010).\n\n\n[7] G. Gompper et al., The 2020 Motile Active Matter Roadmap, Journal of Physics: Condensed Matter 32, 193001 (2020).\n\n\n[8] G. Rassolov, L. Tociu, √â. Fodor, and S. Vaikuntanathan, From Predicting to Learning Dissipation from Pair Correlations of Active Liquids, The Journal of Chemical Physics 157, 054901 (2022).\n\n\n[9] E. Flenner and G. Szamel, Active Matter: Quantifying the Departure from Equilibrium, Physical Review E 102, 022607 (2020).\n\n\n[10] T. Vicsek, A. Czir√≥k, E. Ben-Jacob, I. Cohen, and O. Shochet, Novel Type of Phase Transition in a System of Self- Driven Particles, Physical Review Letters 75, 1226 (1995).\n\n\n[11] A. K. Omar, K. Klymko, T. GrandPre, and P. L. Geissler, Phase Diagram of Active Brownian Spheres: Crystallization and the Metastability of Motility-Induced Phase Separation, Physical Review Letters 126, 188002 (2021).\n\n\n[12] F. Turci and N. B. Wilding, Phase Separation and Multibody Effects in Three- Dimensional Active Brownian Particles, Physical Review Letters 126, 038002 (2021).\n\n\n[13] R. Soto and R. Golestanian, Run-and-Tumble Dynamics in a Crowded Environment: Persistent Exclusion Process for Swimmers, Physical Review E 89, 012706 (2014).\n\n\n[14] N. Sep√∫lveda and R. Soto, Wetting Transitions Displayed by Persistent Active  Particles, Physical Review Letters 119, 078001 (2017).\n\n\n[15] Persistent Exclusion Process, (2023)."
  },
  {
    "objectID": "training/prediction_vs_actual.html",
    "href": "training/prediction_vs_actual.html",
    "title": "Prediction vs actual",
    "section": "",
    "text": "Code\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\ntumbles = np.logspace(-6,-1,10,base=2)\nplot_configs = {\n        \"axes.formatter.use_mathtext\": True,\n        \"font.size\": 14,\n        \"axes.titlesize\": 14,\n        \"axes.labelsize\": 16,\n        \"xtick.labelsize\": 14,\n        \"ytick.labelsize\": 14,\n        \"legend.fontsize\": 16,\n        \"font.family\": \"sans-serif\",\n        \"font.sans-serif\": \"Arial\",\n        \"mathtext.fontset\": \"cm\",\n        \"text.usetex\": False,\n}\nsns.set(rc=plot_configs)\nsns.set_style(\"ticks\")\nsns.set_style({\"xtick.direction\": \"in\", \"ytick.direction\": \"in\"})\nplt.rcParams.update(plot_configs)\n\ndf = pd.read_csv('hyphen1065.csv')\n\nfig, ax = plt.subplots(figsize=(6, 6), constrained_layout=True)\nax.scatter(\n    data=df,\n    x=\"Actual values\",\n    y=\"Predicted values\",\n    marker='o',\n    fc=\"darkblue\",\n    alpha=0.1,\n)\nax.scatter(data=df,x='Actual values',y='Actual values', marker='o', s=100, fc=\"darkorange\", ec='k')\nax.legend(frameon=False, fontsize='medium')\nax.set_xscale('log')\nax.get_xaxis().set_major_formatter(ticker.ScalarFormatter())\nax.set_xticks(np.round(tumbles,3)[::2])\nax.set_yscale('log')\nax.get_yaxis().set_major_formatter(ticker.ScalarFormatter())\nax.set_yticks(np.round(tumbles,3)[::2])\nax.set(xlabel=r\"Actual tumbling rate, $\\alpha_a$\", ylabel=r\"Predicted tumbling rate, $\\alpha_p$\")\nsns.despine()\n\n\n\n\nCode\nimport tensorflow as tf\nimport os\n\nos.chdir(\"/project/persistent-exclusion-process/\")\n\n\n\n\nCode\nmodel = tf.keras.models.load_model(\"models/blue9392.keras\")\nmodel.summary()\n\n\nModel: \"sequential_7\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_21 (Conv2D)          (None, 128, 128, 3)       30        \n                                                                 \n max_pooling2d_21 (MaxPooli  (None, 64, 64, 3)         0         \n ng2D)                                                           \n                                                                 \n re_lu_21 (ReLU)             (None, 64, 64, 3)         0         \n                                                                 \n batch_normalization_21 (Ba  (None, 64, 64, 3)         12        \n tchNormalization)                                               \n                                                                 \n conv2d_22 (Conv2D)          (None, 64, 64, 4)         304       \n                                                                 \n max_pooling2d_22 (MaxPooli  (None, 32, 32, 4)         0         \n ng2D)                                                           \n                                                                 \n re_lu_22 (ReLU)             (None, 32, 32, 4)         0         \n                                                                 \n batch_normalization_22 (Ba  (None, 32, 32, 4)         16        \n tchNormalization)                                               \n                                                                 \n conv2d_23 (Conv2D)          (None, 32, 32, 6)         606       \n                                                                 \n max_pooling2d_23 (MaxPooli  (None, 16, 16, 6)         0         \n ng2D)                                                           \n                                                                 \n re_lu_23 (ReLU)             (None, 16, 16, 6)         0         \n                                                                 \n batch_normalization_23 (Ba  (None, 16, 16, 6)         24        \n tchNormalization)                                               \n                                                                 \n global_average_pooling2d_7  (None, 6)                 0         \n  (GlobalAveragePooling2D)                                       \n                                                                 \n dropout_14 (Dropout)        (None, 6)                 0         \n                                                                 \n dense_21 (Dense)            (None, 128)               896       \n                                                                 \n dropout_15 (Dropout)        (None, 128)               0         \n                                                                 \n dense_22 (Dense)            (None, 3)                 387       \n                                                                 \n flatten_7 (Flatten)         (None, 3)                 0         \n                                                                 \n dense_23 (Dense)            (None, 1)                 4         \n                                                                 \n=================================================================\nTotal params: 2279 (8.90 KB)\nTrainable params: 2253 (8.80 KB)\nNon-trainable params: 26 (104.00 Byte)\n_________________________________________________________________\n\n\n2024-03-27 12:50:35.079060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4454 MB memory:  -&gt; device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:07:00.0, compute capability: 7.5"
  },
  {
    "objectID": "training/training_with_orientation_hi.html",
    "href": "training/training_with_orientation_hi.html",
    "title": "Training with orientation (high density)",
    "section": "",
    "text": "Full code\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n0"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-1-hi_helicopter1822",
    "href": "training/training_with_orientation_hi.html#orientation-1-hi_helicopter1822",
    "title": "Training with orientation (high density)",
    "section": "Orientation 1 (hi_helicopter1822)",
    "text": "Orientation 1 (hi_helicopter1822)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0\n0.02800301\n0.012775287\n0.9913829717454875"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-2-hi_wardrobe9539",
    "href": "training/training_with_orientation_hi.html#orientation-2-hi_wardrobe9539",
    "title": "Training with orientation (high density)",
    "section": "Orientation 2 (hi_wardrobe9539)",
    "text": "Orientation 2 (hi_wardrobe9539)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.004300158\n0.043516878\n0.017011154\n0.988182077028401"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-3-hi_looper2409",
    "href": "training/training_with_orientation_hi.html#orientation-3-hi_looper2409",
    "title": "Training with orientation (high density)",
    "section": "Orientation 3 (hi_looper2409)",
    "text": "Orientation 3 (hi_looper2409)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n1.8626451e-09\n0.034836713\n0.014604139\n0.9875309487526724"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-4-hi_potato8290",
    "href": "training/training_with_orientation_hi.html#orientation-4-hi_potato8290",
    "title": "Training with orientation (high density)",
    "section": "Orientation 4 (hi_potato8290)",
    "text": "Orientation 4 (hi_potato8290)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n3.7252903e-09\n0.033033114\n0.013764223\n0.9883616870216612"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-5-hi_cells9177",
    "href": "training/training_with_orientation_hi.html#orientation-5-hi_cells9177",
    "title": "Training with orientation (high density)",
    "section": "Orientation 5 (hi_cells9177)",
    "text": "Orientation 5 (hi_cells9177)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0044725332\n0.03392468\n0.014844705\n0.9870156978654031"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-6-hi_hyphen1065",
    "href": "training/training_with_orientation_hi.html#orientation-6-hi_hyphen1065",
    "title": "Training with orientation (high density)",
    "section": "Orientation 6 (hi_hyphen1065)",
    "text": "Orientation 6 (hi_hyphen1065)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0027037438\n0.049233653\n0.013682529\n0.9903583821255841"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-7-hi_playground6730",
    "href": "training/training_with_orientation_hi.html#orientation-7-hi_playground6730",
    "title": "Training with orientation (high density)",
    "section": "Orientation 7 (hi_playground6730)",
    "text": "Orientation 7 (hi_playground6730)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0030006783\n0.026939\n0.012529406\n0.9926582688954054"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-8-hi_blue9392",
    "href": "training/training_with_orientation_hi.html#orientation-8-hi_blue9392",
    "title": "Training with orientation (high density)",
    "section": "Orientation 8 (hi_blue9392)",
    "text": "Orientation 8 (hi_blue9392)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.005376949\n0.040994853\n0.015985742\n0.9903124563917847"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-9-hi_alkaline7391",
    "href": "training/training_with_orientation_hi.html#orientation-9-hi_alkaline7391",
    "title": "Training with orientation (high density)",
    "section": "Orientation 9 (hi_alkaline7391)",
    "text": "Orientation 9 (hi_alkaline7391)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.005180236\n0.0316144\n0.014676246\n0.9894957908167329"
  },
  {
    "objectID": "training/training_with_orientation_hi.html#orientation-10-hi_cold6626",
    "href": "training/training_with_orientation_hi.html#orientation-10-hi_cold6626",
    "title": "Training with orientation (high density)",
    "section": "Orientation 10 (hi_cold6626)",
    "text": "Orientation 10 (hi_cold6626)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.00074457406\n0.036156908\n0.016903196\n0.9878206104594179"
  },
  {
    "objectID": "training/visualize_with_orientation.html",
    "href": "training/visualize_with_orientation.html",
    "title": "Visualizing CNN layers with orientation",
    "section": "",
    "text": "Full code"
  },
  {
    "objectID": "training/visualize_with_orientation.html#input-snapshot",
    "href": "training/visualize_with_orientation.html#input-snapshot",
    "title": "Visualizing CNN layers with orientation",
    "section": "Input snapshot",
    "text": "Input snapshot\nLow tumbling rate (top) and high tumbling rate (bottom)\n\n\nCode\nmodel = tf.keras.models.load_model('models/blue9392.keras')"
  },
  {
    "objectID": "training/visualize_with_orientation.html#first-set-of-conv2d-pool-relu",
    "href": "training/visualize_with_orientation.html#first-set-of-conv2d-pool-relu",
    "title": "Visualizing CNN layers with orientation",
    "section": "First set of Conv2D, Pool, ReLU",
    "text": "First set of Conv2D, Pool, ReLU"
  },
  {
    "objectID": "training/visualize_with_orientation.html#second-set-of-conv2d-pool-relu",
    "href": "training/visualize_with_orientation.html#second-set-of-conv2d-pool-relu",
    "title": "Visualizing CNN layers with orientation",
    "section": "Second set of Conv2D, Pool, ReLU",
    "text": "Second set of Conv2D, Pool, ReLU"
  },
  {
    "objectID": "training/visualize_with_orientation.html#third-set-of-conv2d-pool-relu",
    "href": "training/visualize_with_orientation.html#third-set-of-conv2d-pool-relu",
    "title": "Visualizing CNN layers with orientation",
    "section": "Third set of Conv2D, Pool, ReLU",
    "text": "Third set of Conv2D, Pool, ReLU"
  },
  {
    "objectID": "training/training_with_monochrome.html",
    "href": "training/training_with_monochrome.html",
    "title": "Training with monochrome",
    "section": "",
    "text": "Full code\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n485"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-1-boat1822",
    "href": "training/training_with_monochrome.html#monochrome-1-boat1822",
    "title": "Training with monochrome",
    "section": "Monochrome 1 (boat1822)",
    "text": "Monochrome 1 (boat1822)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.8\n1.8626451e-09\n0.041253746\n0.017095365\n0.9814615525480133"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-2-door9539",
    "href": "training/training_with_monochrome.html#monochrome-2-door9539",
    "title": "Training with monochrome",
    "section": "Monochrome 2 (door9539)",
    "text": "Monochrome 2 (door9539)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0031616555\n0.0491944\n0.018290136\n0.9813921658249771"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-3-muffin2409",
    "href": "training/training_with_monochrome.html#monochrome-3-muffin2409",
    "title": "Training with monochrome",
    "section": "Monochrome 3 (muffin2409)",
    "text": "Monochrome 3 (muffin2409)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n3.7252903e-09\n0.040947735\n0.015605074\n0.9798072039836785"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-4-yam8290",
    "href": "training/training_with_monochrome.html#monochrome-4-yam8290",
    "title": "Training with monochrome",
    "section": "Monochrome 4 (yam8290)",
    "text": "Monochrome 4 (yam8290)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n1.8626451e-09\n0.040813085\n0.015562691\n0.9825481420776891"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-5-bacteria9177",
    "href": "training/training_with_monochrome.html#monochrome-5-bacteria9177",
    "title": "Training with monochrome",
    "section": "Monochrome 5 (bacteria9177)",
    "text": "Monochrome 5 (bacteria9177)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0036979427\n0.036329802\n0.014743452\n0.9842731223612726"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-6-slash1065",
    "href": "training/training_with_monochrome.html#monochrome-6-slash1065",
    "title": "Training with monochrome",
    "section": "Monochrome 6 (slash1065)",
    "text": "Monochrome 6 (slash1065)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.003703905\n0.049001247\n0.019465571\n0.9766355852889547"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-7-pool6730",
    "href": "training/training_with_monochrome.html#monochrome-7-pool6730",
    "title": "Training with monochrome",
    "section": "Monochrome 7 (pool6730)",
    "text": "Monochrome 7 (pool6730)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n3.7252903e-09\n0.029708317\n0.0130034955\n0.9852250026696703"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-8-green9392",
    "href": "training/training_with_monochrome.html#monochrome-8-green9392",
    "title": "Training with monochrome",
    "section": "Monochrome 8 (green9392)",
    "text": "Monochrome 8 (green9392)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.00475593\n0.053056147\n0.01874308\n0.9831478274498944"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-9-neutral7391",
    "href": "training/training_with_monochrome.html#monochrome-9-neutral7391",
    "title": "Training with monochrome",
    "section": "Monochrome 9 (neutral7391)",
    "text": "Monochrome 9 (neutral7391)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n1.8626451e-09\n0.03382228\n0.013250096\n0.9851257704627054"
  },
  {
    "objectID": "training/training_with_monochrome.html#monochrome-10-lukewarm6626",
    "href": "training/training_with_monochrome.html#monochrome-10-lukewarm6626",
    "title": "Training with monochrome",
    "section": "Monochrome 10 (lukewarm6626)",
    "text": "Monochrome 10 (lukewarm6626)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0016651626\n0.045824252\n0.01871568\n0.9810886544058843"
  },
  {
    "objectID": "training/training_mse.html",
    "href": "training/training_mse.html",
    "title": "Training MSE",
    "section": "",
    "text": "Code\n%load_ext autoreload\n%autoreload 2\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport os\n\nos.chdir(\"/project/persistent-exclusion-process/\")\n\nimport gc\n\nimport numpy as np\nimport h5py\nimport glob\nimport re\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport seaborn as sns\nfrom tensorflow import keras\n\nfrom src.training_utils import (\n    extract_floats,\n    data_load,\n    split_dataset,\n    predict_multi_by_name,\n    predict_and_plot,\n    plot_violin_and_statistics\n)\nfrom src.models import make_net, make_net_no_dropout\nfrom src.plot_utils import get_plot_configs\n\nplot_configs = get_plot_configs()\nsns.set(rc=plot_configs)\nsns.set_style(\"ticks\")\nsns.set_style({\"xtick.direction\": \"in\", \"ytick.direction\": \"in\"})\nplt.rcParams.update(plot_configs)\n\nnp.set_printoptions(precision=3, suppress=True)\ngpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device, True)\nprint(gpu_devices)\n\n\n\n\nCode\ntumbles = np.logspace(-6, -1, 10, base=2) # here are all the alphas available\n\nx,y,shape = data_load(alphas=tumbles, densities=[0.25], orientation=True)\nx_train, y_train, x_val, y_val = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\n\n\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n0\n\n\n\n\nCode\ntf.keras.utils.set_random_seed(9177)\n\nmodel = make_net(shape)\n# Slightly slower adam and SGD\nadam = keras.optimizers.Adam(learning_rate=0.0002)\nsgd = keras.optimizers.SGD(learning_rate=0.002)\nmodel.compile(loss='mae', optimizer=sgd, metrics=['mae'])\n\n\n\n\nCode\nepochs=60\nbatch_size=64\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs=epochs,\n    verbose=2,\n    batch_size=batch_size,\n    validation_data=(x_val, y_val)\n)\nprint(\"Evaluate on test data:\")\nresults = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=0)\nprint(\"Test loss:\", results)\n\n\n\n\nCode\nacc = history.history['mae']\nval_acc = history.history['val_mae']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.plot(epochs_range, acc, label='Training MAE')\nplt.plot(epochs_range, val_acc, label='Validation MAE')\nplt.legend(loc='upper right')\nplt.title('Training and Validation MAE')\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\nCode\npredict_and_plot(model, x_val, y_val)\n\n\n1.0\n0.0039029366\n0.038392987\n0.016203437\n0.9814846496222708\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save the model here\n\nname = \"cells9177\"\nmodel.save(f\"models/{name}.keras\")\nnp.save(f\"models/{name}.npy\",history.history)\n\n\n\n\nCode\nimport gc\n\ndel model\ndel history\n\nprint(\"Collected: \", gc.collect())\n\n\n\nMSE\n\n\nCode\ntf.keras.utils.set_random_seed(1065)\n\nmodel = make_net(shape)\n# Slightly slower adam and SGD\nadam = keras.optimizers.Adam(learning_rate=0.0002)\nsgd = keras.optimizers.SGD(learning_rate=0.002)\nmodel.compile(loss='mse', optimizer=sgd, metrics=['mse'])\n\n\n\n\nCode\nepochs=100\nbatch_size=64\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs=epochs,\n    verbose=2,\n    batch_size=batch_size,\n    validation_data=(x_val, y_val)\n)\nprint(\"Evaluate on test data:\")\nresults = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=0)\nprint(\"Test loss:\", results)\n\n\n\n\nCode\nacc = history.history['mse']\nval_acc = history.history['val_mse']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.plot(epochs_range, acc, label='Training MSE')\nplt.plot(epochs_range, val_acc, label='Validation MSE')\nplt.legend(loc='upper right')\nplt.title('Training and Validation MSE')\n\n\nText(0.5, 1.0, 'Training and Validation MSE')\n\n\n\n\n\n\n\n\n\n\n\nCode\npredict_and_plot(model, x_val, y_val)\n\n\n0.9\n0.007140547\n0.041066002\n0.02329898\n0.9619045228435774\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save the model here\n\nname = \"better1065\"\nmodel.save(f\"models/{name}.keras\")\nnp.save(f\"models/{name}.npy\",history.history)\n\n\n\n\nCode\nimport gc\n\ndel model\ndel history\n\nprint(\"Collected: \", gc.collect())\n\n\n\n\nCode\ntf.keras.utils.set_random_seed(6626)\n\nmodel = make_net(shape)\n# Slightly slower adam and SGD\nadam = keras.optimizers.Adam(learning_rate=0.0002)\nsgd = keras.optimizers.SGD(learning_rate=0.002)\nmodel.compile(loss='mae', optimizer=sgd, metrics=['mae'])\n\n\n\n\nCode\nepochs=60\nbatch_size=64\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs=epochs,\n    verbose=2,\n    batch_size=batch_size,\n    validation_data=(x_val, y_val)\n)\nprint(\"Evaluate on test data:\")\nresults = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=0)\nprint(\"Test loss:\", results)\n\n\n\n\nCode\nacc = history.history['mae']\nval_acc = history.history['val_mae']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.plot(epochs_range, acc, label='Training MAE')\nplt.plot(epochs_range, val_acc, label='Validation MAE')\nplt.legend(loc='upper right')\nplt.title('Training and Validation MAE')\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\nCode\npredict_and_plot(model, x_val, y_val)\n\n\n0.9\n0.00089638744\n0.050202396\n0.020576788\n0.9768299044891678\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save the model here\n\nname = \"cold6626\"\nmodel.save(f\"models/{name}.keras\")\nnp.save(f\"models/{name}.npy\",history.history)\n\n\n\n\nCode\nimport gc\n\ndel model\ndel history\n\nprint(\"Collected: \", gc.collect())\n\n\n\n\nMAE\n\n\nCode\ntf.keras.utils.set_random_seed(1065)\n\nmodel = make_net(shape)\n# Slightly slower adam and SGD\nadam = keras.optimizers.Adam(learning_rate=0.0002)\nsgd = keras.optimizers.SGD(learning_rate=0.002)\nmodel.compile(loss='mae', optimizer=sgd, metrics=['mae'])\n\n\n\n\nCode\nepochs=100\nbatch_size=64\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs=epochs,\n    verbose=2,\n    batch_size=batch_size,\n    validation_data=(x_val, y_val)\n)\nprint(\"Evaluate on test data:\")\nresults = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=0)\nprint(\"Test loss:\", results)\n\n\n\n\nCode\nacc = history.history['mae']\nval_acc = history.history['val_mae']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.plot(epochs_range, acc, label='Training MAE')\nplt.plot(epochs_range, val_acc, label='Validation MAE')\nplt.legend(loc='upper right')\nplt.title('Training and Validation MAE')\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\nCode\npredict_and_plot(model, x_val, y_val)\n\n\n0.9\n0.0027237784\n0.044947587\n0.015559976\n0.9880269085834323\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save the model here\n\nname = \"hyphen1065_100\"\nmodel.save(f\"models/{name}.keras\")\nnp.save(f\"models/{name}.npy\",history.history)\n\n\n\n\nCode\nimport gc\n\ndel model\ndel history\n\nprint(\"Collected: \", gc.collect())\n\n\n\n\nMAE no dropout\n\n\nCode\ntf.keras.utils.set_random_seed(1065)\n\nmodel = make_net_no_dropout(shape)\n# Slightly slower adam and SGD\nadam = keras.optimizers.Adam(learning_rate=0.0002)\nsgd = keras.optimizers.SGD(learning_rate=0.002)\nmodel.compile(loss='mae', optimizer=sgd, metrics=['mae'])\nmodel.summary()\n\n\n\n\nCode\nepochs=100\nbatch_size=64\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs=epochs,\n    verbose=2,\n    batch_size=batch_size,\n    validation_data=(x_val, y_val)\n)\nprint(\"Evaluate on test data:\")\nresults = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=0)\nprint(\"Test loss:\", results)\n\n\n\n\nCode\nacc = history.history['mae']\nval_acc = history.history['val_mae']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.plot(epochs_range, acc, label='Training MAE')\nplt.plot(epochs_range, val_acc, label='Validation MAE')\nplt.legend(loc='upper right')\nplt.title('Training and Validation MAE')\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\nCode\npredict_and_plot(model, x_val, y_val)\n\n\n0.9\n0.001268603\n0.049102053\n0.013162863\n0.9885613864954195\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save the model here\n\nname = \"hyphen1065_100_no_dropout\"\nmodel.save(f\"models/{name}.keras\")\nnp.save(f\"models/{name}.npy\",history.history)\n\n\n\n\nCode\nimport gc\n\ndel model\ndel history\n\nprint(\"Collected: \", gc.collect())\n\n\n\n\nPlot both\n\n\nCode\nimport pandas as pd\nimport matplotlib.cm as mcm\nfrom mpl_toolkits.axes_grid1.inset_locator import InsetPosition, inset_axes\n\n\n\n\nCode\nmodel_mse = tf.keras.models.load_model(f\"models/better1065.keras\")\nhistory_mse = np.load(\"models/better1065.npy\",allow_pickle=True).item()\nmodel_mae = tf.keras.models.load_model(f\"models/hyphen1065_100.keras\")\nhistory_mae = np.load(\"models/hyphen1065_100.npy\",allow_pickle=True).item()\n\n\n\n\nCode\nprediction_mse = model_mse.predict(x_val, verbose=0)\n\n\n\n\nCode\nprediction_mae = model_mae.predict(x_val, verbose=0)\n\n\n\n\nCode\nacc1 = history_mse['mse']\nval_acc1 = history_mse['val_mse']\nacc2 = history_mae['mae']\nval_acc2 = history_mae['val_mae']\n\ndf = pd.DataFrame(\n    {\n        \"Training\": np.concatenate((acc1,acc2)),\n        \"Validation\": np.concatenate((val_acc1,val_acc2)),\n        \"Loss function\": [\"MSE\"]*100 + [\"MAE\"]*100\n    }\n)\n\ndf_pred = pd.DataFrame(\n    {\n        \"Predictions\": np.concatenate((prediction_mse.T[0]-y_val,prediction_mae.T[0]-y_val)),\n        \"Actual\": np.tile(y_val,2),\n        \"Loss function\": [\"MSE\"]*6000+[\"MAE\"]*6000\n    }\n)\n\npalette={\"MAE\": mcm.gnuplot(150), \"MSE\": mcm.gnuplot(30)}\nepochs_range = np.tile(range(100),2)\nfig, ax1 = plt.subplots(1,1, figsize=(10, 7))\nsns.lineplot(ax=ax1, data=df, x=epochs_range, y=\"Training\", hue='Loss function', palette=palette, legend=False)\nsns.lineplot(ax=ax1, data=df, x=epochs_range, y=\"Validation\", hue='Loss function', legend=False, ls='--', palette=palette)\nax1.set_ylim(bottom=-0.015)\n\nax1.annotate(text='Training MAE', xytext=(50,0.045), xy=(50,0.032), c=palette[\"MAE\"], ha=\"center\",\n             arrowprops={\"arrowstyle\": \"-\", \"color\": palette[\"MAE\"]})\nax1.annotate(text='Validation MAE', xytext=(85,0.045), xy=(85,0.014), c=palette[\"MAE\"], ha=\"center\",\n             arrowprops={\"arrowstyle\": \"-\", \"color\": palette[\"MAE\"]})\n\nax1.annotate(text='Training MSE', xytext=(15,0.02), xy=(15,0.009), c=palette[\"MSE\"], ha=\"center\",\n             arrowprops={\"arrowstyle\": \"-\", \"color\": palette[\"MSE\"]})\nax1.annotate(text='Validation MSE', xytext=(10,-0.005), xy=(10,0.012), c=palette[\"MSE\"], ha=\"center\",\n             arrowprops={\"arrowstyle\": \"-\", \"color\": palette[\"MSE\"]})\n\nax1.set_ylabel(\"Loss\")\nax1.set_xlabel(\"Training epochs\")\n\nax = inset_axes(ax1, width=\"100%\", height=\"100%\", borderpad=1)\nax.set_axes_locator(InsetPosition(ax1, [0.38, 0.5, 0.6, 0.46]))\n\nsns.violinplot(\n    ax=ax,\n    data=df_pred,\n    x=\"Actual\",\n    y=\"Predictions\",\n    hue=\"Loss function\",\n    color=\"w\",\n    alpha=.9,\n    density_norm=\"width\",\n    palette=palette,\n    native_scale=True,\n    log_scale=(True,False),\n    linewidth=1,\n    inner=\"box\",\n    inner_kws={\"box_width\": 1, \"whis_width\": 0, \"color\": \"w\", \"marker\": None},\n)\n\nax.get_xaxis().set_major_formatter(ticker.ScalarFormatter())\nax.set_xticks(np.round(tumbles,3)[::2])\n\nax.set(xlabel=r\"$\\alpha$\", ylabel=r\"$\\hat{y}_i-y_i$\")\nax.axhline(0, zorder=0, c='.75', ls=\"--\")\nsns.move_legend(ax, \"lower left\", frameon=False, fontsize=14)\nsns.despine(ax=ax1)\nfig.savefig(\"plots/mse_vs_mae.pdf\", bbox_inches='tight')\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_configs = get_plot_configs()\nsns.set(rc=plot_configs)\nsns.set_style(\"ticks\")\nsns.set_style({\"xtick.direction\": \"in\", \"ytick.direction\": \"in\"})\nplt.rcParams.update(plot_configs)\n\ndf_pred = pd.DataFrame(\n    {\n        \"Predictions\": np.concatenate((prediction_mse.T[0]-y_val,prediction_mae.T[0]-y_val)),\n        \"Actual\": np.tile(y_val,2),\n        \"Loss function\": [\"MSE\"]*6000+[\"MAE\"]*6000\n    }\n)\n\nfig, ax = plt.subplots(figsize=(9, 6))\nsns.violinplot(\n    ax=ax,\n    data=df_pred,\n    x=\"Actual\",\n    y=\"Predictions\",\n    hue=\"Loss function\",\n    color=\"w\",\n    alpha=.9,\n    density_norm=\"width\",\n    palette=palette,\n    native_scale=True,\n    log_scale=(True,False),\n    linewidth=1,\n    inner=\"box\",\n    inner_kws={\"box_width\": 1.5, \"whis_width\": 0, \"color\": \"w\", \"marker\": None},\n)\n\nax.set(xlabel=r\"Tumbling rates, $\\alpha$\", ylabel=r\"Error, $y_p - y_a$\")\nax.axhline(0, zorder=0, c='.75', ls=\"--\")\nsns.move_legend(ax, \"lower left\", frameon=False, fontsize=14)"
  },
  {
    "objectID": "training/training_without_orientation_hi.html",
    "href": "training/training_without_orientation_hi.html",
    "title": "Training without orientation (high density)",
    "section": "",
    "text": "Full code\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n0"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-1-hi_ice1822",
    "href": "training/training_without_orientation_hi.html#no-orientation-1-hi_ice1822",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 1 (hi_ice1822)",
    "text": "No-orientation 1 (hi_ice1822)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n3.7252903e-09\n0.03100251\n0.013841291\n0.9907492284869572"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-2-hi_house9539",
    "href": "training/training_without_orientation_hi.html#no-orientation-2-hi_house9539",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 2 (hi_house9539)",
    "text": "No-orientation 2 (hi_house9539)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.004664499\n0.039551686\n0.016544359\n0.9883884268011789"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-3-hi_cake2409",
    "href": "training/training_without_orientation_hi.html#no-orientation-3-hi_cake2409",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 3 (hi_cake2409)",
    "text": "No-orientation 3 (hi_cake2409)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n1.8626451e-09\n0.03802927\n0.015795747\n0.9842057055553044"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-4-hi_carrot8290",
    "href": "training/training_without_orientation_hi.html#no-orientation-4-hi_carrot8290",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 4 (hi_carrot8290)",
    "text": "No-orientation 4 (hi_carrot8290)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0\n0.034411933\n0.014111537\n0.9883128871312052"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-5-hi_virus9177",
    "href": "training/training_without_orientation_hi.html#no-orientation-5-hi_virus9177",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 5 (hi_virus9177)",
    "text": "No-orientation 5 (hi_virus9177)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0045715584\n0.035353743\n0.015230444\n0.9875728504523393"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-6-hi_comma1065",
    "href": "training/training_without_orientation_hi.html#no-orientation-6-hi_comma1065",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 6 (hi_comma1065)",
    "text": "No-orientation 6 (hi_comma1065)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0049175383\n0.041311007\n0.01743255\n0.9862715938925832"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-7-hi_toys6730",
    "href": "training/training_without_orientation_hi.html#no-orientation-7-hi_toys6730",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 7 (hi_toys6730)",
    "text": "No-orientation 7 (hi_toys6730)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0045001637\n0.030524084\n0.014988089\n0.9874591185487613"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-8-hi_red9392",
    "href": "training/training_without_orientation_hi.html#no-orientation-8-hi_red9392",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 8 (hi_red9392)",
    "text": "No-orientation 8 (hi_red9392)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.004339098\n0.03961642\n0.016671045\n0.9886075261524339"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-9-hi_acid7391",
    "href": "training/training_without_orientation_hi.html#no-orientation-9-hi_acid7391",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 9 (hi_acid7391)",
    "text": "No-orientation 9 (hi_acid7391)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0054641655\n0.03355443\n0.015286064\n0.989357899208546"
  },
  {
    "objectID": "training/training_without_orientation_hi.html#no-orientation-10-hi_hot6626",
    "href": "training/training_without_orientation_hi.html#no-orientation-10-hi_hot6626",
    "title": "Training without orientation (high density)",
    "section": "No-orientation 10 (hi_hot6626)",
    "text": "No-orientation 10 (hi_hot6626)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.00087254413\n0.037262153\n0.017387044\n0.9875499780574895"
  },
  {
    "objectID": "training/visualize_summary.html",
    "href": "training/visualize_summary.html",
    "title": "Visualizing CNN layers with orientation",
    "section": "",
    "text": "Code\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nos.chdir(\"/project/persistent-exclusion-process\")\n\nimport h5py\nimport numpy as np\n\nimport tensorflow as tf\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\nfrom cmcrameri import cm\nfrom numpy import expand_dims\nimport seaborn as sns\n\nfrom src.utils import get_cluster_labels, get_ds_iters\nfrom src.training_utils import (\n    data_load,\n    split_dataset,\n)\nfrom src.plot_utils import get_plot_configs\n\n\n2024-04-08 20:53:47.156703: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-04-08 20:53:48.063058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\n\n\nCode\nhf = h5py.File(f\"no_roll_data/dataset_tumble_0.016_0.25.h5\", \"r\")\niters = get_ds_iters(hf.keys())\n\n\n\n\nCode\nj = 4\niteration = 500\n\nplot_configs = get_plot_configs()\nsns.set(rc=plot_configs)\nsns.set_style(\"ticks\")\nsns.set_style({\"xtick.direction\": \"in\",\"ytick.direction\": \"in\"})\nplt.rcParams.update(plot_configs)\n\nfig = plt.figure(figsize=(8,6), constrained_layout=True)\ngspec = fig.add_gridspec(3, 4)\n\n\nmodel = tf.keras.models.load_model('models/blue9392.keras')\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[2].output)\n\nimg = hf[f\"conf_{iters[iteration]}\"]\nimg = np.array(img)\n\nfeature_maps1 = model_mini.predict(np.expand_dims(img.reshape((img.shape[0], img.shape[1], 1)), axis=0), verbose=0)\n\nfor jdx in range(j):\n    ax = fig.add_subplot(gspec[0, jdx])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.text(s=f\"A{jdx+1}\", x=0.05, y=0.85, transform=ax.transAxes, backgroundcolor=(1,1,1,0.9))\n    if jdx == 0:\n        plt.imshow(img, cmap='cubehelix')\n    else:\n        plt.imshow(feature_maps1[0, :, :, jdx-1], cmap='cubehelix')\n\n# -------\n\nmodel = tf.keras.models.load_model('models/red9392.keras')\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[2].output)\n\nimg = hf[f\"conf_{iters[iteration]}\"]\nimg = np.array(img)\nimg[img &gt; 0] = 1\nimg = img * np.random.randint(1, 5, size=(128, 128)) / 4\n\nfeature_maps1 = model_mini.predict(np.expand_dims(img.reshape((img.shape[0], img.shape[1], 1)), axis=0), verbose=0)\n\nfor jdx in range(j):\n    ax = fig.add_subplot(gspec[1, jdx])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.text(s=f\"B{jdx+1}\", x=0.05, y=0.85, transform=ax.transAxes, backgroundcolor=(1,1,1,0.9))\n    if jdx == 0:\n        plt.imshow(img, cmap='cubehelix')\n    else:\n        plt.imshow(feature_maps1[0, :, :, jdx-1], cmap='cubehelix')\n\n# -------\n\nmodel = tf.keras.models.load_model('models/green9392.keras')\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[2].output)\n\nimg = hf[f\"conf_{iters[iteration]}\"]\nimg = np.array(img)\nimg[img &gt; 0] = 1\n\nfeature_maps1 = model_mini.predict(np.expand_dims(img.reshape((img.shape[0], img.shape[1], 1)), axis=0), verbose=0)\n\nfor jdx in range(j):\n    ax = fig.add_subplot(gspec[2, jdx])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.text(s=f\"C{jdx+1}\", x=0.05, y=0.85, transform=ax.transAxes, backgroundcolor=(1,1,1,0.9))\n    if jdx == 0:\n        plt.imshow(img, cmap='cubehelix')\n    else:\n        plt.imshow(feature_maps1[0, :, :, jdx-1], cmap='cubehelix')\n\n\nWARNING:tensorflow:5 out of the last 5 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x7b29a3fee3b0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:6 out of the last 6 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x7b29a2c9d900&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig.savefig(\"plots/viz.pdf\", bbox_inches='tight')\n\n\n\n\nCode\nmodel = tf.keras.models.load_model('models/blue9392.keras')\nfor layer in model.layers:\n    if 'conv' not in layer.name:\n        continue\n    filters, biases = layer.get_weights()\n    filters = (filters - filters.min()) / filters.ptp()\n    for i in range(filters.shape[-1]):\n        f = filters[:, :, :, i]\n        for j in range(f.shape[-1]):\n            plt.imshow(f[:, :, j], cmap='cmc.lajolla')\n            plt.show()\n    print(\"ah\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nah\nah\nah"
  },
  {
    "objectID": "training/visualize_with_orientation_hi.html",
    "href": "training/visualize_with_orientation_hi.html",
    "title": "Visualizing CNN layers with orientation",
    "section": "",
    "text": "Code\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nos.chdir(\"/project/persistent-exclusion-process\")\n\nimport h5py\nimport numpy as np\n\nimport tensorflow as tf\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\nfrom cmcrameri import cm\nfrom numpy import expand_dims\n\nfrom src.utils import get_cluster_labels, get_ds_iters\nfrom src.training_utils import (\n    data_load,\n    split_dataset,\n)\nfrom src.plot_utils import get_plot_configs\n\n\n2024-03-25 17:43:29.735868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-03-25 17:43:30.250957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\n\n\nCode\nhf = h5py.File(f\"no_roll_data/dataset_tumble_0.073_0.5.h5\", \"r\")\niters = get_ds_iters(hf.keys())\nimg = hf[f\"conf_{iters[300]}\"]\nimg = np.array(img)\nimg = img.reshape((img.shape[0], img.shape[1], 1))\n\nhf = h5py.File(f\"no_roll_data/dataset_tumble_0.340_0.5.h5\", \"r\")\niters = get_ds_iters(hf.keys())\nimg2 = hf[f\"conf_{iters[300]}\"]\nimg2 = np.array(img2)\nimg2 = img2.reshape((img2.shape[0], img2.shape[1], 1))\n\n\n\n\nCode\nplt.matshow(img, cmap='cmc.oslo')\nplt.xticks([])\nplt.yticks([])\nplt.savefig('plots/input.svg', bbox_inches='tight', pad_inches=-0.1)\nplt.matshow(img2, cmap='cmc.oslo')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel = tf.keras.models.load_model('models/hi_blue9392.keras')\n\n\n2024-03-25 17:44:37.193349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1060 MB memory:  -&gt; device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:07:00.0, compute capability: 7.5\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[0].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 3\nshift = None\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='cmc.oslo')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='cmc.oslo')\n\n\n2024-03-25 17:44:38.572961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[1].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 3\nshift = 64\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='cmc.oslo')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='cmc.oslo')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[2].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 3\nshift = 64\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='cmc.oslo')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='cmc.oslo')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[4].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 4\nshift = 64\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='cmc.oslo')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='cmc.oslo')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[5].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 4\nshift = 32\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='cmc.oslo')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='cmc.oslo')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[6].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 4\nshift = 32\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='cmc.oslo')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='cmc.oslo')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[8].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 6\nshift = 32\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='cmc.oslo')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='cmc.oslo')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[9].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 6\nshift = 16\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='cmc.oslo')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='cmc.oslo')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[10].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 6\nshift = 16\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='cmc.oslo')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='cmc.oslo')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[12].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\n\nfeature_maps2 = model_mini.predict(img2, verbose=0)\n\nplt.matshow(np.rot90(feature_maps1[:, :]))\nplt.matshow(np.rot90(feature_maps2[:, :]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[14].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\n\nplt.matshow(feature_maps1[:, :])\nplt.matshow(feature_maps2[:, :])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[16].output)\n\nfeature_maps1 = model_mini.predict(x1[0], verbose=0)\nfeature_maps2 = model_mini.predict(x2[0], verbose=0)\n\nplt.matshow(np.rot90(feature_maps1[:, :]))\nplt.matshow(np.rot90(feature_maps2[:, :]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[18].output)\n\nfeature_maps1 = model_mini.predict(x1[0], verbose=0)\nfeature_maps2 = model_mini.predict(x2[0], verbose=0)\n\nplt.matshow(np.rot90(feature_maps1[:, :]))\nplt.matshow(np.rot90(feature_maps2[:, :]))"
  },
  {
    "objectID": "activity_log/week_3.html",
    "href": "activity_log/week_3.html",
    "title": "Week 3",
    "section": "",
    "text": "Set up the HPC environment to run PEP code.\nUsing pip to store Python packages.\nThe environment on BluePebble can be set up using this script.\nConveniently, the PATH of a user is kept even when using SLURM, so the packages installed through pip should still work (need to test this). Code ran this week was light enough so I ran it on the login node.\nSee BluePebble\nProduce some snapshots at small and large persistent times.\nSee Some animations"
  },
  {
    "objectID": "activity_log/week_3.html#tasks",
    "href": "activity_log/week_3.html#tasks",
    "title": "Week 3",
    "section": "",
    "text": "Set up the HPC environment to run PEP code.\nUsing pip to store Python packages.\nThe environment on BluePebble can be set up using this script.\nConveniently, the PATH of a user is kept even when using SLURM, so the packages installed through pip should still work (need to test this). Code ran this week was light enough so I ran it on the login node.\nSee BluePebble\nProduce some snapshots at small and large persistent times.\nSee Some animations"
  },
  {
    "objectID": "activity_log/week_3.html#summary",
    "href": "activity_log/week_3.html#summary",
    "title": "Week 3",
    "section": "Summary",
    "text": "Summary\n\nBluePebble\n\nOn BluePebble, the environment for PEP was set up to satisfy all dependencies (I think).\n\nprotobuf minimum dependencies for tensorflow is different on BlueCrystal than on BluePebble? Need to investigate when we run the model.\n\nI added to the README.md on the repo to reflect how to set this all up.\nTo run the code up to generating snapshots:\n\nRun sampler.py to populate datasets.\nAdjust tumble variable in video.py (location here).\nRun video.py. The video is saved as src/myAnimation.gif, transfer that out or rename it before running again with a different tumble value.\n\n\n\n\nSome animations\n\n\n\n\n\n\nYou might need to zoom in a bit to see the patterns more clearly.\n\n\n\n\n\n\n\n\n\n\n\n\nAt Œ±=0.5\\alpha = 0.5, very little cluster formation. Few jamming occurs but cluster does not grow substantially.\n\n\n\n\n\n\n\nAt Œ±=0.05\\alpha = 0.05, this is enough for a bit for some small, temporary clusters that form and dissipate rather quickly.\n\n\n\n\n\n\n\nAt Œ±=0.005\\alpha = 0.005, this is quite a low tumbling rate. A lot of jamming is observed, with particles forming cluster seeds and some evaporation and absorption are observed.\n\n\n\n\n\nThis reflects the effects described in the Method section of the Soto and Golestanian paper."
  },
  {
    "objectID": "activity_log/week_7.html",
    "href": "activity_log/week_7.html",
    "title": "Week 7",
    "section": "",
    "text": "Start the interim report (writing are both synced in under ‚Äúwriting‚Äù and on Overleaf)1\nFigures for interim report\n\nSnapshot grid (3x3 and better font sizes).\nOrientation (one plot with multiple values, fixed density, and same scale)\nCluster labelling (separate plot to demonstrate)\nCluster size distribution (one plot with multiple values of fit, low alpha data points, with data binning to demonstrate power law)\nNumber of clusters (need to write code for this)\n\nit‚Äôs actually just returned by ndimage.label()"
  },
  {
    "objectID": "activity_log/week_7.html#tasks",
    "href": "activity_log/week_7.html#tasks",
    "title": "Week 7",
    "section": "",
    "text": "Start the interim report (writing are both synced in under ‚Äúwriting‚Äù and on Overleaf)1\nFigures for interim report\n\nSnapshot grid (3x3 and better font sizes).\nOrientation (one plot with multiple values, fixed density, and same scale)\nCluster labelling (separate plot to demonstrate)\nCluster size distribution (one plot with multiple values of fit, low alpha data points, with data binning to demonstrate power law)\nNumber of clusters (need to write code for this)\n\nit‚Äôs actually just returned by ndimage.label()"
  },
  {
    "objectID": "activity_log/week_7.html#summary",
    "href": "activity_log/week_7.html#summary",
    "title": "Week 7",
    "section": "Summary",
    "text": "Summary\nThis week I started writing up the interim report, there were a few things to discuss and notes were taken with regard to plans, as well as the PEP code.\n\nPEP code\nWe had a discussion on whether or not the random, independent tumbling mechanism is justified. For a continuous model, the new orientation is a value between 0 and 2œÄ\\pi, and strictly speaking the probability to get any single value is 0. However, for a discrete case, it‚Äôs one in four of (up, down, left, right), thus, 25% of the time there is the case that the particle ‚Äòtumbles‚Äô but it actually just carries on in a straight line. We wonder what the effect of this might be, compared to if we re-roll until it is no longer facing the same direction. It is important to keep in mind what this model models, which are bacteria like E. coli., so in a way there is still some kind of feedback even if the bacteria ‚Äòtumbles‚Äô on the spot (it continues to go in a straight line)2.\n\n\nProject outline\nWe had a discussion on what the project should consist of (roughly speaking, since we are projecting into the future):\nFirst, there are a few things we want to focus on to characterise our model:\n\ntimescales\ncluster drift\npercolation\nŒ±\\alpha-œï\\phi diagram\npair correlations (orientation)\n\nThen, there comes to neural network component, where we construct a minimal CNN for two cases:\n\nwhere we ignore orientation (exp-like)\nwhere we include full information\n\nand compare between the two. Here, Rassolov (2022) is built upon Rassolov et al. (2022). We also define dissipation as the breaking of detailed balance, and there are some relations we can use to ‚Äòmeasure it‚Äô.\nThen, we validate the architecture in terms of how well it predicts. We keep in mind:\n\nthe number of layers, the feature map, other options\nhow much data it needs? Can we minimise\nhow much it can extrapolate?\n\nThen, we consider the explicability of the model and method.\n\nlook into feature maps and find correlations\ndoes it have the pair-correlations + more?\n\nAnd finally, we can also consider its robustness, which ties in prediction and explanation\n\n\nNotes from discussions\nShould we change how the tumbling algorithm works?\npcg32_boundedrand_r(rngptr, bound), bound to be set to 3, and tumbling should uniquely determine a new direction (not the one it‚Äôs currently on)3.\nWhy do we want to data bin it with log? Can get the relationship by finding the fit anyway without binning?4\nDissipation: breaking detailed balance, not spontaneous. - equilibrium limit: Œ±=1\\alpha=1 - PE=v/(Dr*œÉ)PE = v / (D_r * \\sigma) - PE=vr*Œ≥*œÉ/TPE = v_r * \\gamma * \\sigma / T - track-head on collisions possible? Need to modify source code too much.\n\n\n\n\nRassolov, Gregory, Laura Tociu, √âtienne Fodor, and Suriyanarayanan Vaikuntanathan. 2022. ‚ÄúFrom Predicting to Learning Dissipation from Pair Correlations of Active Liquids.‚Äù The Journal of Chemical Physics 157 (5): 054901. https://doi.org/10.1063/5.0097863."
  },
  {
    "objectID": "activity_log/week_7.html#footnotes",
    "href": "activity_log/week_7.html#footnotes",
    "title": "Week 7",
    "section": "",
    "text": "Link to Overleaf document.‚Ü©Ô∏é\nI don‚Äôt know if what I‚Äôm saying is actually correct, though.‚Ü©Ô∏é\nAfter some discussions with FT, seems like this is not quite right, the current method is fully intended (isotropy).‚Ü©Ô∏é\nBinning is recommended depending on the non-binned distribution, we should do it. Here‚Äôs a visual explanation.‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/landing.html",
    "href": "activity_log/landing.html",
    "title": "Activity log",
    "section": "",
    "text": "Week 1\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2023\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 3\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 4\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 5\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 6\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 7\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2023\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 8-13\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2024\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 14\n\n\n\n\n\n\n\n\n\n\n\nFeb 2, 2024\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 15\n\n\n\n\n\n\n\n\n\n\n\nFeb 12, 2024\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 16\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2024\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 17\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2024\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 18\n\n\n\n\n\n\n\n\n\n\n\nFeb 29, 2024\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 19\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 20\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2024\n\n\nNP\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "activity_log/week_5.html",
    "href": "activity_log/week_5.html",
    "title": "Week 5",
    "section": "",
    "text": "Most of this week was reading week for the school of arts so only set out to do a few things\nIn general, tasks to do up to week 9‚Äôs interim report is to carry on working on analysing the clusters.\n\nExamine size distribution over time for (Œ±,œï)(\\alpha, \\phi)\nExamine mean orientation over time for (Œ±,œï)(\\alpha, \\phi)\nMost of the time was spent writing code and getting used to the PEP codebase, so no plots to show here."
  },
  {
    "objectID": "activity_log/week_5.html#tasks",
    "href": "activity_log/week_5.html#tasks",
    "title": "Week 5",
    "section": "",
    "text": "Most of this week was reading week for the school of arts so only set out to do a few things\nIn general, tasks to do up to week 9‚Äôs interim report is to carry on working on analysing the clusters.\n\nExamine size distribution over time for (Œ±,œï)(\\alpha, \\phi)\nExamine mean orientation over time for (Œ±,œï)(\\alpha, \\phi)\nMost of the time was spent writing code and getting used to the PEP codebase, so no plots to show here."
  },
  {
    "objectID": "activity_log/week_5.html#summary",
    "href": "activity_log/week_5.html#summary",
    "title": "Week 5",
    "section": "Summary",
    "text": "Summary\nI moved to python 3.9.13 (module load lang/python/3.9.13) to use more recent features in matplotlib.\nI looked at what is being saved in the h5 binaries. Some remarks:\n\nFor all files, they have a length of 14000.\nEvery unique snapshot appears to ‚Äúroll‚Äù through the square grid 13 times\n\nI got this number from the size of np.arange(0,128,10), where 128 is just the size of the grid. This bit of code is in sampler.py and I‚Äôm not quite sure why the additional ‚Äúclones‚Äù are there. My guess is that it is for training?\n\n\n\nWhat to run to look into h5 files\nI did this in the python3 console. Import a random data file, can check with another one by repeating this whole process:\n\n\nCode\nimport os\nos.chdir(\"/project/persistent-exclusion-process/\")\n\nimport re\nimport h5py\n\nhf = h5py.File(\"no_roll_data/dataset_tumble_0.023_0.25.h5\", \"r\")\nprint(len(hf))  # gives 14000\nk = list(hf.keys())\nprint(k[:3])  # gives a bunch of strings like 'conf_9900_10'\n\n\n1000\n['conf_0', 'conf_10019', 'conf_10062']\n\n\nThe unique snapshots won‚Äôt have the last number, like conf_9820. To get the list of all iterations:\n\n\nCode\niter_n = []\nfor val in k:\n    if re.search(\"^conf_\\d+$\", val):\n        iter_n.append(int(val[5:]))\nprint(sorted(iter_n)[:10])  # gives sorted unique snapshots\n\n\n[0, 43, 86, 129, 172, 215, 258, 301, 344, 387]\n\n\nIf I want to plot the penultimate snapshot, I would retrieve that by doing something like:\nimg = hf[f\"conf_{sorted(iter_n[-2])}\"]\naxis.matshow(img, cmap=cmap)"
  },
  {
    "objectID": "activity_log/week_2.html",
    "href": "activity_log/week_2.html",
    "title": "Week 2",
    "section": "",
    "text": "Clone/fork and comment PEP repo1 (and add docstrings).\nWrite short intro (about 500 words) about why we study active matter, with references2."
  },
  {
    "objectID": "activity_log/week_2.html#tasks",
    "href": "activity_log/week_2.html#tasks",
    "title": "Week 2",
    "section": "",
    "text": "Clone/fork and comment PEP repo1 (and add docstrings).\nWrite short intro (about 500 words) about why we study active matter, with references2."
  },
  {
    "objectID": "activity_log/week_2.html#summary",
    "href": "activity_log/week_2.html#summary",
    "title": "Week 2",
    "section": "Summary",
    "text": "Summary\n\nThis week, the main task was to comb through introductory literature, and produce a writeup on motivation to study active matter.\nThere was also some code to comment and look through (from the persistent-exclusion-process (PEP) repo).\nThe other task was to sort out HPC access. CP & I have access to BlueCrystal and BluePebble now."
  },
  {
    "objectID": "activity_log/week_2.html#footnotes",
    "href": "activity_log/week_2.html#footnotes",
    "title": "Week 2",
    "section": "",
    "text": "PEP repo and forked version.‚Ü©Ô∏é\nSee Motivation report‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_15.html",
    "href": "activity_log/week_15.html",
    "title": "Week 15",
    "section": "",
    "text": "Play with different layers in Keras and train some models.\nMake some utility functions to reuse for training in training_utils.py (basically data preprocessing stuff).\nResearch CNNs."
  },
  {
    "objectID": "activity_log/week_15.html#tasks",
    "href": "activity_log/week_15.html#tasks",
    "title": "Week 15",
    "section": "",
    "text": "Play with different layers in Keras and train some models.\nMake some utility functions to reuse for training in training_utils.py (basically data preprocessing stuff).\nResearch CNNs."
  },
  {
    "objectID": "activity_log/week_15.html#summary",
    "href": "activity_log/week_15.html#summary",
    "title": "Week 15",
    "section": "Summary",
    "text": "Summary\nWe are currently doing this on our personal machines as doing interactive mode is not possible on BluePebble (unclear about BlueCrystal). Playing with the CNNs on a local notebook is the best method for now to be able to prototype quickly.\n\nBasics on the architecture of CNN\nWe feed our snapshots in, but to represent it as a tensor. Our snapshot has one channel depth, so the tensor shape is (128,128,1).\nWe start out with the convolutional layer. This layer performs a convolution, scanning the input with a number of filters with a smaller size than the input image itself, the size of the filter is determined by the kernel size. And the output of shape of the convolutional layer is of shape (128,128,N) where N is the number of filters applied.\n\nKernel size (x,y) is the window size that scans the image at each iteration.\nStride (x,y) is the step length to jump at each iteration.\nEach filter produces a feature map, every filter added captures more complex patterns.\nWe increase filter size with subsequent layers to capture more more combinations.\n\nA flatten layer will turn the input shape (x,y,c) into (x*y*c), i.e.¬†a 1D vector.\nA dense layer (or fully-connected), map all input neurons to output neurons. It takes in the number of units (neurons) and turn the input shape (x,y,c) into (x,y,units).\n\nLinear activation is pass-through (does nothing).\n\nA pooling layer reduces dimensions of the feature maps, which reduces the number of parameters. We have max pooling and average pooling (max takes maximum value from the kernel window and average takes the mean).\nA dropout layer randomly drops a fraction (the input parameter) of the input units to 0.\nA batch normalization layer normalizes the output. This helps with training speed.\nTo help reduce overfitting:\n\nIncrease training data\nUse pooling, batch normalization, and dropout layers\n\n\n\nClassifying our model/problem\nFor this week, we start building the network. Our network is a regression problem, predicting a continuous parameter, our tumbling rate Œ±\\alpha.\nFor this to work, we choose a loss function such as mean absolute error and mean squared error. We picked mean absolute error for now. This means the neural network will try and optimize this function, and this metric will be a good indication of how well we‚Äôve designed the architecture and everything surrounding it.\nThe equation for mean absolute error is:\nŒ¥=‚àëi=0N|yi‚àíyp|N,\n\\delta = \\frac{\\sum_{i=0}^{N}|y_i - y_p|}{N},\n\nwhere yiy_i is the actual value and ypy_p is the predicted value.\nEffectively, we want the model to minimise the mean absolute error (MAE from now on). From some precursor research, regression done on non-image data typically use only fully-connected layers. We have image data that we wish to apply convolution on, therefore we have to combine both.\nThe input is an image, but we have to output a 1D vector that maps to predictions for one parameter (continuous). To do this, we apply Flatten() and Dense(1, activation=\"linear\") at the end.\n\n\nInitial strategy\nWe begin with a simple model with one Conv2D layer, and train it on data that is not experimental-like, i.e.¬†orientation is still encoded as colours. We shall later consider training without this, or seeing the effect without it:\n\nA simple network to start with: Model A\nI used this in the single density notebook as the ‚Äúbasic‚Äù network:\nmodel = Sequential()\n\nmodel.add(\n    Conv2D(\n        filters=3,\n        kernel_size=(3, 3),\n        padding=\"same\",\n        strides=(3, 3),\n        activation=\"relu\",\n        input_shape=shape,\n    )\n)\nmodel.add(Flatten())\nmodel.add(Dense(units=1, activation=\"linear\"))\nWe compare this with a slightly more complicated one.\n\n\nA more complicated network: Model B\nBased on this blog post, where they work on a classification problem, so we need to be careful with the output1.\nmodel = Sequential()\n\nmodel.add(\n    Conv2D(\n        filters=3,\n        kernel_size=(3, 3),\n        padding=\"same\",\n        strides=(3, 3),\n        activation=\"relu\",\n        input_shape=shape,\n    )\n)\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\"))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\n\nmodel.add(Conv2D(filters=6, kernel_size=(3, 3), padding=\"same\"))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=6, kernel_size=(3, 3), padding=\"same\"))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\n\nmodel.add(Dense(units=128, activation=\"relu\"))\n\nwith options({\"layout_optimizer\": False}):\n    model.add(Dropout(0.2))\nmodel.add(Dense(units=10, activation=\"softmax\"))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=1, activation=\"linear\"))\nI was interested in the effect of dropout, so I used Model B with and without dropout to compare the results. We expect dropout to produce distributions that are more centred around the actual value.\n\n\n\nModel A trained on one density, predicting the same density.\n\n\nNumber of unique alpha:  10\nShape of x:  (10000, 128, 128, 1)\nShape of y:  (10000,)\nSize of training data:  8000\nSize of validation data:  2000\n\n\n\n\n1.0\n0.04027245\n0.08436323\n0.051214695\n0.8800811375901546\n\n\n\n\n\n\n\n\n\n\n\nModel B, trained on one density, predicting the same density\n\n\nCollected:  11020\n1.0\n0.0036920607\n0.0717594\n0.032156073\n0.9376105985517396\n\n\n\n\n\n\n\n\n\n\n\nModel B, without dropout layer, trained on one density, predicting the same density\n\n\nCollected:  12148\n1.0\n0.01220879\n0.0647896\n0.03377225\n0.9100308053552608\n\n\n\n\n\n\n\n\n\n\n\nPredicting novel densities\nWe previously trained on œï=0.15\\phi = 0.15 and try to predict the validation set also for the same œï\\phi. What happens if we try and predict it on a different value for œï\\phi? We expect it to still be somewhat accurate for a slightly different value, but not perform at all for very different value.\nWe think this is because there are thresholds for œï\\phi where the behaviour of cluster changes, they can consistently enter percolation regime (for high œï\\phi) and can have extremely big cluster sizes (also for high œï\\phi). This would present to the network novel situations not seen at œï=0.15\\phi = 0.15, where we don‚Äôt expect percolation as it is very unlikely.\nWe use œï=0.25\\phi = 0.25 for the ‚Äúslightly‚Äù different density and œï=0.45\\phi = 0.45 for the ‚Äúvery‚Äù different density. As of now we don‚Äôt have a metric to evaluate our model (this is planned for next week), so comparisons are done qualitatively.\n\n\nModel A on œï=0.25\\phi=0.25\n\n\nCollected:  13435\nNumber of unique alpha:  10\nShape of x:  (10000, 128, 128, 1)\nShape of y:  (10000,)\nSize of training data:  8000\nSize of validation data:  2000\n\n\n\n\n0.9\n0.056310352\n0.09474326\n0.07733949\n0.7240413106786887\n\n\n\n\n\n\n\n\n\n\n\nModel B on œï=0.25\\phi=0.25\n\n\nCollected:  12509\n1.0\n0.0038437229\n0.07215052\n0.032901235\n0.9577752110859448\n\n\n\n\n\n\n\n\n\n\n\nModel B, without dropout layer, on œï=0.25\\phi=0.25\n\n\nCollected:  11280\n1.0\n0.013498955\n0.08504163\n0.042217374\n0.9397948348732196\n\n\n\n\n\n\n\n\n\n\n\nModel A on œï=0.45\\phi=0.45\n\n\nCollected:  13630\nNumber of unique alpha:  10\nShape of x:  (10000, 128, 128, 1)\nShape of y:  (10000,)\nSize of training data:  8000\nSize of validation data:  2000\n\n\n\n\n0.2\n0.06198603\n0.089977786\n0.07721992\n0.3369544604797045\n\n\n\n\n\n\n\n\n\n\n\nModel B on œï=0.45\\phi=0.45\n\n\nCollected:  12664\n0.0\n0.0032266236\n0.052909803\n0.015262815\n0.9224203064863151\n\n\n\n\n\n\n\n\n\n\n\nModel B, without dropout layer, on œï=0.45\\phi=0.45\n\n\nCollected:  10330\n1.0\n0.013544914\n0.06589952\n0.02933981\n0.9244929021652859\n\n\n\n\n\n\n\n\n\n\n\nComparing Model A to Model B\n\nBoth seem to exhibit correlation to the actual values.\nModel A has significantly more spread than Model B\nDropout doesn‚Äôt reduce spread but make the average of each Œ±\\alpha less centred around the actual value.\nDropout adds a lot of spread to the first Œ±\\alpha.\nModel A performs poorly on œï‚â†0.15\\phi \\neq 0.15 (which it was trained on).\nModel B performs poorly only on œï=0.45\\phi = 0.45 (it does well on œï=0.25\\phi = 0.25)\nBut turning off dropout for B makes it perform better on œï=0.45\\phi = 0.45.\n\nDropout seems to reduce overfit by a lot. I don‚Äôt know if setting it to 0.2 here is too much dropout. In the next iteration of the network, I think we can work with 0.1."
  },
  {
    "objectID": "activity_log/week_15.html#footnotes",
    "href": "activity_log/week_15.html#footnotes",
    "title": "Week 15",
    "section": "",
    "text": "See also House price regression 1, House price regression 2, TF Regression tutorial, StackOverflow, StackOverflow 2, TDS pytorch on CNN to predict a continuous property, CNN with regression.‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_8.html",
    "href": "activity_log/week_8.html",
    "title": "Week 8-13",
    "section": "",
    "text": "Across these weeks were a mix of interim report writing, other coursework deadlines, as well as the winter break. Below are some tasks we could look at over the break. Because tasks were done sporadically, left and came back to, and not ordered across weeks, they are all included within one entry to make more sense."
  },
  {
    "objectID": "activity_log/week_8.html#task-for-week-8-12",
    "href": "activity_log/week_8.html#task-for-week-8-12",
    "title": "Week 8-13",
    "section": "Task for week 8-12",
    "text": "Task for week 8-12\n\nFinish and submit a draft interim report\nHave a chat with our assessor over our report"
  },
  {
    "objectID": "activity_log/week_8.html#task-for-the-break-up-to-week-13",
    "href": "activity_log/week_8.html#task-for-the-break-up-to-week-13",
    "title": "Week 8-13",
    "section": "Task for the break up to week 13",
    "text": "Task for the break up to week 13\n\nTest GPU on BluePebble1.\nFit the cluster size distribution2.\nLook at cluster distribution over time\n\nThis provides timescale for stationarity\nAlready doing the average, adapt code to do over time\n\nLook at percolation condition\n\nFor a given Œ±\\alpha, at what œï\\phi do you get a cluster that is as large as LL?\n\nRequires combing through may œï\\phi‚Äôs, which means combining our data3.\n\n\nLook at convergence of cluster distribution. (???)\nQuantify percolation4."
  },
  {
    "objectID": "activity_log/week_8.html#project-plan-and-outline",
    "href": "activity_log/week_8.html#project-plan-and-outline",
    "title": "Week 8-13",
    "section": "Project plan and outline",
    "text": "Project plan and outline\n\nCharacterisation: this is to set the landscape through PEP analysis, contrasted to a data-driven method with ML\n\ntimescales\ncluster drift\npercolation\nŒ±\\alpha-œï\\phi diagram\nPair correlations (linking with dissipation)5.\n\nConstruction: a minimal CNN model with two approaches\n\nignore orientation (experiment-like) and only using positions\nall information, positions and orientation\n\nValidation: of the architecture (in terms of prediction)\n\nnumber of layers, the feature map, options\nhow much data (can we minimise it?)\nhow does it extrapolate?\n\nExplainability\n\nlook into feature maps and find correlations\ndoes it have the pair-correlations + more? Check with these explicit ways of measuring dissipation\n\nRobustness:\n\nCan we get robustness?\n\nDifferent systems\nNon-steady state\nOff-lattice?"
  },
  {
    "objectID": "activity_log/week_8.html#tensorflow-and-gpu-testing",
    "href": "activity_log/week_8.html#tensorflow-and-gpu-testing",
    "title": "Week 8-13",
    "section": "Tensorflow and GPU testing",
    "text": "Tensorflow and GPU testing\nNeed to install tensorflow with CUDA like this\npip install tensorflow[and-cuda]\nInclude these directives to SLURM GPU jobs:\n#SBATCH --gres=gpu:2\n#SBATCH --partition gpu\nThis is the output of tf.config.list_physical_devices(\"GPU\"):\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1886\\]\n  Created device /device:GPU:0 with 9804 MB memory:\n  -&gt; device: 0, name: NVIDIA GeForce RTX 2080 Ti,\n  pci bus id: 0000:3b:00.0, compute capability: 7.5\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1886\\]\n  Created device /device:GPU:1 with 9804 MB memory:\n  -&gt; device: 1, name: NVIDIA GeForce RTX 2080 Ti,\n  pci bus id: 0000:af:00.0, compute capability: 7.5\nIn addition to this, I got weird errors and info even though the above works:\ncpu-bind=MASK - bp1-gpu002, task  0  0 [170146]: mask 0x2020 set\nE tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342]\n  Unable to register cuDNN factory: Attempting to register factory\n  for plugin cuDNN when one has already been registered\nE tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609]\n  Unable to register cuFFT factory: Attempting to register factory\n  for plugin cuFFT when one has already been registered\nE tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518]\n  Unable to register cuBLAS factory: Attempting to register factory\n  for plugin cuBLAS when one has already been registered\nI tensorflow/core/platform/cpu_feature_guard.cc:182]\n  This TensorFlow binary is optimized to use available CPU\n  instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other\noperations, rebuild TensorFlow with the appropriate compiler flags.\nImporting keras and other tensorflow modules seem to work fine. The error appears at the start. Maybe it might be an issue later on."
  },
  {
    "objectID": "activity_log/week_8.html#quantifying-percolation",
    "href": "activity_log/week_8.html#quantifying-percolation",
    "title": "Week 8-13",
    "section": "Quantifying percolation",
    "text": "Quantifying percolation\nHere was our initial assumption on percolation:\n\nPercolation: increase LL increases largest cluster size (physical dimension is the limiting factor).\nNo percolation: increase LL does not affect ‚Äúbiggest‚Äù cluster size.\n\nWe can‚Äôt implement this in code because we cannot modify physical dimension without making new datasets at different system sizes6.\n\nProblem\nThe issue with this approach is it doesn‚Äôt quite capture percolation, as what we care more about is the edge-to-edge connectedness. For this, we look not at its bulk size but its size from one edge to the other, and calculate its fractal dimension, which will indicate whether or not its smooth or has more complex details.\nBy only looking at the bulk size, we miss out on the details. At some point, we should return to this percolation analysis and calculate the fractal dimension as a link to percolation."
  },
  {
    "objectID": "activity_log/week_8.html#footnotes",
    "href": "activity_log/week_8.html#footnotes",
    "title": "Week 8-13",
    "section": "",
    "text": "See section Tensorflow and GPU testing.‚Ü©Ô∏é\nPlots here.‚Ü©Ô∏é\nSee section Quantifying percolation.‚Ü©Ô∏é\nPlots here.‚Ü©Ô∏é\nIf time allows.‚Ü©Ô∏é\nInstead, we looked at how œï\\phi affect the biggest cluster size, measured as the ratio to the system size.‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_17.html",
    "href": "activity_log/week_17.html",
    "title": "Week 17",
    "section": "",
    "text": "Between last week and this week, we tried to come up with some questions to answer, to piece together all the experimentation up to now.\n\n\n\nHypothesis: Cluster formation occurs when two particles collide head on (so left vs right and up vs down) and form the cluster seed. Due to exclusion, these seeds are jammed, until they tumble away. Hence at the center of the clusters, we expect the network to pick up on these (1-3, 2-4) configurations. At the edges, we expect particles to point towards the clusters. This means there is a difference between the ‚Äúcolourful‚Äù and the ‚Äúmonochromatic‚Äù one. Because of this, we expect the ‚Äúcross-prediction‚Äù (i.e.¬†taking a dataset with orientation and asking a model trained without orientation for predictions) to perform poorly, as the networks will be looking for something completely differently.\n\nExperiment 1a: inject into the model information on the 4 degrees of freedom and predict with and without this information (i.e.¬†merely positions, this is experiment-like).\n\nOutcome: Prediction without orientation performs much poorer compared to prediction with orientation.\nModels: magic7474, buckwheat3306\n\nExperiment 1b: train only on positions and predict on data with and without the degrees of freedom injected.\n\nOutcome: Prediction with orientation fails completely.\nModels: failing2399\n\n\n\n\nTrained on SGD, with a learning rate of 0.008, for 45 epochs.\n\n\n2024-02-29 17:49:13.302023: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-29 17:49:13.302093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-29 17:49:13.337158: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-02-29 17:49:13.415338: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-02-29 17:49:14.267255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\nWith the same data\n\n\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n\n\n2024-02-29 17:51:50.977357: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393216000 exceeds 10% of free system memory.\n\n\n188/188 [==============================] - 3s 16ms/step\nOverlap ratio: 0.7\n(Min, Max, Avg) STD: 0.0022416604 0.034824748 0.011316802\nPearson's correlation coeff:  0.992173827540833\nOverlap ratio: 0.7\n(Min, Max, Avg) STD: 0.0022416604 0.034824748 0.011316802\nPearson's correlation coeff:  0.992173827540833\n\n\n\n\n\n\n\n\n\nWith data where orientation is removed (binarized)\n\n\n  5/913 [..............................] - ETA: 13s 913/913 [==============================] - 14s 16ms/step\nOverlap ratio: 0.3\n(Min, Max, Avg) STD: 0.0 0.06442532 0.024747767\nPearson's correlation coeff:  0.13855496918568383\nOverlap ratio: 0.3\n(Min, Max, Avg) STD: 0.0 0.06442532 0.024747767\nPearson's correlation coeff:  0.13855496918568383\n\n\n2024-02-29 17:52:07.912672: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1913651200 exceeds 10% of free system memory.\n\n\n\n\n\n\n\n\n\nWith orientation removed, the model trained on orientation seems to overpredict the orientations, and cannot tell at all what‚Äôs happening at high Œ±\\alpha‚Äôs, where it cannot distinguish 0.231 and 0.340 from 0.500.\nTo visualize what‚Äôs going on, here are the snapshots at Œ±=0.340,0.500\\alpha = 0.340, 0.500:\n\n\n\n\n\n\n\n\n\nTo the human eyes, these are very similar. It is possible the network learns from the orientation here, seeing more 1-3 and 2-4 configurations for the lower values of Œ±\\alpha‚Äôs, since more clustering happens. This would mean removing orientation as information makes the network fail to distinguish.\nThe regime where it overpredicts is also interesting, although I‚Äôm not quite sure why this is happening.\nThe same kind of experiment, but with œï=0.4\\phi = 0.4 instead:\n\n\n\nWith the same data\n\n\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n  5/188 [..............................] - ETA: 2s 188/188 [==============================] - 3s 14ms/step\nOverlap ratio: 1.0\n(Min, Max, Avg) STD: 0.0020176726 0.03462249 0.01297331\nPearson's correlation coeff:  0.9852125254093039\nOverlap ratio: 1.0\n(Min, Max, Avg) STD: 0.0020176726 0.03462249 0.01297331\nPearson's correlation coeff:  0.9852125254093039\n\n\n2024-02-29 17:54:17.299810: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393216000 exceeds 10% of free system memory.\n\n\n\n\n\n\n\n\n\nOrientation added into data\n\n\n16/16 [==============================] - 0s 14ms/step\nOverlap ratio: 0.0\n(Min, Max, Avg) STD: 0.00018386112 0.0018590111 0.001102606\nPearson's correlation coeff:  0.9107537153185321\nOverlap ratio: 0.0\n(Min, Max, Avg) STD: 0.00018386112 0.0018590111 0.001102606\nPearson's correlation coeff:  0.9107537153185321\n\n\n\n\n\n\n\n\n\nAdding orientation to the snapshots makes the model completely fail to predict any meaningful Œ±\\alpha. It does not predict a single value within the accuracy defined. My guess is that the way the model has learned is to potentially only see blobs as clusters, so when individual pixels can be distinguished from their defining ‚Äúbrightness‚Äù (grayscale image with five values 0 (background), 0.25, 0.5, 0.75, 1), it cannot see them as clusters no longer. Instead, a lot of ‚Äúnoise‚Äù is now present. Yet, the model was not trained on noise, so it‚Äôs not surprising that it cannot handle noise.\n\n\n\nOverall, they perform the same, with loss and different metrics for standard deviation within a similar ball park figure:\n\nŒ¥MAE‚âà0.02\\delta_{\\mathrm{MAE}}\\approx 0.02\nœÉmax\\sigma_{\\mathrm{max}} in the range 0.04,0.050.04,0.05.\nœÉmean\\sigma_{\\mathrm{mean}} in the range 0.01,0.020.01,0.02.\nOverlap ratios are both 1.0.\nr‚âà0.99r \\approx 0.99.\n\nI think for experiment-like, it is best to inject noise into the training dataset1. Injecting noise reduces overfitting and increases robustness, as it is a form of augmentation2 3 4."
  },
  {
    "objectID": "activity_log/week_17.html#tasks",
    "href": "activity_log/week_17.html#tasks",
    "title": "Week 17",
    "section": "",
    "text": "Between last week and this week, we tried to come up with some questions to answer, to piece together all the experimentation up to now.\n\n\n\nHypothesis: Cluster formation occurs when two particles collide head on (so left vs right and up vs down) and form the cluster seed. Due to exclusion, these seeds are jammed, until they tumble away. Hence at the center of the clusters, we expect the network to pick up on these (1-3, 2-4) configurations. At the edges, we expect particles to point towards the clusters. This means there is a difference between the ‚Äúcolourful‚Äù and the ‚Äúmonochromatic‚Äù one. Because of this, we expect the ‚Äúcross-prediction‚Äù (i.e.¬†taking a dataset with orientation and asking a model trained without orientation for predictions) to perform poorly, as the networks will be looking for something completely differently.\n\nExperiment 1a: inject into the model information on the 4 degrees of freedom and predict with and without this information (i.e.¬†merely positions, this is experiment-like).\n\nOutcome: Prediction without orientation performs much poorer compared to prediction with orientation.\nModels: magic7474, buckwheat3306\n\nExperiment 1b: train only on positions and predict on data with and without the degrees of freedom injected.\n\nOutcome: Prediction with orientation fails completely.\nModels: failing2399\n\n\n\n\nTrained on SGD, with a learning rate of 0.008, for 45 epochs.\n\n\n2024-02-29 17:49:13.302023: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-29 17:49:13.302093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-29 17:49:13.337158: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-02-29 17:49:13.415338: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-02-29 17:49:14.267255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\nWith the same data\n\n\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n\n\n2024-02-29 17:51:50.977357: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393216000 exceeds 10% of free system memory.\n\n\n188/188 [==============================] - 3s 16ms/step\nOverlap ratio: 0.7\n(Min, Max, Avg) STD: 0.0022416604 0.034824748 0.011316802\nPearson's correlation coeff:  0.992173827540833\nOverlap ratio: 0.7\n(Min, Max, Avg) STD: 0.0022416604 0.034824748 0.011316802\nPearson's correlation coeff:  0.992173827540833\n\n\n\n\n\n\n\n\n\nWith data where orientation is removed (binarized)\n\n\n  5/913 [..............................] - ETA: 13s 913/913 [==============================] - 14s 16ms/step\nOverlap ratio: 0.3\n(Min, Max, Avg) STD: 0.0 0.06442532 0.024747767\nPearson's correlation coeff:  0.13855496918568383\nOverlap ratio: 0.3\n(Min, Max, Avg) STD: 0.0 0.06442532 0.024747767\nPearson's correlation coeff:  0.13855496918568383\n\n\n2024-02-29 17:52:07.912672: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1913651200 exceeds 10% of free system memory.\n\n\n\n\n\n\n\n\n\nWith orientation removed, the model trained on orientation seems to overpredict the orientations, and cannot tell at all what‚Äôs happening at high Œ±\\alpha‚Äôs, where it cannot distinguish 0.231 and 0.340 from 0.500.\nTo visualize what‚Äôs going on, here are the snapshots at Œ±=0.340,0.500\\alpha = 0.340, 0.500:\n\n\n\n\n\n\n\n\n\nTo the human eyes, these are very similar. It is possible the network learns from the orientation here, seeing more 1-3 and 2-4 configurations for the lower values of Œ±\\alpha‚Äôs, since more clustering happens. This would mean removing orientation as information makes the network fail to distinguish.\nThe regime where it overpredicts is also interesting, although I‚Äôm not quite sure why this is happening.\nThe same kind of experiment, but with œï=0.4\\phi = 0.4 instead:\n\n\n\nWith the same data\n\n\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n  5/188 [..............................] - ETA: 2s 188/188 [==============================] - 3s 14ms/step\nOverlap ratio: 1.0\n(Min, Max, Avg) STD: 0.0020176726 0.03462249 0.01297331\nPearson's correlation coeff:  0.9852125254093039\nOverlap ratio: 1.0\n(Min, Max, Avg) STD: 0.0020176726 0.03462249 0.01297331\nPearson's correlation coeff:  0.9852125254093039\n\n\n2024-02-29 17:54:17.299810: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393216000 exceeds 10% of free system memory.\n\n\n\n\n\n\n\n\n\nOrientation added into data\n\n\n16/16 [==============================] - 0s 14ms/step\nOverlap ratio: 0.0\n(Min, Max, Avg) STD: 0.00018386112 0.0018590111 0.001102606\nPearson's correlation coeff:  0.9107537153185321\nOverlap ratio: 0.0\n(Min, Max, Avg) STD: 0.00018386112 0.0018590111 0.001102606\nPearson's correlation coeff:  0.9107537153185321\n\n\n\n\n\n\n\n\n\nAdding orientation to the snapshots makes the model completely fail to predict any meaningful Œ±\\alpha. It does not predict a single value within the accuracy defined. My guess is that the way the model has learned is to potentially only see blobs as clusters, so when individual pixels can be distinguished from their defining ‚Äúbrightness‚Äù (grayscale image with five values 0 (background), 0.25, 0.5, 0.75, 1), it cannot see them as clusters no longer. Instead, a lot of ‚Äúnoise‚Äù is now present. Yet, the model was not trained on noise, so it‚Äôs not surprising that it cannot handle noise.\n\n\n\nOverall, they perform the same, with loss and different metrics for standard deviation within a similar ball park figure:\n\nŒ¥MAE‚âà0.02\\delta_{\\mathrm{MAE}}\\approx 0.02\nœÉmax\\sigma_{\\mathrm{max}} in the range 0.04,0.050.04,0.05.\nœÉmean\\sigma_{\\mathrm{mean}} in the range 0.01,0.020.01,0.02.\nOverlap ratios are both 1.0.\nr‚âà0.99r \\approx 0.99.\n\nI think for experiment-like, it is best to inject noise into the training dataset1. Injecting noise reduces overfitting and increases robustness, as it is a form of augmentation2 3 4."
  },
  {
    "objectID": "activity_log/week_17.html#footnotes",
    "href": "activity_log/week_17.html#footnotes",
    "title": "Week 17",
    "section": "",
    "text": "Noise to reduce overtting‚Ü©Ô∏é\nData Augmentation in Training CNNS: Injecting Noise to Images‚Ü©Ô∏é\nIncrease robustness with noise‚Ü©Ô∏é\nNoise models for CNNs‚Ü©Ô∏é"
  },
  {
    "objectID": "shared/ftnotes/label.html",
    "href": "shared/ftnotes/label.html",
    "title": "Minimal cluster analysis",
    "section": "",
    "text": "Code\nfrom scipy import ndimage\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nI create a random binary image (through thresholding).\n\n\nCode\nimage = np.random.uniform(0, 1, (128, 128))\nim = (image &gt; 0.8).astype(int)\n\nplt.matshow(im)\n\n\n\n\n\n\n\n\n\nI can then label connected regions, by specifying the structuring element (kernel).\n\n\nCode\nkernel = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]\nlabelled, nlabels = ndimage.label(im, structure=kernel)\n\n\n\n\nCode\nplt.imshow(labelled, cmap=plt.cm.rainbow)\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nI count the number of pixels with a certain label (ignoring label 0 because it is the background)\n\n\nCode\ncluster_sizes = np.bincount(labelled.flatten())[1:]\n\n\nAnd plot the probability distribution with logarithmically spaced bins\n\n\nCode\nminimum = cluster_sizes.min()\nmaximum = cluster_sizes.max()\nbin_edges = np.logspace(np.log2(minimum), np.log2(maximum), 32, base=2)\nhist, edges = np.histogram(cluster_sizes, bins=bin_edges, density=True)\nplt.plot(2 ** bin_edges[:-1], hist, \"o\")\nplt.yscale(\"log\")\nplt.xscale(\"log\")\nplt.xlabel(\"cluster sizes\")\nplt.ylabel(\"pdf\")\n\n\nText(0, 0.5, 'pdf')"
  },
  {
    "objectID": "shared/repo.html",
    "href": "shared/repo.html",
    "title": "Repository information",
    "section": "",
    "text": "A brief guide on how to setup this website elsewhere and develop the wiki."
  },
  {
    "objectID": "shared/repo.html#forking",
    "href": "shared/repo.html#forking",
    "title": "Repository information",
    "section": "Forking",
    "text": "Forking\n\nIf using a Codeberg account, fork this repo.\nIf using a GitHub account, fork this repo."
  },
  {
    "objectID": "shared/repo.html#local-development",
    "href": "shared/repo.html#local-development",
    "title": "Repository information",
    "section": "Local development",
    "text": "Local development\nIt‚Äôs recommended to use SSH and SSH keys when working with a remote git.\n\nKey generating instructions are found here (this is git-server agnostic).\nFor GitHub, follow this to add your key.\nFor Codeberg, it‚Äôs similar, navigate to this link when logged in, and then Add key under the Manage SSH Keys section.\n\nClone the repo locally:\n\nFor Codeberg:\n\ngit clone git@codeberg.org:&lt;user&gt;/msci-wiki.git\n\nFor GitHub:\n\ngit clone git@github.com:&lt;user&gt;/msci-wiki.git"
  },
  {
    "objectID": "shared/repo.html#managing-branches-and-commits",
    "href": "shared/repo.html#managing-branches-and-commits",
    "title": "Repository information",
    "section": "Managing branches and commits",
    "text": "Managing branches and commits\nMake a new branch to build your own website from with\ngit checkout -b &lt;make_your_own_unique_name&gt;\nThis branch will contain individual work + shared stuff. It should be the source of truth.\nFrom now on, we will refer to this branch as my_branch.\nWhen contributing to shared knowledge, switch to shared branch with git checkout shared. In this branch, there should be only one directory called shared. This is the root folder of all shared information. Any further directory structuring occurs within this, not outside of it.\n\nNo individual work goes into the shared branch to avoid conflicts with filenames!\n\nWhen merging new commits containing shared information from shared to my_branch, switch to my_branch with git checkout my_branch, and then perform a merge with\ngit merge shared\n\nDon‚Äôt merge from my_branch to shared!\n\nIn the case there are problematic commits in shared, future merge can be done with cherry-pick. Say this is shared:\nSHA0 (HEAD): I want this commit\nSHA1: I don't want this commit\nSHA2: I want this commit\nThen, in my_branch:\ngit cherry-pick SHA2\ngit cherry-pick SHA0"
  },
  {
    "objectID": "shared/repo.html#initialise-a-quarto-project",
    "href": "shared/repo.html#initialise-a-quarto-project",
    "title": "Repository information",
    "section": "Initialise a Quarto project",
    "text": "Initialise a Quarto project\nIn my_branch, make a new Quarto project with the website template:\nquarto create project website\nTake a look at _quarto.yml from branch np for an example of how to configure it."
  },
  {
    "objectID": "shared/repo.html#building-pages",
    "href": "shared/repo.html#building-pages",
    "title": "Repository information",
    "section": "Building pages",
    "text": "Building pages\nQuarto by default publishes to the branch gh-pages.\nTo build the pages, first, run the following:\nquarto publish gh-pages\nThis will build and push to the gh-pages branch.\n\nIf using GitHub, that‚Äôs all you need to do.\nIf using Codeberg, you can view it by going to https://username.codeberg.page/@gh-pages"
  },
  {
    "objectID": "shared/repo.html#push-the-changes",
    "href": "shared/repo.html#push-the-changes",
    "title": "Repository information",
    "section": "Push the changes",
    "text": "Push the changes\nPushing changes to remote servers make rolling back very difficult, make sure everything looks correct first. Use git log and git status to ensure everything has been committed. To push everything to a mirror:\ngit push &lt;remote&gt; &lt;branch&gt;\nTry to keep all branches up-to-date on all mirrors!"
  },
  {
    "objectID": "shared/repo.html#accessing-the-live-website",
    "href": "shared/repo.html#accessing-the-live-website",
    "title": "Repository information",
    "section": "Accessing the live website",
    "text": "Accessing the live website\n\nFor Codeberg, it‚Äôs https://username.codeberg.page/msci-wiki/@gh-pages (more information).\nFor GitHub, it‚Äôs https://username.github.io/msci-wiki (more information)."
  },
  {
    "objectID": "shared/deadlines.html",
    "href": "shared/deadlines.html",
    "title": "Deadline information",
    "section": "",
    "text": "TB1: Thursday 11:00\nTB2: to be decided"
  },
  {
    "objectID": "shared/deadlines.html#weekly-meeting",
    "href": "shared/deadlines.html#weekly-meeting",
    "title": "Deadline information",
    "section": "",
    "text": "TB1: Thursday 11:00\nTB2: to be decided"
  },
  {
    "objectID": "shared/deadlines.html#deadlines",
    "href": "shared/deadlines.html#deadlines",
    "title": "Deadline information",
    "section": "Deadlines",
    "text": "Deadlines\n\nWeek 9: Interim report submitted\nWeek 11/12: Feedback on progress so far\nWeek 18: Practical work finished\nWeek 19/20: Analysis of results finished. Start of report write up. Results presented\nWeek 22: Final reports submitted\nWeek 24/25: Final interviews"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dissipation Learning in Active Matter - Project notebook",
    "section": "",
    "text": "CNN logbook\nZotero library\nPEP repository\n\n\n\n\n\n\n\n\nWatch the wiki repository for information on data release1."
  },
  {
    "objectID": "index.html#external-links",
    "href": "index.html#external-links",
    "title": "Dissipation Learning in Active Matter - Project notebook",
    "section": "",
    "text": "CNN logbook\nZotero library\nPEP repository\n\n\n\n\n\n\n\n\nWatch the wiki repository for information on data release1."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Dissipation Learning in Active Matter - Project notebook",
    "section": "",
    "text": "README.md‚Ü©Ô∏é"
  },
  {
    "objectID": "plots/snapshot.html",
    "href": "plots/snapshot.html",
    "title": "Dissipation Learning in Active Matter",
    "section": "",
    "text": "Code\nimport os\nos.chdir(\"/project/persistent-exclusion-process\")\n\nfrom src.utils import get_ds_iters\nfrom src.plot_utils import get_plot_configs\n\nimport h5py\nimport glob\n\nfrom scipy import ndimage\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\nfrom mpl_toolkits.axes_grid1.inset_locator import mark_inset\n\nplot_configs = get_plot_configs()\nplot_configs[\"xtick.labelsize\"] = 12\nplot_configs[\"ytick.labelsize\"] = 12\nplt.rcParams.update(plot_configs)\n\n\n\n\nCode\nhf = h5py.File(\"no_roll_data/dataset_tumble_0.016_0.4.h5\", \"r\")\niters = get_ds_iters(hf.keys())\nimg = hf[f\"conf_{iters[-10]}\"]\nimg = np.array(img)\n\n\n\n\nCode\nfig, (axis) = plt.subplots(\n    1,\n    1,\n    figsize=(5, 5),\n    constrained_layout=True\n)\naxis.set(xticks=[], yticks=[])\nm = axis.imshow(img, cmap='cubehelix',\n             origin=\"upper\")\n#plt.colorbar(mappable=m)\nax = zoomed_inset_axes(axis, 8, loc=3)\n#ax.set_axes_locator(InsetPosition(axis, [0.7, 0.7, 0.2, 0.2]))\nax.set(xticklabels=[],yticklabels=[])\nax.imshow(img, cmap='cubehelix',\n             origin=\"upper\")\nax.set_ylim([63,58])\nax.set_xlim([40,45])\n_patch, pp1, pp2 = mark_inset(axis, ax, loc1=2, loc2=4, fc=\"none\", ec=\"r\", lw=1.5)\n \npp1.loc1, pp1.loc2 = 2, 3  # inset corner 1 to origin corner 4 (would expect 1)\npp2.loc1, pp2.loc2 = 4, 1  # inset corner 3 to origin corner 2 (would expect 3)\nplt.setp(ax.spines.values(), color=\"r\", lw=1.5)\n# \"‚Üë\",\"‚Üì\",\"‚Üê\",\"‚Üí\"\nax.plot([42.5,42.5,43.5,43.5,42.5],[61.5,60.5,60.5,61.5,61.5], c='r', lw=1)\nax.text(s=\"‚Üë\", x=42.8, y=61.2, fontsize=15, transform=ax.transData, c='r')\nax.plot([42.5,42.5,43.5,43.5,42.5],[60.5,59.5,59.5,60.5,60.5], c='r', lw=1)\nax.text(s=\"‚Üì\", x=42.8, y=60.15, fontsize=15, transform=ax.transData, c='r')\nax.plot([41.5,41.5,42.5,42.5,41.5],[61.5,60.5,60.5,61.5,61.5], c='r', lw=1)\nax.text(s=\"‚Üí\", x=41.6, y=61.2, fontsize=15, transform=ax.transData, c='r')\nax.plot([43.5,43.5,44.5,44.5,43.5],[59.45,58.45,58.45,59.45,59.45], c='r', lw=1)\nax.text(s=\"‚Üê\", x=43.62, y=59.15, fontsize=15, transform=ax.transData, c='r')\n\n\nText(43.62, 59.15, '‚Üê')\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig.savefig(\"plots/a_snapshot.pdf\",bbox_inches='tight')"
  },
  {
    "objectID": "plots/landing.html",
    "href": "plots/landing.html",
    "title": "Plots",
    "section": "",
    "text": "Stability check\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of cluster and biggest cluster size\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nCNN analysis\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nCluster distribution grid\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nSnapshot evolution\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nCluster manipulation (orientation analysis)\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of clusters\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nPercolation check\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nRatio of biggest cluster over density\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "plots/csize_grid.html",
    "href": "plots/csize_grid.html",
    "title": "Cluster distribution grid",
    "section": "",
    "text": "Full code"
  },
  {
    "objectID": "plots/csize_grid.html#get-all-points",
    "href": "plots/csize_grid.html#get-all-points",
    "title": "Cluster distribution grid",
    "section": "Get all points",
    "text": "Get all points\n\n\nCode\ndef save_points():\n    densities = [0.15,0.25,0.35,0.45]\n    tumbles = [0.016,0.073,0.340]\n\n    sizes = []\n    ds = []\n    ts = []\n    \n    for idx, d in enumerate(densities):\n        for jdx, t in enumerate(tumbles):\n            file = f\"no_roll_data/dataset_tumble_{t:.3f}_{d}.h5\"\n            all_cs = np.array([])\n            for idx2 in range(500,1000,1):\n                labelled, nlabels = get_cluster_labels(file, idx2)\n                lb = labelled.flatten()\n                cs = np.bincount(labelled.flatten())[1:]\n                all_cs = np.hstack((all_cs,cs))\n            ds.append(d)\n            ts.append(t)\n            sizes.append(all_cs.tolist())\n    csv_out = pd.DataFrame()\n    csv_out.insert(0, \"alphas\", ts)\n    csv_out.insert(1, \"phis\", ds)\n    csv_out.insert(2, \"sizes\", sizes)\n    csv_out.to_csv(f\"cache/cluster_distribution.csv\")"
  },
  {
    "objectID": "plots/csize_grid.html#binning-check",
    "href": "plots/csize_grid.html#binning-check",
    "title": "Cluster distribution grid",
    "section": "Binning check",
    "text": "Binning check\n\n\nCode\nc = np.array(ast.literal_eval(df['sizes'][0]), dtype=int)\nc = c[c!=0]\nmin_c = np.min(c)\nmax_c = np.max(c)\nbin_edges = np.logspace(np.log2(min_c), np.log2(max_c), 64, base=2)\ncount, _ = np.histogram(\n    c, bins=bin_edges, density=True\n)\nplt.scatter(bin_edges[1:], count)\nplt.axvline(128)\nplt.xscale('log'), plt.yscale('log')"
  },
  {
    "objectID": "plots/csize_grid.html#old-plots",
    "href": "plots/csize_grid.html#old-plots",
    "title": "Cluster distribution grid",
    "section": "Old plots",
    "text": "Old plots"
  },
  {
    "objectID": "plots/csize_grid.html#new-plot",
    "href": "plots/csize_grid.html#new-plot",
    "title": "Cluster distribution grid",
    "section": "New plot",
    "text": "New plot"
  },
  {
    "objectID": "plots/cnn_summary.html",
    "href": "plots/cnn_summary.html",
    "title": "CNN analysis",
    "section": "",
    "text": "Full code"
  },
  {
    "objectID": "plots/cnn_summary.html#old-cnn-plots",
    "href": "plots/cnn_summary.html#old-cnn-plots",
    "title": "CNN analysis",
    "section": "Old CNN plots",
    "text": "Old CNN plots\n\n\nText(0.58, 0.33, '(B3) $\\\\phi = 0.50$')"
  },
  {
    "objectID": "plots/cnn_summary.html#iqr-and-median-residual-analysis-across-categories",
    "href": "plots/cnn_summary.html#iqr-and-median-residual-analysis-across-categories",
    "title": "CNN analysis",
    "section": "IQR and median residual analysis across categories",
    "text": "IQR and median residual analysis across categories\n\n\n\n\n\n\n\n\n\n\ngradient\nintercept\ndensity\n\n\n\n\n0\n0.005228\n0.027753\n0.25\n\n\n1\n0.004492\n0.024347\n0.25\n\n\n2\n0.003951\n0.021785\n0.25\n\n\n3\n0.035502\n0.103532\n0.25\n\n\n4\n0.037269\n0.102676\n0.25\n\n\n\n\n\n\n\n\n\n\nCode\nprint(\n    (\n        np.array(fits[fits.density == 0.25][3:][\"gradient\"])\n        / np.array(fits[fits.density == 0.25][:3][\"gradient\"])\n    ),\n    np.mean(\n        np.array(fits[fits.density == 0.25][3:][\"gradient\"])\n        / np.array(fits[fits.density == 0.25][:3][\"gradient\"])\n    ),\n    np.std(\n        np.array(fits[fits.density == 0.25][3:][\"gradient\"])\n        / np.array(fits[fits.density == 0.25][:3][\"gradient\"])\n    ),\n)\n\n\n[6.79044274 8.29697111 8.92616137] 8.004525075190188 0.8960904088730705\n\n\nAn 8 times increase in gradient for higher tumbling rates!\nNow, calculate the median residual from actual value:\n\n\nCode\ntumbles = np.logspace(-6, 1, 10, base=2)\ndf_before = pd.read_csv(\"cache/model_summary.csv\")\n\n\n\n\nCode\na = np.abs(\n    np.array(\n        df_before.query('Context == \"Trained with orientation\"')\n        .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n        .median()[\"Predicted\"]\n        - tumbles\n    )\n)\nb = np.abs(\n    np.array(\n        df_before.query('Context == \"Trained without orientation\"')\n        .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n        .median()[\"Predicted\"]\n        - tumbles\n    )\n)\nc = np.abs(\n    np.array(\n        df_before.query('Context == \"Trained with thresholding\"')\n        .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n        .median()[\"Predicted\"]\n        - tumbles\n    )\n)\nprint(np.mean(a[:6]), a[:6].ptp() / 2)\nprint(np.mean(b[:6]), b[:6].ptp() / 2)\nprint(np.mean(c[:6]), c[:6].ptp() / 2)\n\n\n0.03762587323326023 0.05972326155383203\n0.03906283973326024 0.06109300030383203\n0.03905561981659356 0.06042071430383203\n\n\nNo substantial difference between the three catgories are found."
  },
  {
    "objectID": "plots/cnn_summary.html#iqr-changes-when-going-to-higher-packing-fraction",
    "href": "plots/cnn_summary.html#iqr-changes-when-going-to-higher-packing-fraction",
    "title": "CNN analysis",
    "section": "IQR changes when going to higher packing fraction",
    "text": "IQR changes when going to higher packing fraction\n\n\nCode\ndf_before = pd.read_csv(\"cache/model_summary.csv\")\ndf_after = pd.read_csv(\"cache/model_summary_hi.csv\")\ndf_analysis = pd.DataFrame(\n    {\n        \"IQR changes\": np.concatenate(\n            (\n                (\n                    df_after.query('Context == \"Trained with orientation\"')\n                    .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                    .agg(iqr)[\"Predicted\"]\n                    - df_before.query('Context == \"Trained with orientation\"')\n                    .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                    .agg(iqr)[\"Predicted\"]\n                )\n                / df_before.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .agg(iqr)[\"Predicted\"],\n                (\n                    df_after.query('Context == \"Trained without orientation\"')\n                    .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                    .agg(iqr)[\"Predicted\"]\n                    - df_before.query('Context == \"Trained without orientation\"')\n                    .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                    .agg(iqr)[\"Predicted\"]\n                )\n                / df_before.query('Context == \"Trained without orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .agg(iqr)[\"Predicted\"],\n                (\n                    df_after.query('Context == \"Trained with thresholding\"')\n                    .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                    .agg(iqr)[\"Predicted\"]\n                    - df_before.query('Context == \"Trained with thresholding\"')\n                    .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                    .agg(iqr)[\"Predicted\"]\n                )\n                / df_before.query('Context == \"Trained with thresholding\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .agg(iqr)[\"Predicted\"],\n            )\n        ),\n        \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 3),\n        \"Context\": (\n            [\"Trained with orientation\"] * 10\n            + [\"Trained without orientation\"] * 10\n            + [\"Trained with thresholding\"] * 10,\n        ),\n    }\n)\n\n\n\nLow tumbling rates\n\n\nCode\nx = df_analysis.query(\n    'Context == \"Trained with orientation\"'\n    ).groupby(\n        \"Actual\",\n        s_index=False\n    )[\"IQR changes\"].head()[:6]\ny = df_analysis.query(\n        'Context == \"Trained without orientation\"'\n    ).groupby(\n        \"Actual\",\n        as_index=False\n    )[\"IQR changes\"].head()[:6]\nz = df_analysis.query(\n        'Context == \"Trained with thresholding\"'\n    ).groupby(\n        \"Actual\",\n        as_index=False\n    )[\"IQR changes\"].head()[:6]\nsummary = np.array([x,y,z])\nprint(summary.mean()*100, summary.std()*100)\n\n\n2.7292093511099234 18.01397230945069\n\n\nSeems like IQR worsens a bit here, but insignificant (plus very high variance in the changes so it‚Äôs not really saying anything)."
  },
  {
    "objectID": "plots/cnn_summary.html#high-tumbling-rates",
    "href": "plots/cnn_summary.html#high-tumbling-rates",
    "title": "CNN analysis",
    "section": "High tumbling rates",
    "text": "High tumbling rates\n\n\nCode\nx = df_analysis.query(\n        'Context == \"Trained with orientation\"'\n    ).groupby(\n        \"Actual\",\n        as_index=False\n    )[\"IQR changes\"].head()[6:]\ny = df_analysis.query(\n        'Context == \"Trained without orientation\"'\n    ).groupby(\n        \"Actual\",\n        as_index=False\n    )[\"IQR changes\"].head()[6:]\nz = df_analysis.query(\n        'Context == \"Trained with thresholding\"'\n    ).groupby(\n        \"Actual\",\n        as_index=False\n    )[\"IQR changes\"].head()[6:]\nsummary = np.array([x,y,z])\nprint(summary.mean()*100, summary.std()*100)\n\n\n-23.074341173645955 7.258581821492993\n\n\nThere is a big improvement in the IQR, and the STD of the change is small compared to the change itself."
  },
  {
    "objectID": "plots/cnn_summary.html#mean-residual-variance-across-all-categories-at-a-higher-packing-fraction",
    "href": "plots/cnn_summary.html#mean-residual-variance-across-all-categories-at-a-higher-packing-fraction",
    "title": "CNN analysis",
    "section": "Mean residual variance across all categories at a higher packing fraction",
    "text": "Mean residual variance across all categories at a higher packing fraction\nCalculate the variance between the residual (median - actual) averaged across tumbling rates and categories:\n\n\nCode\na = np.abs(\n    np.array(\n        df_before.query('Context == \"Trained with orientation\"')\n        .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n        .median()[\"Predicted\"]\n        - tumbles\n    )\n)\nb = np.abs(\n    np.array(\n        df_before.query('Context == \"Trained without orientation\"')\n        .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n        .median()[\"Predicted\"]\n        - tumbles\n    )\n)\nc = np.abs(\n    np.array(\n        df_before.query('Context == \"Trained with thresholding\"')\n        .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n        .median()[\"Predicted\"]\n        - tumbles\n    )\n)\ntot = np.array([a, b, c])\nstd = tot.ptp(axis=0)\n\n\n\n\nCode\na2 = np.abs(\n    np.array(\n        df_after.query('Context == \"Trained with orientation\"')\n        .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n        .median()[\"Predicted\"]\n        - tumbles\n    )\n)\nb2 = np.abs(\n    np.array(\n        df_after.query('Context == \"Trained without orientation\"')\n        .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n        .median()[\"Predicted\"]\n        - tumbles\n    )\n)\nc2 = np.abs(\n    np.array(\n        df_after.query('Context == \"Trained with thresholding\"')\n        .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n        .median()[\"Predicted\"]\n        - tumbles\n    )\n)\ntot2 = np.array([a2, b2, c2])\nstd2 = tot2.ptp(axis=0)\n\n\nEliminate some outliers\n\n\nCode\nf = ((std2 - std)/std)\nfo = np.array([f[3],f[6]])\nbo = fo.std()\nprint(fo.mean(),bo)\nfc = np.concatenate((f[:3], f[4:6], f[7:]))\nbc = fc.std()\nprint(fc.mean(),bc)\n\n\n0.1093539437083822 0.4239089399598512\n-0.5309963242493272 0.22287041094959653\n\n\nSo the variance in residuals decreased when going to higher packing fractions."
  },
  {
    "objectID": "plots/cnn_summary.html#new-cnn-plots",
    "href": "plots/cnn_summary.html#new-cnn-plots",
    "title": "CNN analysis",
    "section": "New CNN plots",
    "text": "New CNN plots"
  },
  {
    "objectID": "plots/labelling.html",
    "href": "plots/labelling.html",
    "title": "Cluster manipulation (orientation analysis)",
    "section": "",
    "text": "Full code"
  },
  {
    "objectID": "plots/labelling.html#functions-for-orientation-analysis",
    "href": "plots/labelling.html#functions-for-orientation-analysis",
    "title": "Cluster manipulation (orientation analysis)",
    "section": "Functions for orientation analysis",
    "text": "Functions for orientation analysis\n\n\nCode\ndef plot_labelled_cluster(axis, file, sshot_idx):\n    cmap_label = plt.get_cmap(name=\"gnuplot\")\n    labelled, _ = get_cluster_labels(file, sshot_idx)\n    axis.matshow(labelled, cmap=cmap_label)\n    return axis\n\n\ndef get_biggest_cluster(img):\n    kernel = [[0, 1, 0], [1, 1, 1], [0, 1, 0]]\n    labelled, _ = ndimage.label(img, structure=kernel)\n    lb = labelled.flatten()\n    cluster_sizes = np.bincount(lb)[1:]\n    biggest_cluster_id = np.argmax(cluster_sizes)\n    loc = ndimage.find_objects(labelled)[biggest_cluster_id]\n    labelled_crop = labelled[loc]\n    img_crop = img[loc]\n    labelled_crop[labelled_crop != biggest_cluster_id+1] = 0\n    labelled_crop[labelled_crop == biggest_cluster_id+1] = 1\n    img_crop *= labelled_crop\n    return img_crop, ndimage.center_of_mass(labelled_crop)\n\ndef get_edges(img,axis):\n    img_threshold = np.zeros_like(img)\n    img_threshold[img &gt; 0] = 1\n    edges = ndimage.sobel(img_threshold, axis=axis)\n    #edges[edges &gt; -2] = 0\n    #edges[edges != 0] = 1\n    edges *= img\n    return edges\n\ndef map_ori(ori):\n    ori_mapped = np.zeros_like(ori, dtype=np.float_)\n    ori_mapped[ori == 1] = np.pi\n    ori_mapped[ori == 2] = np.pi/2\n    ori_mapped[ori == 3] = 0\n    ori_mapped[ori == 4] = -np.pi/2\n    return ori_mapped\n\n\ndef map_ori_human(ori):\n    ori_mapped = np.zeros_like(ori, dtype=np.dtype('U100'))\n    ori_mapped[ori == 3] = \"Down\"\n    ori_mapped[ori == 2] = \"Right\"\n    ori_mapped[ori == 1] = \"Up\"\n    ori_mapped[ori == 4] = \"Left\"\n    return ori_mapped\n\n\n# 0: y, 1: x\ndef get_ori_and_loc(edges,com):\n    positions = edges.nonzero()\n    edges_ori = map_ori(edges[positions[0],positions[1]])\n    edges_loc = np.arctan2((com[0]-positions[0]),(positions[1]-com[1]))\n\n    # CHECK CODE\n    # colors = ListedColormap([\"k\", \"r\", \"yellow\", \"g\", \"b\"])\n    # edges[edges == 0] = -4\n    # edges[positions[0],positions[1]] = edges_loc\n    plt.matshow(edges)\n    plt.colorbar()\n    plt.axvline(com[1], c='w')\n    plt.axhline(com[0], c='w')\n\n    return edges_ori, edges_loc"
  },
  {
    "objectID": "plots/labelling.html#labelling-fix",
    "href": "plots/labelling.html#labelling-fix",
    "title": "Cluster manipulation (orientation analysis)",
    "section": "Labelling fix",
    "text": "Labelling fix\nShould see labelling work with periodic boundary conditions now"
  },
  {
    "objectID": "plots/labelling.html#orientation-plots",
    "href": "plots/labelling.html#orientation-plots",
    "title": "Cluster manipulation (orientation analysis)",
    "section": "Orientation plots",
    "text": "Orientation plots"
  },
  {
    "objectID": "plots/labelling.html#other-types-of-plots",
    "href": "plots/labelling.html#other-types-of-plots",
    "title": "Cluster manipulation (orientation analysis)",
    "section": "Other types of plots",
    "text": "Other types of plots"
  },
  {
    "objectID": "plots/labelling.html#another-alpha",
    "href": "plots/labelling.html#another-alpha",
    "title": "Cluster manipulation (orientation analysis)",
    "section": "Another alpha",
    "text": "Another alpha"
  },
  {
    "objectID": "plots/acf.html",
    "href": "plots/acf.html",
    "title": "Stability check",
    "section": "",
    "text": "Full code"
  },
  {
    "objectID": "plots/acf.html#plotting-average-snapshots",
    "href": "plots/acf.html#plotting-average-snapshots",
    "title": "Stability check",
    "section": "Plotting average snapshots",
    "text": "Plotting average snapshots\n\n\nCode\ntumbles = np.logspace(-6, -1, 10, base=2)\nfor i in tumbles[::4]:\n    hf = h5py.File(f\"no_roll_data/dataset_tumble_{i:.3f}_0.25.h5\")\n    data = [\n        hf[i][:] for i in np.array(\n            sorted(list(hf.keys()),\n                   key=lambda x: int(x[5:])\n                  )\n        )\n    ]\n    data = np.array(data)\n    con = np.concatenate(\n        (\n            data,\n            np.roll(data, (42, 42), axis=(1, 2)),\n            np.roll(data, (120, 120), axis=(1, 2)),\n        )\n    )\n    plt.matshow(np.mean(con, axis=0) / np.max(con), cmap=\"cmc.bamako\")\n    plt.colorbar()"
  },
  {
    "objectID": "plots/acf.html#acf-code",
    "href": "plots/acf.html#acf-code",
    "title": "Stability check",
    "section": "ACF code",
    "text": "ACF code\n\n\nCode\ndef overlap(traj,i,j):\n    return ((traj[i]&gt;0)*(traj[j]&gt;0)).mean()\n\n\n\n\nCode\ntumbles = np.logspace(-6, -1, 10, base=2)\nlags = np.arange(0, 100 + 1, 1)\nts = []\nacfs = []\n\nfor t in tumbles:\n    hf = h5py.File(f'no_roll_data/dataset_tumble_{t:.3f}_0.25.h5')\n    data = [ hf[i][:] for i in natsort.natsorted(list(hf.keys()))]\n    data = np.array(data)\n    acf =[]\n    # moving window size 10, 50 times\n    for i in range(0, 500, 10):\n        a = [overlap(data,i,i+lag) for lag in lags]\n        acf.append(a)\n    acf = np.asarray(acf).mean(axis=0) # mean across all lag\n    acf = acf-0.25**2\n    acf/= 0.25 - 0.25**2 # divide by its range\n    acfs.append(acf)\n    ts.append(np.repeat(t,len(lags)))\n\n\n\n\nCode\nacfs = np.array(acfs).flatten()\nts = np.array(ts).flatten()\ndf = pd.DataFrame()\ndf.insert(0, \"lags\", np.tile(lags,10))\ndf.insert(1, \"acfs\", acfs)\ndf.insert(2, \"alpha\", ts)\ndf.to_csv(\"cache/acf.csv\")"
  },
  {
    "objectID": "plots/acf.html#acf-plots",
    "href": "plots/acf.html#acf-plots",
    "title": "Stability check",
    "section": "ACF plots",
    "text": "ACF plots"
  },
  {
    "objectID": "plots/acf.html#lag-check-for-rolled-data",
    "href": "plots/acf.html#lag-check-for-rolled-data",
    "title": "Stability check",
    "section": "Lag check for rolled data",
    "text": "Lag check for rolled data\n\n\nCode\nacfs = df_0['acfs']\ntrs = df_0['alpha']\nlags = df_0['lags']\n\ntrue_lags = lags*trs\n\n\n\n\nCode\nax = sns.lineplot(x=df_0.lags * df_0.alpha, y=df.acfs, hue=trs, palette='cmc.bamako', marker='o', alpha=0.9, mec=(0,0,0,0.1))\n#ax.set_xscale('log')\nax.set_xlim(left=0, right=15)\nax.set_ylim(bottom=0.06, top=0.07)\nax.axhline(0.25**2)"
  },
  {
    "objectID": "plots/number_of_cluster.html",
    "href": "plots/number_of_cluster.html",
    "title": "Number of clusters",
    "section": "",
    "text": "Code\nimport os\nos.chdir(\"/project/persistent-exclusion-process\")\n\nfrom src.utils import get_ds_iters\nfrom src.plot_utils import get_plot_configs\n\nimport h5py\nimport glob\n\nfrom scipy import ndimage\nimport matplotlib.pyplot as plt\nfrom cmcrameri import cm\nimport numpy as np\n\nplot_configs = get_plot_configs()\nplot_configs[\"xtick.labelsize\"] = 12\nplot_configs[\"ytick.labelsize\"] = 12\nplt.rcParams.update(plot_configs)\n\nfig, (axis) = plt.subplots(\n    1,\n    1,\n    figsize=(4, 3),\n    constrained_layout=True\n)\naxis.set_xscale(\"log\")\nfiles = glob.glob(\"bp_data/dataset*\")\nsizes = np.zeros_like(files, dtype=np.float_)\nkernel = [[0, 1, 0], [1, 1, 1], [0, 1, 0]]\nfor idx, f in enumerate(sorted(files)):\n    hf = h5py.File(f, \"r\")\n    iters = get_ds_iters(hf.keys())\n    num = []\n    for idx2 in range(100):\n        img = hf[f\"conf_{iters[idx2]}\"]\n        _, nlabels = ndimage.label(img, structure=kernel)\n        num.append(nlabels)\n    sizes[idx] = np.mean(num)\n    \naxis.plot([0.023, 0.107, 0.500], sizes[0::3], marker=\"o\", c=cm.batlowS(2), mfc=cm.batlowS(2,0.3), mec=cm.batlowS(2))\naxis.text(x=0.6, y=0.18, rotation=3, transform=axis.transAxes, s=r\"$\\phi = 0.05$\", c=cm.batlowS(2))\naxis.plot([0.023, 0.107, 0.500], sizes[1::3], marker=\"o\", c=cm.batlowS(3), mfc=cm.batlowS(3,0.3), mec=cm.batlowS(3))\naxis.text(x=0.5, y=0.68, rotation=30, transform=axis.transAxes, s=r\"$\\phi = 0.25$\", c=cm.batlowS(3))\naxis.plot([0.023, 0.107, 0.500], sizes[2::3], marker=\"o\", c=cm.batlowS(4), mfc=cm.batlowS(4,0.3), mec=cm.batlowS(4))\naxis.text(x=0.55, y=0.4, rotation=24, transform=axis.transAxes, s=r\"$\\phi = 0.45$\", c=cm.batlowS(4))\naxis.set_xlabel(r\"Tumbling rate, $\\alpha$\")\naxis.set_ylabel(r\"Number of clusters\")\naxis.set_xticks([0.023, 0.107, 0.500], labels=[0.023, 0.107, 0.500])\n#fig.savefig(\"../plots/num_labels.pdf\")"
  },
  {
    "objectID": "plots/percolation_ratio_rho.html",
    "href": "plots/percolation_ratio_rho.html",
    "title": "Ratio of biggest cluster over density",
    "section": "",
    "text": "Full code"
  },
  {
    "objectID": "plots/percolation.html",
    "href": "plots/percolation.html",
    "title": "Percolation check",
    "section": "",
    "text": "Code\npip install natsort\n\n\nDefaulting to user installation because normal site-packages is not writeable\nCollecting natsort\n  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\nDownloading natsort-8.4.0-py3-none-any.whl (38 kB)\nInstalling collected packages: natsort\n  WARNING: The script natsort is installed in '/home/jupyter/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\nSuccessfully installed natsort-8.4.0\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport os\n\nos.chdir(\"/project/persistent-exclusion-process\")\n\n\n#from statsmodels.graphics.mosaicplot import mosaic\nimport matplotlib.pyplot as plt\nimport cmcrameri\nimport h5py\nimport numpy as np\nfrom scipy import ndimage\nimport seaborn as sns\nimport pandas as pd\nfrom cmcrameri import cm\n#import natsort\n\nfrom src.utils import get_cluster_labels, get_ds_iters\nfrom src.plot_utils import get_plot_configs\n\nplot_configs = get_plot_configs()\nplt.rcParams.update(plot_configs)\nnp.set_printoptions(precision=5)\n\n\n\n\nCode\ndef get_biggest_cluster_loc(file, idx):\n    kernel = [[0, 1, 0], [1, 1, 1], [0, 1, 0]]\n    labelled, _ = get_cluster_labels(file, idx)\n    lb = labelled.flatten()\n    cluster_sizes = np.bincount(lb)[1:]\n    biggest_cluster_id = np.argmax(cluster_sizes) + 1\n    return np.where(labelled == biggest_cluster_id)\n\n\ndef check_threshold(locs, threshold=20, dim=128):\n    #print(np.ptp(locs[0]), np.ptp(locs[1]))\n    if np.ptp(locs[0]) &gt;= 128-threshold:\n        return True\n    if np.ptp(locs[1]) &gt;= 128-threshold:\n        return True\n    return False\n\n\n\n\nCode\ntumbles = np.logspace(-6,-1,10, base=2)\ndensity = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.6,0.7]\nacceptance = .5\nres = []\nfor t in tumbles:\n    for d in density:\n        file = f\"no_roll_data/dataset_tumble_{t:.3f}_{d}.h5\"\n        hf = h5py.File(file)\n        data = [ hf[i][:] for i in natsort.natsorted(list(hf.keys()))]\n        data = np.array(data)\n\n        \n        P = []\n        \n        for idx in range(1000):\n            locs = get_biggest_cluster_loc(file, idx)\n            P.append(check_threshold(locs))\n        res.append(np.mean(P))\n        print(np.mean(P))\n\n\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n\n\n\n\nCode\nwith open(\"cache/perc.txt\", 'r') as cache:\n    res = cache.readlines()\n    perc = [float(val.strip('\\n')) for val in res]\n    perc = np.reshape(perc, (10,14))\n\n\n\n\nCode\ntumbles = np.logspace(-6,-1,10, base=2)\ndensity = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7]\n\ncmap = plt.get_cmap('cmc.lajolla')\n\nxlabels = np.concatenate(([0,0],tumbles))\nylabels = np.concatenate(([0,0],density))\n\nfig, ax = plt.subplots(1,1, figsize=(5,5), constrained_layout=True)\nm = ax.imshow(perc, cmap=cmap.reversed())\ncbar = plt.colorbar(ax=ax, mappable=m, location='top', aspect=25,\n                    fraction=0.046, pad=0.05)\nax.set_yticks([0,2,4,6,8], labels=np.round(tumbles[::2],3))\nax.set_xticks([0,2,4,6,8,10,12], labels=density[::2])\n\n#ax.plot([7.5,7.5,8.5,8.5,8.5,9.5],[-0.5,0.5,0.5,1.5,4.5,4.5], c='white', linestyle='--')\nax.plot([8.5,8.5,8.5,8.5,9.5,9.5],[-0.5,0.5,1.5,2.5,2.5,9.5], c='white', linestyle='--')\n\ncbar.ax.set_xlabel('$F_\\mathrm{P}$', labelpad=7)\ncbar.ax.set_xticks([0.1,0.3,0.5,0.7,0.9])\n\nax.set_ylabel(r\"Tumbling rate, $\\alpha$\")\nax.set_xlabel(r\"Packing fraction, $\\phi$\")\n\nax.text(s=r\"Percolating\", x=10.75, y=6.75, c='w', rotation=90, fontsize=22)\nfig.savefig('plots/percolating_prob.pdf')\n\n\n\n\n\n\n\n\n\n\n\nCode\nhf = h5py.File(\"no_roll_data/dataset_tumble_0.016_0.7.h5\", \"r\")\niters = get_ds_iters(hf.keys())\nimg = hf[f\"conf_{iters[-10]}\"]\nimg = np.array(img)\nplt.matshow(img, cmap='cubehelix')\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport matplotlib as mpl\nfrom mpl_toolkits.axes_grid1.inset_locator import InsetPosition, inset_axes\n\ncmap=plt.get_cmap('cmc.batlow', lut=10)\nfig, axm = plt.subplots(1,1, figsize=(5,5), constrained_layout=True)\nfor i in range(10):\n    axm.plot(density,perc[i], mec='k', mfc=cmap(i), c=cmap(i), marker='^')\nsns.despine()\naxm.set_ylabel(r\"$F_\\mathrm{P}$\")\naxm.set_xlabel(r\"$\\phi$\")\naxm.set_xticks([0.1,0.3,0.5,0.7])\nax3 = inset_axes(axm, width=\"100%\", height=\"100%\", borderpad=1)\nax3.set_axes_locator(InsetPosition(axm, [0.9, 0.1, 0.05, 0.45]))\ncmap = 'cmc.batlow'\nnorm = mpl.colors.Normalize(vmin=0.016, vmax=0.5)\ncb1 = mpl.colorbar.ColorbarBase(ax3,\n                                cmap=cmap,\n                                norm=norm,\n                                ticklocation='left',\n                                orientation='vertical',\n                                boundaries=[0.0,0.1,0.2,0.3,0.4,0.5,0.6])\n\ncb1.ax.set_yticks([0.05,0.15,0.25,0.35,0.45,0.55])\ncb1.ax.set_yticklabels([0.0,0.1,0.2,0.3,0.4,0.5])\nax3.text(s=r\"$\\alpha$\", x=0.2, y=1.05, transform=ax3.transAxes)\n\nax = inset_axes(axm, width=\"100%\", height=\"100%\", borderpad=1)\nax.set_axes_locator(InsetPosition(axm, [0.14, 0.52, 0.35, 0.45]))\n\ncax = inset_axes(axm, width=\"100%\", height=\"100%\", borderpad=1)\ncax.set_axes_locator(InsetPosition(axm, [0.5, .72, 0.02, 0.25]))\n\ntumbles = np.logspace(-6,-1,10, base=2)\ndensity = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7]\n\ncmap = plt.get_cmap('cmc.lajolla')\n\nxlabels = np.concatenate(([0,0],tumbles))\nylabels = np.concatenate(([0,0],density))\n\nm = ax.imshow(perc.T[::-1], cmap=cmap.reversed())\ncbar = plt.colorbar(ax=ax, mappable=m, cax=cax, location='right', aspect=5,\n                    fraction=0.046, pad=0.05)\nax.set_xticks([0,4,8])\nax.set_xticklabels(np.round(tumbles[::4],3),fontsize=12)\nax.set_yticks([0,4,8,12])\nax.set_yticklabels(density[::-4], fontsize=12)\n\n#ax.plot([7.5,7.5,8.5,8.5,8.5,9.5],[-0.5,0.5,0.5,1.5,4.5,4.5], c='white', linestyle='--')\nax.plot([-0.5,0.5,1.5,2.5,2.5,9.5], [4.5,4.5,4.5,4.5,3.5,3.5], c='white', linestyle='--')\n\ncbar.ax.set_xlabel('$F_\\mathrm{P}$', labelpad=7, fontsize=14, loc='center')\ncbar.ax.set_yticks([0.1,0.5,0.9])\ncbar.ax.set_yticklabels([0.1,0.5,0.9], fontsize=12)\n\nax.set_xlabel(r\"$\\alpha$\", fontsize=12)\nax.set_ylabel(r\"$\\phi$\", fontsize=12)\nax.text(s=r\"Percolating\", x=.5, y=2, c='w', fontsize=16)\n#cax.text(s=r\"$F_\\mathrm{P}$\", x=0, y=1.1, c='k', fontsize=12)\n\naax = inset_axes(axm, width=\"100%\", height=\"100%\", borderpad=1)\naax.set_axes_locator(InsetPosition(axm, [0.76, .68, 0.21, 0.21]))\naax.set(xticks=[],yticks=[])\naax.imshow(img, origin='upper', cmap='cubehelix')\n\nfig.savefig('plots/percolating_prob.pdf')\n\n\n\n\n\n\n\n\n\n\n\nCode\ntumbles[::2]\n\n\narray([0.01562, 0.03375, 0.07291, 0.15749, 0.3402 ])\n\n\n\n\nCode\ntumbles = np.logspace(-6,-1,10, base=2)\ndensity = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\nacceptance = .5\nres2 = []\n\nfor t in tumbles:\n    file = f\"no_roll_data/dataset_tumble_{t:.3f}_0.5.h5\"\n    hf = h5py.File(file)\n    data = [ hf[i][:] for i in natsort.natsorted(list(hf.keys()))]\n    data = np.array(data)\n\n    \n    P = []\n    \n    for idx in range(1000):\n        locs = get_biggest_cluster_loc(file, idx)\n        P.append(check_threshold(locs))\n    res2.append(P)\n\n\n\n\nCode\nprint(np.shape(res))\nprint(np.shape(res2))\n\n\n(10, 1000)\n\n\n\n\nCode\nplt.plot(density,np.mean(res,axis=1), marker='o')\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.plot(tumbles,np.mean(res2,axis=1), marker='o')\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint([perc[i][10] for i in range(0,10)])\n\n\n[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.999, 1.0]"
  },
  {
    "objectID": "plots/evo.html",
    "href": "plots/evo.html",
    "title": "Snapshot evolution",
    "section": "",
    "text": "Code\nimport os\nos.chdir(\"/project/persistent-exclusion-process\")\n\nfrom src.plot_utils import get_plot_configs\n\nimport cmcrameri\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import ndimage\nfrom matplotlib.patches import ConnectionPatch\nfrom mpl_toolkits.axes_grid1.inset_locator import InsetPosition, inset_axes\n\nimport src.lattice as lattice\n\nplot_configs = get_plot_configs()\nplot_configs[\"xtick.labelsize\"] = 12\nplot_configs[\"ytick.labelsize\"] = 12\nplt.rcParams.update(plot_configs)\n\ndef plot_img(ax, img, tau):\n    ax.set_xlim(0, n_x)\n    ax.set_ylim(0, n_y)\n    ax.set_aspect(\"equal\", \"box\")\n    ax.tick_params(\n        axis = \"both\",\n        which = \"both\",\n        length = 0,\n        labelleft = False,\n        labelbottom = False,\n    )\n    ax.matshow(img, cmap=plt.get_cmap(name=\"cmc.grayCS\", lut=5))\n    ax.set_title(r\"$\\tau = {}$\".format(tau))\n    return ax\n\ndef plot_lb(img, ax):\n    cmap=plt.get_cmap(\"cmc.lipariS\")\n    cl = cmap.__dict__['colors']\n    new_cls = np.concatenate((cl,cl[1:],cl[1:],cl[1:]))\n    cmap.__dict__[\"colors\"] = new_cls\n    cmap.__dict__[\"colors\"][0] = np.array([1,1,1])\n    cmap.__dict__[\"N\"] = len(new_cls)\n    kernel = [[0, 1, 0], [1, 1, 1], [0, 1, 0]]\n    lb, _ = ndimage.label(img, structure=kernel)\n    ax.tick_params(\n        axis = \"both\",\n        which = \"both\",\n        length = 0,\n        labelleft = False,\n        labelbottom = False,\n    )\n    ax.matshow(np.flipud(lb), cmap=cmap)\n    return ax\n\nn_x = n_y = 128\nn_p = int(0.45 * n_x * n_y)\ntumble = 0.023\nspeed = 1\nlat = lattice.Lattice(n_x * n_y, n_p)\nlat.set_square_connectivity(n_x, n_y)\nlat.reset_random_occupancy()\nlat.reset_orientations()\nplt.rcParams[\"figure.autolayout\"] = False\n\nfig, (ax1, ax2, ax3) = plt.subplots(\n    3,\n    1,\n    figsize=(4, 9),\n)\n\nfor idx in range(201):\n    if idx == 0:\n        ima = lat.image()\n        ax1 = plot_img(ax1, ima, idx)\n    if idx == 20:\n        ax2 = plot_img(ax2, lat.image(), idx)\n    if idx == 200:\n        imb = lat.image()\n        ax3 = plot_img(ax3, imb, idx)\n        break\n    lat.c_move(tumble, speed)\n\nkernel = [[0, 1, 0], [1, 1, 1], [0, 1, 0]]\nlba, _ = ndimage.label(ima, structure=kernel)\nlbb, _ = ndimage.label(imb, structure=kernel)\n\naxi1 = inset_axes(ax1, width=\"100%\", height=\"100%\", borderpad=1)\naxi1.set_axes_locator(InsetPosition(ax1, [1.1, -0.65, 1.5, 1.5]))\naxi1 = plot_lb(ima, axi1)\n\naxi3 = inset_axes(ax3, width=\"100%\", height=\"100%\", borderpad=1)\naxi3.set_axes_locator(InsetPosition(ax3, [1.1, 0.15, 1.5, 1.5]))\naxi3 = plot_lb(imb, axi3)\n\nkwg = {\"alpha\":.3, \"zorder\":0, \"color\": \"k\"}\n\nfig.add_artist(\n    ConnectionPatch(\n        xyA=(0, 0),\n        coordsA=ax1.transAxes,\n        xyB=(0, 0),\n        coordsB=axi1.transAxes,\n        **kwg\n    )\n)\nfig.add_artist(\n    ConnectionPatch(\n        xyA=(1, 1),\n        coordsA=ax1.transAxes,\n        xyB=(1, 1),\n        coordsB=axi1.transAxes,\n        **kwg\n    )\n)\nfig.add_artist(\n    ConnectionPatch(\n        xyA=(1, 0),\n        coordsA=ax3.transAxes,\n        xyB=(1, 0),\n        coordsB=axi3.transAxes,\n        **kwg\n    )\n)\nfig.add_artist(\n    ConnectionPatch(\n        xyA=(0, 1),\n        coordsA=ax3.transAxes,\n        xyB=(0, 1),\n        coordsB=axi3.transAxes,\n        **kwg\n    )\n)\nfig.savefig(\"plots/evo.pdf\", bbox_inches='tight')\n\n\n/tmp/ipykernel_51/2033320881.py:89: MatplotlibDeprecationWarning: The InsetPosition class was deprecated in Matplotlib 3.8 and will be removed two minor releases later. Use Axes.inset_axes instead.\n  axi1.set_axes_locator(InsetPosition(ax1, [1.1, -0.65, 1.5, 1.5]))\n/tmp/ipykernel_51/2033320881.py:93: MatplotlibDeprecationWarning: The InsetPosition class was deprecated in Matplotlib 3.8 and will be removed two minor releases later. Use Axes.inset_axes instead.\n  axi3.set_axes_locator(InsetPosition(ax3, [1.1, 0.15, 1.5, 1.5]))"
  },
  {
    "objectID": "plots/cluster_count_and_biggest.html",
    "href": "plots/cluster_count_and_biggest.html",
    "title": "Number of cluster and biggest cluster size",
    "section": "",
    "text": "Full code"
  },
  {
    "objectID": "plots/cluster_count_and_biggest.html#size-plots",
    "href": "plots/cluster_count_and_biggest.html#size-plots",
    "title": "Number of cluster and biggest cluster size",
    "section": "Size plots",
    "text": "Size plots"
  },
  {
    "objectID": "plots/cluster_count_and_biggest.html#calculating-values-at-zero-tumbling-rate",
    "href": "plots/cluster_count_and_biggest.html#calculating-values-at-zero-tumbling-rate",
    "title": "Number of cluster and biggest cluster size",
    "section": "Calculating values at zero tumbling rate",
    "text": "Calculating values at zero tumbling rate\n\n\nCode\ndensities = np.sort(np.unique(df.density))\ncolors = [0,50,100,150,200]\npalette = {}\n\nfor idx in range(5):\n    palette[densities[idx]] = cm.glasgow(colors[idx])\n\n\n\n\nCode\nfor d in [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:\n    file = f\"validation_data/dataset_tumble_1.000_{d}.h5\"\n    ds = []\n    ts = []\n    big = []\n    num = []\n    d = 0.1\n    t = 1.0\n    for idx2 in range(0,1000,1):\n        ds.append(d)\n        ts.append(t)\n        labelled, nlabels = get_cluster_labels(file, idx2)\n        lb = labelled.flatten()\n        big.append(np.max(np.bincount(lb)[1:]))\n        num.append(nlabels)\n    print(np.mean(big))\n    #print(np.mean(num), np.std(num))\n\n\n\n\nCode\n737.47/(0.05*128*128)\n\n\n0.90023193359375\n\n\n\nKeeping track of counts here\n\n0 -&gt; 1\n0.05 -&gt; 0.90023193359375\n0.1 -&gt; 0.801976318359375\n0.2 -&gt; 0.6097885131835937\n0.3 -&gt; 0.4292635091145834\n0.4 -&gt; 0.2676585388183593\n0.5 -&gt; 0.1344013671875\n0.6 -&gt; 0.04449951171875\n0.7 -&gt; 0.011117292131696429\n0.8 -&gt; 0.001993408203125\n0.9 -&gt; 0.00018819173177083332\n1.0 -&gt; 0.0\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.scatter(x,y)"
  },
  {
    "objectID": "shared/gitinfo.html",
    "href": "shared/gitinfo.html",
    "title": "Useful Commands and Information for Shared Github Activity",
    "section": "",
    "text": "Useful Commands and Information for Shared Github Activity\n\n\nTable of Contents\n\nTable of Contents\nIntroduction\nCloning\nBasic Git Commands\nBasic Quarto Commands\n\n\n\n1. Introduction\nThis page is an attempt to take commands that pop up in the course of sharing our activity (whether it‚Äôs passing it collectively or publishing it to an easily accessible site). Everything here is subject to change and addition as we discover more commands that need remembering. This page should be as standardised and explanatory as possible; when deemed necessary, examples should be given alongside the basic command structure.\n\n\n2. Cloning\nWhen cloning a repository, use:\ngit clone git@github.com:&lt;user&gt;/&lt;repo&gt;\nIf you didn‚Äôt use ssh url while cloning, change remote before pushing:\ngit remote set-url origin git@github.com:&lt;user&gt;/&lt;repo&gt;\nFor instance, cloning the persistent exclusion process example script:\ngit remote set-url origin git@github:dlactivematter/persistent-exclusion-process.git\nIf in doubt, use the following to show all the available remotes:\ngit remote -v\n\n\n3. Basic Git Commands\nCheck which branch you are on (and also other available branches):\ngit status\nAdd new file to current branch\ngit add &lt;filename&gt;\nCommit new file to current branch (prompts adding a commit comment)\ngit commit &lt;filename&gt; \nPush all changes to branch\ngit push origin &lt;branch&gt;\n\n\n4. Basic Quarto Commands\nNote: only works on .qmd files\nPreview .qmd document in browser\nquarto preview &lt;filename&gt;\nRender all .qmd files into html (usually not necessary)\nquarto render\nRender all .qmd files into html and publish them to the gh-pages branch\nquarto publish gh-pages"
  },
  {
    "objectID": "shared/cluster.html",
    "href": "shared/cluster.html",
    "title": "Cluster information",
    "section": "",
    "text": "Project code: PHYS030564"
  },
  {
    "objectID": "shared/ftnotes/interim-report-structure.html",
    "href": "shared/ftnotes/interim-report-structure.html",
    "title": "Dissipation Learning in Active Matter",
    "section": "",
    "text": "Generalities [700 words]\nModelling of active matter [300 words]\n\nparticle-based (active Brownian particles or active OrnsteinUhlenbeck particles)\nfield theories (Model B+ , Tjhung et al 2023)\n\nLattice models ( Soto, Telo de Gama) [200 words]\nFocus on Persistent Exclusion Process (Background and main results) [200 words]\nAnticipate the overall goal (linking structure to activity), mention the precedent of Rassolov et al.¬†2022 [200 words]\nPreparatory work up to now [500 words]\n\nbrief reference to the in-house code\nvalidation of the code\ntests in different conditions\nfirst measurements (orientation, cluster sizes, cluster distributions)\ncompare with Soto?\n\nlook back critically: discussion [200 words]\nPlan for the future [200 words]"
  },
  {
    "objectID": "shared/ftnotes/Colab.html",
    "href": "shared/ftnotes/Colab.html",
    "title": "Link to colab notebook",
    "section": "",
    "text": "Link to colab notebook\nThis is an experimental notebook for the training of the convolutional neural network onto the data from the Persistence Exclusion Process\nhttps://colab.research.google.com/drive/1B0vXEyb2GG4Mjc5dbd45LIrfcQbReFCr?usp=sharing"
  },
  {
    "objectID": "activity_log/week_20.html",
    "href": "activity_log/week_20.html",
    "title": "Week 20",
    "section": "",
    "text": "Redo orientation analysis1\n\nAfter discussion, it‚Äôs easier to look at the whole snapshot, perform edge detection (laplace or sobel) and take orientation distribution there. I.e. We look at whole system, and compare counts at negative vs positive gradients.\n\nPercolation (Plots here.)\nWork on summary plots and analysis for CNN2.\nWork on report structure3.\nACF check for rolling (what‚Äôs going on?)4.\nFlowchart for CNN model5\nFix cluster labelling so it works with periodic boundary conditions6."
  },
  {
    "objectID": "activity_log/week_20.html#tasks",
    "href": "activity_log/week_20.html#tasks",
    "title": "Week 20",
    "section": "",
    "text": "Redo orientation analysis1\n\nAfter discussion, it‚Äôs easier to look at the whole snapshot, perform edge detection (laplace or sobel) and take orientation distribution there. I.e. We look at whole system, and compare counts at negative vs positive gradients.\n\nPercolation (Plots here.)\nWork on summary plots and analysis for CNN2.\nWork on report structure3.\nACF check for rolling (what‚Äôs going on?)4.\nFlowchart for CNN model5\nFix cluster labelling so it works with periodic boundary conditions6."
  },
  {
    "objectID": "activity_log/week_20.html#summary",
    "href": "activity_log/week_20.html#summary",
    "title": "Week 20",
    "section": "Summary",
    "text": "Summary\n\nRealizing what‚Äôs going wrong with ACF plots\n\nThe augmented data is appended after each snapshot, meaning the evolution kk times slower, where kk is the number of times the same snapshot is rolled (including itself).\nThus we have to increase the maximum kk the lag goes up to.\nLooking at the second panel of the plot, it seems to fit nicely\n\n\n\nACF plot units\nRationale:\n\nLag time is initially represented in seconds.\nLooking back, a particle update is œÑ\\tau.\nLag time for each Œ±\\alpha is scaled by œÑ/Œ±\\tau/ \\alpha.\nTo get an absolute lag time in unit œÑ\\tau, plot x as lags times Œ±\\alpha.\n\nBoth panels of the plot were updated to reflect this.\n\n\nDraft structure for the final report\n\nPreparation\n\nLiterature review\nPEP rules and claims\nAnalysis:\n\nCluster size distribution\nNumber of distribution\nBiggest cluster\nDissipation: PE‚âàŒ±‚àí1PE \\approx \\alpha^{-1}\nOrientation at edges\nPercolation\n\n\n\n\nPre-CNN\n\nOur data is in the ‚Äúclustering regime‚Äù by warming up 500 steps.\nAugmentation (rolling):\n\nPeriodic BCs\nMore/cheap data\n\nACF check\n\nHas the state relaxed (NOT steady state!)?\nAre we capturing enough permutations of the system (in the clustering regime) in order to have a diverse dataset? We should have in order to avoid the CNN memorising the snapshots.\nWith rolling, the ACF is not affected (weird peaks enveloped by real ACF).\n\n\n\n\nCNN\n\nA regression problem\nArchitecture\n\nDifferent kinds of layers: pooling, convolutional, fully connected, dropout, batch norm, etc.\nLoss function: MAE\nActivation: RELU (why not Sigmoid or LeakyRELU?)\nKernel size: (odd dimensions)\nDepth: capture more generality\nOptimizer: SGD over Adam\nBatch size: 64 (high is slow, low overfits)\n\nData preparation\n\nRandomize dataset order\nNormalization\nTypes\n\nWhich is experiment like?\nOriginal: full information, so orientation + position.\nMonochrome: no orientation, particles all set to 1.\nScrambled: particle‚Äôs orientation uniformly redistributed (a different permutation/instance).\nConfusion (future): percentage of original goes to scrambled.\nNoise (future): no orientation, each particle uniformly distributed some noise.\n\n\nMetrics (what makes a decent model?)\n\nMaximum standard deviation: 0.02 (optimistic) (use IQR instead as distributions are not normal)\nLoss (MAE): ‚àº0.02¬±0.005\\sim0.02\\pm0.005\nRange of predictions fully overlap actual values within 1% (didn‚Äôt make it to final report)\nPearson‚Äôs r between predictions and actual values: 0.975 (didn‚Äôt make it to final report)\n\nOutcomes\n\nŒòo(o)worsethanŒòs(s)worsethanŒòm(m)\\Theta_{o}(o) worse than \\Theta_{s}(s) worse than \\Theta_{m}(m)7.\nInterpolation: okay (need to check again) (CP did this so I might not include it in my report)\nExtrapolation (future)\nRange (0.1 - 0.5) where predictions are worse in terms of the spread, most likely due to the way data was sampled8.\n\nOther things to potentially look into\n\nExplore PEPE and RDF.\nOptimize model to give better predictions at the weird range"
  },
  {
    "objectID": "activity_log/week_20.html#footnotes",
    "href": "activity_log/week_20.html#footnotes",
    "title": "Week 20",
    "section": "",
    "text": "Plots here.‚Ü©Ô∏é\nPlots and analysis here.‚Ü©Ô∏é\nSee section Draft structure for the final report.‚Ü©Ô∏é\nPlots here (inset) and discussion in section Realizing what‚Äôs going wrong with ACF plots.‚Ü©Ô∏é\nSaved on draw.io, not really relevant as it‚Äôs just for report‚Ü©Ô∏é\nPlots here.‚Ü©Ô∏é\nŒò\\Theta denotes the trained models, and s,o,ms,o,m denotes dataset, might change up notation in final report‚Ü©Ô∏é\nDiscussed last week.‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_4.html",
    "href": "activity_log/week_4.html",
    "title": "Week 4",
    "section": "",
    "text": "Act on feedback on from last week.\nWe can aim to make a density map of snapshots (Œ±/œï\\alpha / \\phi), on a 3x3 grid1.\n\nRange of Œ±\\alpha: [0.01, 0.5], 10 values in total, split between me and CP.\nUse scikit-learn to detect clusters and cluster size.\nI didn‚Äôt get enough time to do any cluster analysis, just the grid of snapshots.\n\nPlot some snapshots2."
  },
  {
    "objectID": "activity_log/week_4.html#tasks",
    "href": "activity_log/week_4.html#tasks",
    "title": "Week 4",
    "section": "",
    "text": "Act on feedback on from last week.\nWe can aim to make a density map of snapshots (Œ±/œï\\alpha / \\phi), on a 3x3 grid1.\n\nRange of Œ±\\alpha: [0.01, 0.5], 10 values in total, split between me and CP.\nUse scikit-learn to detect clusters and cluster size.\nI didn‚Äôt get enough time to do any cluster analysis, just the grid of snapshots.\n\nPlot some snapshots2."
  },
  {
    "objectID": "activity_log/week_4.html#summary",
    "href": "activity_log/week_4.html#summary",
    "title": "Week 4",
    "section": "Summary",
    "text": "Summary\n\nGeneral\n\nI acted on the feedback3.\nWe decided on a range Œ±\\alpha, which is 10 values spaced logarithmically (base 2) in the range [2-6,2-1]. We thought this would be a sensible range for the snapshot grid, and we weren‚Äôt sure whether to go with log-spacing or normal spacing. In the end, we went with log-spacing.\nFor œï\\phi (density), we decided on a range of [0.05,0.5], with intervals of 0.05, giving a total of 10 values.\nWe modified sampler.py to reflect this, and regenerated the data so that we get a set of static datasets to work on creating this grid, ensuring the plot can be reproduced. I ran everything on the cluster this time.\n\n\n\nPlotting snapshots\nI began making plots of a selection of these datasets (a 3x5 grid), first as individual plots to before I spend more time and place them all on one figure. Then, I put them altogether on one grid:\n\n\n\nSnapshots for various values of Œ±\\alpha and œï\\phi.\n\n\nSome observations:\n\nPercolation is observed clearly in top right figures. This is an exotic feature of phase transition.\nI tried to add figure x and y labels but the matplotlib I was using was too old to support fig.supxlabel or fig.supylabel. I also need to add labels for each block to indicate the value (œï,Œ±)(\\phi, \\alpha)."
  },
  {
    "objectID": "activity_log/week_4.html#footnotes",
    "href": "activity_log/week_4.html#footnotes",
    "title": "Week 4",
    "section": "",
    "text": "See this notebook for a demo.‚Ü©Ô∏é\nSee section Plotting snapshots.‚Ü©Ô∏é\nReflected/updated here.‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_16.html",
    "href": "activity_log/week_16.html",
    "title": "Week 16",
    "section": "",
    "text": "Try and tune/optimize the models we‚Äôve tested1.\nCome up with a set of metrics to evaluate our experiments2."
  },
  {
    "objectID": "activity_log/week_16.html#tasks",
    "href": "activity_log/week_16.html#tasks",
    "title": "Week 16",
    "section": "",
    "text": "Try and tune/optimize the models we‚Äôve tested1.\nCome up with a set of metrics to evaluate our experiments2."
  },
  {
    "objectID": "activity_log/week_16.html#summary",
    "href": "activity_log/week_16.html#summary",
    "title": "Week 16",
    "section": "Summary",
    "text": "Summary\n\nTracking progress systematically\nWe made a spreadsheet table3. to log and track different changes, and start anew, as last week we only designed basic experiments to see what we can potentially do. We also give the model a unique ID (randomly generated), to refer to them easier.\n\n\nMetrics\nTo evaluate the models, we established some metrics and threshold:\n\nMean absolute error\n\nMAE&lt;0.01\\mathrm{MAE} &lt; 0.01\n\nStandard deviation (minimum, maxmimum and average of all Œ±\\alpha‚Äôs)\n\nœÉmax&lt;0.02\\sigma_{\\mathrm{max}} &lt; 0.02\nœÉmean&lt;0.01\\sigma_{\\mathrm{mean}} &lt; 0.01\n\nOverlap ratio within 10‚àí310^{-3} (whether the prediction ranges cover the actual value)\n\nO=1O = 1\n\nPearson‚Äôs rr (this is only affective on a handful of Œ±\\alpha‚Äôs, using it on one or two data points is not very indicative of the model‚Äôs performance)\n\nr&gt;0.975r &gt; 0.975\n\n\n\n\nPrevious progress and old strategy\nFrom last week, model B learned okay. It didn‚Äôt reduce the spread to the desirable metric after 10 epochs. This prompted us to tweak it slightly. Here were the different attempts, after researching for some tips online45:\n\nFrom the previous week, reducing dropout from 0.2 to 0.1.\nInstead of training on one œï\\phi, train on similar values to add to it more data (everything else kept the same).\n\nNot much improvement. But I only compared between two runs, should do two more pairs and take the average.\n\nIncreasing the number of filters and kernel size in the convolutional layer\n\nNo improvement, if not slightly worse, slow training times as there are now many more parameters. Still not descending after 10 epochs or so.\n\nUse LeakyReLU6 (ReLU but with small gradient when unit is inactive, apparently works well on regression)\n\nLeakyReLU seems to be worse. We stick to ReLU for now.\n\nApply a separate ReLU() layer after Conv2D() (which now has no activation). Apply MaxPooling2D() in between to reduce parameters.\n\nThis helps training speed but doesn‚Äôt improve nor degrade performance. For simple model we don‚Äôt need to use pooling so we can apply it when we declare the Conv2D layer.\n\nAdding more dense layers with non-linear activation.\n\nSignificantly more parameters, reduce training speed, no improvement\n\n\n# Before\nmodel.add(\n    Conv2D(\n        filters=3,\n        kernel_size=(3, 3),\n        padding=\"same\",\n        activation=\"relu\",\n        input_shape=shape,\n    )\n)\nmodel.add(BatchNormalization())\n\n# After\nmodel.add(Conv2D(\n    filters=3,\n    kernel_size=(3, 3),\n    padding=\"same\",\n    input_shape=shape)\n)\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\nmodel.add(ReLU())\nmodel.add(BatchNormalization())\nAdvising some models found in examples online78, we revise last weeks‚Äô architecture:\ndef make_net(shape):\n    model = Sequential()\n\n    model.add(Conv2D(filters=3,\n                     kernel_size=(3, 3),\n                     padding=\"same\",\n                     input_shape=shape)\n             )\n    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n    model.add(ReLU())\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(filters=4, kernel_size=(4, 4), padding=\"same\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n    model.add(ReLU())\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(filters=6, kernel_size=(5, 5), padding=\"same\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n    model.add(ReLU())\n    model.add(BatchNormalization())\n\n    model.add(GlobalAveragePooling2D())\n\n    with options({\"layout_optimizer\": False}):\n        model.add(Dropout(0.1))\n\n    model.add(Dense(units=128, activation=\"relu\"))\n\n    with options({\"layout_optimizer\": False}):\n        model.add(Dropout(0.1))\n\n    model.add(Dense(units=3, activation=\"relu\"))\n\n    model.add(Flatten())\n    model.add(Dense(units=1, activation=\"linear\"))\n    return model\n\nOverall results\nIn general, even with minor tweaks, the performance is just okay, there is a lot of spread. The run below showcases an ‚Äúaverage‚Äù spread/distribution of the predictions, it was trained on all Œ±\\alpha‚Äôs, using the default Adam optimizer, ran on 10 epochs (but seemed to have constant loss quickly after 3-4 epochs).\nModel name is rock8943.\n\n\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n0.9\n0.0021703113\n0.030762767\n0.011323685\n0.9913190773147734\n\n\n2024-04-14 19:31:56.708222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-04-14 19:31:56.723473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-04-14 19:31:56.723659: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-04-14 19:31:56.724326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-04-14 19:31:56.724474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-04-14 19:31:56.724604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-04-14 19:31:56.826565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-04-14 19:31:56.826731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-04-14 19:31:56.826865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-04-14 19:31:56.826976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 727 MB memory:  -&gt; device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:07:00.0, compute capability: 7.5\n2024-04-14 19:31:57.032079: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393216000 exceeds 10% of free system memory.\n2024-04-14 19:31:57.228226: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n\n\n\n\n\n\n\n\n\n\n\n\nValidating our code (and figuring out the effect of learning rate)\nAs a sanity check, it‚Äôs important to make sure our model can learn and overfit a few values at a time. Thus, with the same architecture, we start with one value of Œ±\\alpha. The models are actually trained on augmented data. To redo the predictions here, we remove the augmentation.\n\n\nOne Œ±\\alpha\nWith the chosen network, try training only on one set of (Œ±,œï)(\\alpha, \\phi) value first. It worked fine with the default Adam parameters, loss stopped improving after roughly 3-4 epochs.\nModel name is rattle9304.\n\n\nNumber of unique alpha:  1\nShape of x:  (3000, 128, 128, 1)\nShape of y:  (3000,)\nSize of training data:  2400\nSize of validation data:  600\n1.0\n5.8096216e-08\n5.8096216e-08\n5.8096216e-08\nnan\n\n\n/project/persistent-exclusion-process/src/training_utils.py:153: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  print(pearsonr(actual, predictions).statistic)\n\n\n\n\n\n\n\n\n\n\n\nTwo Œ±\\alpha‚Äôs\nAlso works wonderfully well with default Adam, but now loss stopped improving after roughly 17-18 epochs.\nModel name is bake3945.\n\n\nNumber of unique alpha:  2\nShape of x:  (6000, 128, 128, 1)\nShape of y:  (6000,)\nSize of training data:  4800\nSize of validation data:  1200\n1.0\n1.8626451e-09\n6.2078734e-06\n3.104868e-06\n0.9999999990745181\n\n\n\n\n\n\n\n\n\n\n\nThree Œ±\\alpha‚Äôs\nStarting out with Adam again, but it was getting stuck with 0.001 learning rate. Reducing to 0.006 made it converge again, after around 10 epochs. Here, we learned that one thing we didn‚Äôt try earlier was also decreasing the learning rate.\nModel name is fish9182.\n\n\nNumber of unique alpha:  3\nShape of x:  (9000, 128, 128, 1)\nShape of y:  (9000,)\nSize of training data:  7200\nSize of validation data:  1800\n57/57 [==============================] - 0s 3ms/step\n1.0\n1.8626451e-09\n6.458889e-06\n2.1560675e-06\n0.9999998813094848\n\n\n\n\n\n\n\n\n\n\n\nFilling in the gaps\nA model trained on 4 Œ±\\alpha‚Äôs with the same architecture as above tries to predict the values in between. Here, the learning rate is 0.0002.\nModel name is tart1924.\n\n\nNumber of unique alpha:  4\nShape of x:  (12000, 128, 128, 1)\nShape of y:  (12000,)\nSize of training data:  9600\nSize of validation data:  2400\n75/75 [==============================] - 0s 2ms/step\n 57/282 [=====&gt;........................] - ETA: 0s282/282 [==============================] - 1s 2ms/step\n\n\n2024-04-14 19:32:30.603963: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 589824000 exceeds 10% of free system memory.\n\n\nText(0, 0.5, 'Predicted turning rate')\n\n\n\n\n\n\n\n\n\nFor low values, it does quite poorly, being able to only predict values centered around 0.0230.023. At 0.05,0.107,0.157,0.3400.05, 0.107,0.157,0.340, it starts to spread more, predicting values with range established by the nearest Œ±\\alpha‚Äôs that was trained on.\nThe model shows that it is quite specific for each Œ±\\alpha.\nWe also learn here that we‚Äôve left the learning rate for our optimizer untouched, but this parameter is quite important! The optimizer, often stochastic gradient descent (SGD), imparts ‚Äúmomentum‚Äù to ‚Äúunstuck‚Äù the network from local minima. When traversing the loss landscape, which for us is non-trival (i.e.¬†non-convex, so not just one minimum), a learning rate too high means we figuratively jump from valley to valley, not converging on anything. Too slow and we don‚Äôt make any progress, and potentially get stuck."
  },
  {
    "objectID": "activity_log/week_16.html#footnotes",
    "href": "activity_log/week_16.html#footnotes",
    "title": "Week 16",
    "section": "",
    "text": "See section Previous progress and old strategy.‚Ü©Ô∏é\nSee section Metrics.‚Ü©Ô∏é\nLink here‚Ü©Ô∏é\nFinding a good learning rate.‚Ü©Ô∏é\nA lot of good general tips.‚Ü©Ô∏é\nLeakyReLU vs ReLU.‚Ü©Ô∏é\nWell-explained CNN regression model‚Ü©Ô∏é\nAnother one, less useful though‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_14.html",
    "href": "activity_log/week_14.html",
    "title": "Week 14",
    "section": "",
    "text": "Regenerate datasets without the rolling to reduce filesizes and complexity1\nQuantify where cluster distribution stabilises2\n\nAn aside for now as we wrap up analysis to focus on the neural network"
  },
  {
    "objectID": "activity_log/week_14.html#tasks",
    "href": "activity_log/week_14.html#tasks",
    "title": "Week 14",
    "section": "",
    "text": "Regenerate datasets without the rolling to reduce filesizes and complexity1\nQuantify where cluster distribution stabilises2\n\nAn aside for now as we wrap up analysis to focus on the neural network"
  },
  {
    "objectID": "activity_log/week_14.html#summary",
    "href": "activity_log/week_14.html#summary",
    "title": "Week 14",
    "section": "Summary",
    "text": "Summary\n\nRemove the hardcoded augmentation function\nTo remove the extra snapshots3, we remove the final loop in sampler.py, create a new version for this, which we named sampler_no_roll.py, and regenerated the datasets, each only 66 MB in size (reduced from 220 MB!).\nA one-liner for this:\nfor i in $(seq 0.0.5 0.05 0.5); \\\ndo python3 sampler_no_roll.py \\\n--odd --density $i; done\nI think augmentation can be added in when we clean up and prepare data for the neural network, instead of being saved on disk.\nThe rest of this week was spent wrapping up the analysis, and doing some reading on neural network, and convolutional neural networks 4."
  },
  {
    "objectID": "activity_log/week_14.html#footnotes",
    "href": "activity_log/week_14.html#footnotes",
    "title": "Week 14",
    "section": "",
    "text": "All saved in subdirectory no_roll_data.‚Ü©Ô∏é\nDidn‚Äôt complete. Might have to return later down the line.‚Ü©Ô∏é\nlook at Week 5 for an explanation of this‚Ü©Ô∏é\nDeep learning book (MIT Press) (good for references), Neural networks and deep learning (nicely written), TF tutorial (hands-on)‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_6.html",
    "href": "activity_log/week_6.html",
    "title": "Week 6",
    "section": "",
    "text": "Part of this week was the school of arts‚Äô reading week so I only set out to do a few things."
  },
  {
    "objectID": "activity_log/week_6.html#tasks",
    "href": "activity_log/week_6.html#tasks",
    "title": "Week 6",
    "section": "Tasks",
    "text": "Tasks\n\nUpdate last week‚Äôs plot with axis labels1.\nUpdate PEP‚Äôs docs2.\nRegenerate dataset with new orientation fix3.\nDemo of mean orientation over time4.\nDemo of cluster labelling and size distribution5."
  },
  {
    "objectID": "activity_log/week_6.html#summary",
    "href": "activity_log/week_6.html#summary",
    "title": "Week 6",
    "section": "Summary",
    "text": "Summary\n\nA problem with how the h5 binaries were saved\nWhile doing this, I found out that the matrix is being saved with the background at 0, and the 4 orientation are 0, 1, 2, 3. This means the 0th orientation is confused with the background. To fix this, I modified the image() method of the Lattice object (in lattice.py) to add 1 to the orientation: so they start at 1 (to 4) instead:\ndef image(self) -&gt; np.ndarray:\n    \"\"\"Define the (x,y) lattice array\n\n    :param self: object's attributes\n    :returns: the lattice array [np.ndarray]\n\n    ------\n\n    # Explanation\n\n    Create a matrix of physical size [`n_x`, `n_y`]\n    and fill it as follows:\n\n    * get the coordinates of all particles with positions()\n    * set those coordinates to the orientation\n\n    \"\"\"\n    matrix = np.zeros((self.n_x, self.n_y))\n    x_pos, y_pos = self.positions()\n    matrix[x_pos, y_pos] = self.orientation + 1\n    return matrix\nThus, I had to regenerate all the dataset on BluePebble. Snippet to batch run all SLURM scripts in a directory (I had a separate script for each density):\nfor file in *.sbat; do sbatch $file; done\n\n\nSteady-state in orientation\nHere, I plotted the average orientation of a snapshot, plotting its accumulated mean over time, for this particular dataset, Œ±=0.23\\alpha = 0.23 and œï=0.25\\phi = 0.25.\nThis first part of the code is part of utils.py;\n\n\nCode\nimport os\n\nos.chdir(\"/project/persistent-exclusion-process/\")\nimport re\n\n\nimport h5py\nimport numpy as np\n\n\ndef get_ds_iters(key_list: list) -&gt; list:\n    \"\"\"\n    Get all the unique iteration numbers\n\n\n    :param key_list: a list of all the possible dataset keys/names\n\n\n    :returns: a list of unique iterations\n    \"\"\"\n    iter_n = []\n    for val in key_list:\n        if re.search(\"^conf_\\d+$\", val):\n            iter_n.append(int(val[5:]))\n    return sorted(iter_n)\n\n\ndef get_mean_orientation(file) -&gt; list:\n    \"\"\"\n    Get the mean orientation at each iteration\n\n\n    :param file: the h5 file to open [str]\n    :returns: mean orientation of length 1000 [list]\n    \"\"\"\n    hf = h5py.File(file, \"r\")\n    key_list = list(hf.keys())\n    iter_n = get_ds_iters(key_list)\n    ori = []\n    ori_acm = []\n    for idx, val in enumerate(iter_n):\n        sshot = np.array(hf[f\"conf_{val}\"]).flatten()\n        avg_ori = np.average(sshot[np.where(sshot != 0)[0]] - 1)\n        ori.append(avg_ori)\n        ori_acm.append(np.mean(ori))\n    return ori_acm\n\n\nWe now plot using those two functions:\n\n\nCode\nimport os\nos.chdir(\"/project/persistent-exclusion-process/\")\nimport matplotlib.pyplot as plt\nfrom cmcrameri import cm\n\ndef plot_mean_ori(file, let):\n    cmap = plt.get_cmap(name='cmc.bilbaoS', lut=5)\n    hf = h5py.File(file, \"r\")\n    fig, (ax1, ax2) = plt.subplots(\n        1,\n        2,\n        figsize=(9, 3),\n        width_ratios = [1,1.25],\n        constrained_layout=True\n    )\n    iters = get_ds_iters(hf.keys())\n    fig.colorbar(plt.cm.ScalarMappable(cmap=cmap), ax=ax1)\n    img = hf[f\"conf_{iters[-1]}\"]\n    ax1.matshow(img, cmap=cmap)\n    ax2.set_xlabel(r\"Number of iterations, $N$\")\n    ax2.set_ylabel(\"Average orientation\")\n    ax2.plot(\n        iters,\n        get_mean_orientation(file),\n        c=\"k\",\n    )\n    fig.suptitle(\n        r\"({}) $\\alpha = {}$\".format(let, file[25:30]),\n        x=0.15,\n        ha=\"left\",\n        fontweight=\"bold\"\n    )\n    ax2.grid(alpha=.3)\n    ax2.set_axisbelow(True)\n    plt.show()\n\n\n\n\nCode\nplot_mean_ori('no_roll_data/dataset_tumble_0.023_0.25.h5', \"a\")\nplot_mean_ori('no_roll_data/dataset_tumble_0.500_0.25.h5', \"b\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI think it‚Äôs worth rerunning this analysis where the number of iterations is the same in both (so h5 size and length takes the form of the one with the most iterations, Œ±=0.023\\alpha = 0.023 in this case), just so the x-scale matches.\n\n\nCluster analysis\nThe code below labels clusters.6\n\n\nCode\nimport os\n\nos.chdir(\"/project/persistent-exclusion-process/\")\nfrom scipy import ndimage\n\n\ndef label_cluster(file, let):\n    cmap = plt.get_cmap(name=\"cmc.bilbaoS\", lut=5)\n    cmap_label = plt.get_cmap(name=\"cmc.actonS\")\n    hf = h5py.File(file, \"r\")\n    fig, (ax1, ax2, ax3) = plt.subplots(\n        1,\n        3,\n        figsize=(8, 3),\n        width_ratios=(1, 1, 1.3),\n        constrained_layout=True\n    )\n    iters = get_ds_iters(hf.keys())\n    fig.suptitle(\n        r\"({}) $\\alpha = {}$\".format(let, file[25:30]),\n        x=0.1,\n        ha=\"left\",\n        fontweight=\"bold\",\n    )\n\n    img = hf[f\"conf_{iters[-1]}\"]\n    ax1.matshow(img, cmap=cmap)\n\n    kernel = [[0, 1, 0], [1, 1, 1], [0, 1, 0]]\n    labelled, nlabels = ndimage.label(img, structure=kernel)\n    ax2.matshow(labelled, cmap=cmap_label)\n\n    cluster_sizes = np.bincount(labelled.flatten())[1:]\n    min_c = cluster_sizes.min()\n    max_c = cluster_sizes.max()\n    # one can also make bins in log space,\n    # in Soto (2014) the base range is 1-1.5\n    # bin_edges = np.logspace(\n    #     np.log2(min_c),\n    #     np.log2(max_c),\n    #     30, base=2\n    #)\n    bin_edges = np.linspace(min_c, max_c, 100)\n    counts, _ = np.histogram(cluster_sizes, bins=bin_edges, density=True)\n    ax3.grid(alpha=0.3)\n    ax3.set_axisbelow(True)\n    ax3.scatter(\n        bin_edges[:-1],\n        counts,\n        edgecolor=(0, 0, 0, 1),\n        facecolor=(0, 0, 0, 0.3)\n    )\n    ax3.set_yscale(\"log\"), ax3.set_xscale(\"log\")\n    ax3.set_xlabel(\"Cluster size\")\n\n    fig.colorbar(plt.cm.ScalarMappable(cmap=cmap), ax=ax1)\n    # fig.colorbar(plt.cm.ScalarMappable(cmap=cmap_label), ax=ax2)\n    plt.show()\n\n\n\n\nCode\nlabel_cluster('no_roll_data/dataset_tumble_0.023_0.25.h5', \"a\")\nlabel_cluster('no_roll_data/dataset_tumble_0.500_0.25.h5', \"b\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCluster size distribution\nSteps:\n\nBin data (log?) and get the log-log fit\nPlot all of them on a plot7\n\n\nIn addition, we can also look at how the number of cluster varies.\n\n\nNotes from discussion\n\ncode is already doing a monte carlo sweep (in check c_move in lattice.c) it‚Äôs going through all the particles and move them at random.\ncan check by keeping alpha the same and changing œï\\phi\nFix LL, change NN, the other way around is too painful too\nIf too dilute then training is tricky as there‚Äôs basically no particles\nThere‚Äôs a lower limit minimal œï\\phi that‚Äôs meaningful, below that it isn‚Äôt\nAt low Œ±\\alpha and low œï\\phi what happens?\nIsotropic makes cluster ‚Äúround‚Äù? Not true, we see gelation.\nOver time you find most particles pointing at the centre of the cluster (the argument is to think of a particle pointing in)\n\n\n\nUnits for PEP\n\nTime œÑ\\tau: 1 particle update\nŒ±\\alpha = tumbling rate, Poisson distribution, P(t)=exp(‚àíŒ±t)P(t) = exp(-\\alpha t)\nLattice site = aa\nLength L=128aL = 128a\nœÉparticle=1a\\sigma_\\mathrm{particle} = 1a (particle size)\n\n\n\nA rough condition for percolation\nœÉ/Œ±\\sigma / \\alpha is the persistent length. If this is approximately equal to the system size then percolation occurs.\nPerhaps too strict as the lowest Œ±\\alpha is 0.016, but this is only 62.5/128."
  },
  {
    "objectID": "activity_log/week_6.html#footnotes",
    "href": "activity_log/week_6.html#footnotes",
    "title": "Week 6",
    "section": "",
    "text": "See Week 4.‚Ü©Ô∏é\nREADME.md.‚Ü©Ô∏é\nIt is in the folder ./data.‚Ü©Ô∏é\nSee section Steady-state in orientation.‚Ü©Ô∏é\nSee section Cluster size distribution.‚Ü©Ô∏é\nUsing sample code from this notebook.‚Ü©Ô∏é\nSame values as these, but with the above cluster size analysis for the last iteration of each dataset.‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_19.html",
    "href": "activity_log/week_19.html",
    "title": "Week 19",
    "section": "",
    "text": "Attempt the cluster orientation visualization1.\n\nThis didn‚Äôt really work out, because the clusters have a lot of detailed structure (very fractal), taking only the distance from the centre of mass didn‚Äôt cut it2.\n\nCluster count and biggest cluster size plot3.\n\nNoticed linear-ish relationship between biggest cluster size and the tumbling rate4.\n\nRelaxation time check5.\nMean image plots (+rolling)\n\nAlso in the notebook above. It doesn‚Äôt seem like there are drastic fluctuations, but it is very clear that as Œ±\\alpha gets higher the fluctations get smaller and lower in magnitude.\n\nRetrain each model (now with proper GPU running, finally) with fixed seeds and better learning rates to obtain some averages for comparison.\n\nFor all final runs, see the following notebooks:\n\nWith orientation (low density)\nWith orientation (high density)\nWithout orientation (low density)\nWithout orientation (high density)\nMonochrome (low density)\nMonochrome (high density)\n\n\nVisualize the activation maps6 7."
  },
  {
    "objectID": "activity_log/week_19.html#tasks",
    "href": "activity_log/week_19.html#tasks",
    "title": "Week 19",
    "section": "",
    "text": "Attempt the cluster orientation visualization1.\n\nThis didn‚Äôt really work out, because the clusters have a lot of detailed structure (very fractal), taking only the distance from the centre of mass didn‚Äôt cut it2.\n\nCluster count and biggest cluster size plot3.\n\nNoticed linear-ish relationship between biggest cluster size and the tumbling rate4.\n\nRelaxation time check5.\nMean image plots (+rolling)\n\nAlso in the notebook above. It doesn‚Äôt seem like there are drastic fluctuations, but it is very clear that as Œ±\\alpha gets higher the fluctations get smaller and lower in magnitude.\n\nRetrain each model (now with proper GPU running, finally) with fixed seeds and better learning rates to obtain some averages for comparison.\n\nFor all final runs, see the following notebooks:\n\nWith orientation (low density)\nWith orientation (high density)\nWithout orientation (low density)\nWithout orientation (high density)\nMonochrome (low density)\nMonochrome (high density)\n\n\nVisualize the activation maps6 7."
  },
  {
    "objectID": "activity_log/week_19.html#summary",
    "href": "activity_log/week_19.html#summary",
    "title": "Week 19",
    "section": "Summary",
    "text": "Summary\n\nCan the neural network learn?\nYes, that is clear\n\n\nHow relevant is orientation/DOF (a dynamical feature) in the learning of dissipation?\n\nHypothesis: there are no difference in performance between two models, where one is trained on data where orientation is embedded, and one where it isn‚Äôt.\nRigour: 10 independent models for each (so 20 different models, and 10 seeds, one for each pair).\nDataset: 1000 per tumbling rate, each augmented twice, giving 3000 configurations. For all densities, this gives 30000, where 24000 goes to training, and 6000 goes to validation.\nData preparation:\n\nFor model on orientation: leave as is. Call this (x).\nFor model without: where the orientations are effectively removed by reassigning each particle a random orientation, out of the same pool (i.e.¬†it is scrambled, but with a new instance), for each image (out of 3000), the noise is regenerated. Call this (y).\n\nWhy not threshold? Seems to tamper with the original configuration too much. Network fails to predict potentially because with black and white, it only learns to differentiate the background.\nMethod:\n\nA model has been designed to minimize computationl expense but still has some depth.\nTrain model 1, predict using (x) original dataset, then predict with (y) dataset prepared for model 2. Train model 2, predict using original dataset.\n\nIntuition:\n\nThe cluster edges point towards the centre of the cluster.\nThis could be picked up by the neural network as a dynamical feature of clusters.\nThis additional information, alongside their structure, can be used to predict dissipation.\nTherefore, (1x) should perform better than (1y).\nBecause we have made the distribution of the orientation the same for the scrambled dataset (but not their configuration), (2x) should perform just as well as (2y).\n\nConclusion:\n\nOrientation is picked up by the neural network.\nThe standard deviation for (1x) is better than (2y) at higher tumbling rates.\nAt low tumbling rates, they are effectively equal, meaning the structural configuration has more weight. For Œ±\\alpha below ‚âà0.107\\approx 0.107, their performances are comparable.\nFor what it‚Äôs worth, the predictions are good enough to differentiate very from mildly active systems, and we can always benefit more from a larger sample size plus more tumbling rate, as well as tune the whole architecture better, to improve the metrics.\nThe key takeaway is that there is not a substantial improvement to performance trained on orientation at this level and scale, and thus the static configuration is adequate in giving a prediction of the level of activity where it might matter?\n\n\n\n\nWhat happens when the packing fraction is increased?\n\nIt seems like the spread is lower, I have yet to discuss this but I think it‚Äôs due to the presence of more clusters overall, and the model is somehow bias towards seeing clusters (but not seeing the lack of clusters)8."
  },
  {
    "objectID": "activity_log/week_19.html#footnotes",
    "href": "activity_log/week_19.html#footnotes",
    "title": "Week 19",
    "section": "",
    "text": "Resulting code and plots here.‚Ü©Ô∏é\nPerhaps there is a better way, without isolating single clusters (to discuss with FT).‚Ü©Ô∏é\nPlots here.‚Ü©Ô∏é\nIt does correlate with cluster distribution grid plotted here.‚Ü©Ô∏é\nPlots here (will change and undergo revisions for report).‚Ü©Ô∏é\nA guide on visualizing feature maps. The code isn‚Äôt entirely correct but I adapted it.‚Ü©Ô∏é\nDemo notebook here‚Ü©Ô∏é\nI need to figure out why there is underfitting at higher tumbling rates. Update: I think it‚Äôs most likely due to log-spaced samples‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_18.html",
    "href": "activity_log/week_18.html",
    "title": "Week 18",
    "section": "",
    "text": "Establish whether training on orientation makes the model confused when feeding it srambled data as a follow up to last week‚Äôs degrees of freedom discussion1.\nMake violin plots (and update previous plots to reflect this)2.\n\nIncorporated into this week‚Äôs work. Updated code (training_utils.py) to add the violin plots.\n\nIsolate a cluster and look at it3.\nPercolation?4."
  },
  {
    "objectID": "activity_log/week_18.html#tasks",
    "href": "activity_log/week_18.html#tasks",
    "title": "Week 18",
    "section": "",
    "text": "Establish whether training on orientation makes the model confused when feeding it srambled data as a follow up to last week‚Äôs degrees of freedom discussion1.\nMake violin plots (and update previous plots to reflect this)2.\n\nIncorporated into this week‚Äôs work. Updated code (training_utils.py) to add the violin plots.\n\nIsolate a cluster and look at it3.\nPercolation?4."
  },
  {
    "objectID": "activity_log/week_18.html#summary",
    "href": "activity_log/week_18.html#summary",
    "title": "Week 18",
    "section": "Summary",
    "text": "Summary\n\nConfusion experiment\nFrom the previous week, training a network on ‚Äúblack and white‚Äù data leads to no regression when predicting ‚Äúcolor‚Äù data5. We now ask the question, had the ‚Äúblack and white‚Äù data contain ‚Äúorientation‚Äù color instead, but the orientation is randomly placed, rather than obtained from the evolution of the system, would it perform better when we predict ‚Äúcolor‚Äù?\nWe can also compare this ‚Äúscrambled‚Äù data to genuine ‚Äúcolor‚Äù data (i.e.¬†where the orientation comes from the dynamics of the system). For this, we devise to experiments:\nHypothesis: Predicting genuine color data with a model trained on scrambled data should perform the same as predicting with the same scrambled data. We expect this because we expect the orientation distribution for each to match (uniform between 1-4 up to normalization). We expect predicting confused data with a model trained on genuine color data would (1) yield worse predictions (according to our metrics) if the orientation is picked up by the model as a property of the system (as patterns of cluster formation, which hints at the tumbling rate), and (2) yield no improvement if the orientation is not picked up by the model as a property the system.\n\nExperiment 1a: inject into the model information on the 4 degrees of freedom and predict with a dataset where the orientation is fully scrambled.\n\nOutcome: predictions have roughly the same spread but their centres are substantially off\nModels: magic7474\n\nExperiment 1b: train only on scrambled/confused data and predict with a dataset where the orientation is genuine.\n\nOutcome: predictions have roughly the same spread and same centres\nModels: ring1111\n\n\nConclusion: orientation is picked up as a feature of the system. Although training without orientation, but where the noise is random, provides good prediction of images with real orientation injected anyway. Albeit, the model does moderately well at low tumbling rate, indicating that it does ‚Äúconfuse‚Äù orientation a bit.\n\nPlots for training with orientation\nTrained on SGD, with a learning rate of 0.008, for 45 epochs.\n\n\n2024-03-05 14:29:16.648463: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-03-05 14:29:17.151662: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\nWith the same data\n\n\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n\n\n188/188 [==============================] - 3s 15ms/step\nOverlap ratio: 0.7\n(Min, Max, Avg) STD: 0.0022823645 0.035767958 0.011195814\nPearson's correlation coeff:  0.9922203197613441\nOverlap ratio: 0.7\n(Min, Max, Avg) STD: 0.0022823645 0.035767958 0.011195814\nPearson's correlation coeff:  0.9922203197613441\n\n\n\n\n\n\n\n\n\nOrientation scrambled\n\n\n25/25 [==============================] - 0s 16ms/step\nOverlap ratio: 0.0\n(Min, Max, Avg) STD: 0.0026376054 0.03763844 0.013460962\nPearson's correlation coeff:  0.9485194294783785\nOverlap ratio: 0.0\n(Min, Max, Avg) STD: 0.0026376054 0.03763844 0.013460962\nPearson's correlation coeff:  0.9485194294783785\n\n\n\n\n\n\n\n\n\nWith orientation scrambled, the model trained on orientation seems to overpredict the orientations, it seems to have gotten close for 0.5, but for the central Œ±\\alpha‚Äôs, it does very poorly.\n\n\nPlots for training with confused data\nWith the same data\n\n\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n188/188 [==============================] - 3s 15ms/step\nOverlap ratio: 0.9\n(Min, Max, Avg) STD: 1.8626451e-09 0.04303491 0.015331155\nPearson's correlation coeff:  0.9794483339595415\nOverlap ratio: 0.9\n(Min, Max, Avg) STD: 1.8626451e-09 0.04303491 0.015331155\nPearson's correlation coeff:  0.9794483339595415\n\n\n2024-02-29 16:24:15.451320: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n\n\n\n\n\n\n\n\n\nWith data with genuine orientation\n\n\n25/25 [==============================] - 0s 15ms/step\nOverlap ratio: 0.8\n(Min, Max, Avg) STD: 1.8626451e-09 0.03673462 0.014396628\nPearson's correlation coeff:  0.9799307539609515\nOverlap ratio: 0.8\n(Min, Max, Avg) STD: 1.8626451e-09 0.03673462 0.014396628\nPearson's correlation coeff:  0.9799307539609515\n\n\n\n\n\n\n\n\n\n\n\n\nViolin plots\nfig, ax = plt.subplots(figsize=(9, 6))\nsns.violinplot(\n    ax=ax,\n    data=df,\n    x=\"actual\",\n    y=\"predicted\",\n    color=\"w\",\n    alpha=0.7,\n    density_norm=\"width\",\n    linewidth=1,\n    inner=\"box\",\n    inner_kws={\"box_width\": 4, \"color\": \"0.2\"},\n)\nax.set(xlabel=r\"Tumbling rates, $\\alpha$\", ylabel=r\"Error, $y_p - y_a$\")\nReasoning for plotting the error is for a less cluttered look.\n\n\nIsolate cluster\nTechnically the biggest cluster here, but can do for any label ID.\ndef get_biggest_cluster(img):\n    labelled, _ = ndimage.label(img, structure=kernel)\n    lb = labelled.flatten()\n    cluster_sizes = np.bincount(lb)[1:]\n    biggest_cluster_id = np.argmax(cluster_sizes)\n    loc = ndimage.find_objects(labelled)[biggest_cluster_id]\n    labelled_crop = labelled[loc]\n    img_crop = img[loc]\n    labelled_crop[labelled_crop != biggest_cluster_id+1] = 0\n    labelled_crop[labelled_crop == biggest_cluster_id+1] = 1\n    img_crop *= labelled_crop\n    return img_crop, ndimage.center_of_mass(labelled_crop)\nWhich gives something like (uncropped version):\n\n\n\nThe biggest_cluster of a snapshot, isolated\n\n\nIt might be useful for visualization later when writing the report, I intend to somehow visualize the distribution of orientation to express quantitatively that models trained on orientation can pick up this information."
  },
  {
    "objectID": "activity_log/week_18.html#footnotes",
    "href": "activity_log/week_18.html#footnotes",
    "title": "Week 18",
    "section": "",
    "text": "See section Confusion experiment for further details and plots.‚Ü©Ô∏é\nSee section Violin plot code for the snippet.‚Ü©Ô∏é\nSee section Isolate cluster for snippet.‚Ü©Ô∏é\nDidn‚Äôt attempt still.‚Ü©Ô∏é\nMore detail here‚Ü©Ô∏é"
  },
  {
    "objectID": "activity_log/week_1.html",
    "href": "activity_log/week_1.html",
    "title": "Week 1",
    "section": "",
    "text": "Catch up on background reading\nSet up electronic notebook\nSet up git repository for shared knowledge\n\nPersonal logs and files in .gitignore\nHow to resolve conflicts? Avoid editing at the same time?\nWhere to host? Private GitHub repo?\n\nSet up a GitHub organisation (a single repo might not cover the whole project). To be discussed when a more concrete project is decided."
  },
  {
    "objectID": "activity_log/week_1.html#tasks",
    "href": "activity_log/week_1.html#tasks",
    "title": "Week 1",
    "section": "",
    "text": "Catch up on background reading\nSet up electronic notebook\nSet up git repository for shared knowledge\n\nPersonal logs and files in .gitignore\nHow to resolve conflicts? Avoid editing at the same time?\nWhere to host? Private GitHub repo?\n\nSet up a GitHub organisation (a single repo might not cover the whole project). To be discussed when a more concrete project is decided."
  },
  {
    "objectID": "activity_log/week_1.html#summary",
    "href": "activity_log/week_1.html#summary",
    "title": "Week 1",
    "section": "Summary",
    "text": "Summary\n\nThere were some texts to read through, we were also given a brief of the project and different directions we can take it.\nWe agreed to make an electronic notebook using Quarto and git1."
  },
  {
    "objectID": "activity_log/week_1.html#footnotes",
    "href": "activity_log/week_1.html#footnotes",
    "title": "Week 1",
    "section": "",
    "text": "Brief guide documenting how to set it up is found here.‚Ü©Ô∏é"
  },
  {
    "objectID": "training/visualize_without_orientation.html",
    "href": "training/visualize_without_orientation.html",
    "title": "Visualizing CNN layers without orientation",
    "section": "",
    "text": "Code\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nos.chdir(\"/project/persistent-exclusion-process\")\n\nimport h5py\nimport numpy as np\n\nimport tensorflow as tf\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\nfrom numpy import expand_dims\n\nfrom src.utils import get_cluster_labels, get_ds_iters\nfrom src.training_utils import (\n    data_load,\n    split_dataset,\n)\nfrom src.plot_utils import get_plot_configs\n\n\n2024-03-22 17:47:24.004793: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-03-22 17:47:24.505489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\n\n\nCode\nhf = h5py.File(f\"no_roll_data/dataset_tumble_0.016_0.25.h5\", \"r\")\niters = get_ds_iters(hf.keys())\nimg = hf[f\"conf_{iters[300]}\"]\nimg = np.array(img)\nimg[img &gt; 0] = 1\nimg = img * np.random.randint(1, 5, size=(128, 128)) / 4\nimg = img.reshape((img.shape[0], img.shape[1], 1))\n\nhf = h5py.File(f\"no_roll_data/dataset_tumble_0.500_0.25.h5\", \"r\")\niters = get_ds_iters(hf.keys())\nimg2 = hf[f\"conf_{iters[300]}\"]\nimg2 = np.array(img2)\nimg2[img2 &gt; 0] = 1\nimg2 = img2 * np.random.randint(1, 5, size=(128, 128)) / 4\nimg2 = img2.reshape((img2.shape[0], img2.shape[1], 1))\n\n\n\n\nCode\nplt.matshow(img, cmap='gray')\nplt.matshow(img2, cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel = tf.keras.models.load_model('models/red9392.keras')\n\n\n2024-03-22 17:47:28.444277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:47:28.455724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:47:28.455903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:47:28.456447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:47:28.456586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:47:28.456709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:47:28.504587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:47:28.504797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:47:28.504970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:47:28.505113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 131 MB memory:  -&gt; device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:07:00.0, compute capability: 7.5\n2024-03-22 17:47:28.515604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:753] failed to allocate 131.88MiB (138280960 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n2024-03-22 17:47:28.515664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:753] failed to allocate 118.69MiB (124452864 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[0].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 3\nshift = None\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n2024-03-22 17:47:06.964519: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n2024-03-22 17:47:06.964572: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 22216704 bytes free, 6198984704 bytes total.\n2024-03-22 17:47:06.964587: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at conv_ops_impl.h:770 : UNIMPLEMENTED: DNN library is not found.\n\n\nUnimplementedError: Graph execution error:\n\nDetected at node 'model_1/conv2d/Conv2D' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 18, in &lt;module&gt;\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2150/3177651713.py\", line 5, in &lt;module&gt;\n      feature_maps1 = model_mini.predict(img, verbose=0)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2554, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2341, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2327, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2315, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2283, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_1/conv2d/Conv2D'\nDNN library is not found.\n     [[{{node model_1/conv2d/Conv2D}}]] [Op:__inference_predict_function_1093]\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[1].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 3\nshift = 64\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n2024-03-22 17:47:07.817029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n2024-03-22 17:47:07.919779: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:190] failed to create cublas handle: the resource allocation failed\n2024-03-22 17:47:07.919802: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:193] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n2024-03-22 17:47:07.926896: E tensorflow/compiler/xla/stream_executor/dnn.cc:1133] CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(7321): 'cudnnPoolingForward( cudnn.handle(), pooling_desc.handle(), alpha, src_desc.handle(), input_ptr, beta, dest_desc.handle(), output_ptr)'\n2024-03-22 17:47:07.926923: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at pooling_ops_common.cc:416 : UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(7321): 'cudnnPoolingForward( cudnn.handle(), pooling_desc.handle(), alpha, src_desc.handle(), input_ptr, beta, dest_desc.handle(), output_ptr)'\n\n\nUnknownError: Graph execution error:\n\nDetected at node 'model_2/max_pooling2d/MaxPool' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 18, in &lt;module&gt;\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2150/2744020825.py\", line 5, in &lt;module&gt;\n      feature_maps1 = model_mini.predict(img, verbose=0)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2554, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2341, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2327, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2315, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2283, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/pooling/base_pooling2d.py\", line 84, in call\n      outputs = self.pool_function(\nNode: 'model_2/max_pooling2d/MaxPool'\nCUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(7321): 'cudnnPoolingForward( cudnn.handle(), pooling_desc.handle(), alpha, src_desc.handle(), input_ptr, beta, dest_desc.handle(), output_ptr)'\n     [[{{node model_2/max_pooling2d/MaxPool}}]] [Op:__inference_predict_function_1179]\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[2].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 3\nshift = 64\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[4].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 4\nshift = 64\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[5].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 4\nshift = 32\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[6].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 4\nshift = 32\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[8].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 6\nshift = 32\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[9].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 6\nshift = 16\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[10].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 6\nshift = 16\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[13].output)\n\nfeature_maps1 = model_mini.predict(x1[0], verbose=0)\nfeature_maps2 = model_mini.predict(x2[0], verbose=0)\n\nplt.matshow(np.rot90(feature_maps1[:, :]))\nplt.matshow(np.rot90(feature_maps2[:, :]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[14].output)\n\nfeature_maps1 = model_mini.predict(x1[0], verbose=0)\nfeature_maps2 = model_mini.predict(x2[0], verbose=0)\n\nplt.matshow(feature_maps1[:, :])\nplt.matshow(feature_maps2[:, :])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[16].output)\n\nfeature_maps1 = model_mini.predict(x1[0], verbose=0)\nfeature_maps2 = model_mini.predict(x2[0], verbose=0)\n\nplt.matshow(np.rot90(feature_maps1[:, :]))\nplt.matshow(np.rot90(feature_maps2[:, :]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[18].output)\n\nfeature_maps1 = model_mini.predict(x1[0], verbose=0)\nfeature_maps2 = model_mini.predict(x2[0], verbose=0)\n\nplt.matshow(np.rot90(feature_maps1[:, :]))\nplt.matshow(np.rot90(feature_maps2[:, :]))"
  },
  {
    "objectID": "training/training_summary_hi.html",
    "href": "training/training_summary_hi.html",
    "title": "Training summary (high density)",
    "section": "",
    "text": "Code\n%load_ext autoreload\n%autoreload 2\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport os\n\nos.chdir(\"/project/persistent-exclusion-process/\")\n\nimport gc\n\nimport numpy as np\nimport h5py\nimport glob\nimport re\nimport tensorflow as tf\nfrom cmcrameri import cm\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom matplotlib.patches import Patch\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.ticker as ticker\n\nfrom src.training_utils import (\n    extract_floats,\n    data_load,\n    split_dataset,\n    predict_multi_by_name,\n    predict_and_plot,\n    plot_violin_and_statistics\n)\nfrom src.models import make_net\nfrom src.plot_utils import get_plot_configs\n\nnp.set_printoptions(precision=3, suppress=True)\ngpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device, True)\nprint(gpu_devices)"
  },
  {
    "objectID": "training/training_summary_hi.html#self-prediction",
    "href": "training/training_summary_hi.html#self-prediction",
    "title": "Training summary (high density)",
    "section": "Self-prediction",
    "text": "Self-prediction\n\n\nCode\ntumbles = np.logspace(-6, -1, 10, base=2) # here are all the alphas available\n\nx,y,_ = data_load(alphas=tumbles, densities=[0.5], orientation=True, series=\"validation_data\")\n_, _, x_val, y_val = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_with_orientation = [\n    \"hi_helicopter1822\",\n    \"hi_wardrobe9539\",\n    \"hi_looper2409\",\n    \"hi_potato8290\",\n    \"hi_cells9177\",\n    \"hi_hyphen1065_tuned\",\n    \"hi_playground6730_tuned\",\n    \"hi_blue9392\",\n    \"hi_alkaline7391_tuned\",\n    \"hi_cold6626\"\n]\n\npredictions_with_orientation, actual_with_orientation = predict_multi_by_name(model_names_with_orientation, x_val, y_val)\ndel x_val\ndel y_val\ngc.collect()\n\n\n\n\nCode\ngc.collect()\nx,y,_ = data_load(alphas=tumbles, densities=[0.5], orientation=False, scrambled=True,  series=\"validation_data\")\n_, _, x_val2, y_val2 = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_without_orientation = [\n    \"hi_ice1822\",\n    \"hi_house9539\",\n    \"hi_cake2409\",\n    \"hi_carrot8290\",\n    \"hi_virus9177\",\n    \"hi_comma1065\",\n    \"hi_toys6730\",\n    \"hi_red9392\",\n    \"hi_acid7391\",\n    \"hi_hot6626\",\n]\n\npredictions_without_orientation, actual_without_orientation = predict_multi_by_name(model_names_without_orientation, x_val2, y_val2)\ndel x_val2\ndel y_val2\ngc.collect()\n\n\n\n\nCode\ngc.collect()\nx,y,_ = data_load(alphas=tumbles, densities=[0.5], orientation=False, scrambled=False,  series=\"validation_data\")\n_, _, x_val2, y_val2 = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_with_monochrome = [\n    \"hi_boat1822\",\n    \"hi_door9539\",\n    \"hi_muffin2409\",\n    \"hi_yam8290\",\n    \"hi_bacteria9177\",\n    \"hi_slash1065\",\n    \"hi_pool6730\",\n    \"hi_green9392\",\n    \"hi_neutral7391\",\n    \"hi_lukewarm6626\",\n]\n\npredictions_with_monochrome, actual_with_monochrome = predict_multi_by_name(model_names_with_monochrome, x_val2, y_val2)\ndel x_val2\ndel y_val2\ngc.collect()\n\n\n\n\nCode\ndf = pd.DataFrame(\n    {\n        \"Predicted\": np.concatenate(\n            (\n                predictions_with_orientation,\n                predictions_without_orientation,\n                predictions_with_monochrome,\n            )\n        ),\n        \"Actual\": np.concatenate((actual_with_orientation, actual_without_orientation, actual_with_monochrome)),\n        \"Context\": pd.Categorical(\n            [\"Trained with orientation\"] * len(actual_with_orientation)\n            + [\"Trained without orientation\"] * len(actual_without_orientation)\n            + [\"Trained with thresholding\"] * len(actual_with_monochrome),\n            categories=[\"Trained with orientation\", \"Trained without orientation\", \"Trained with thresholding\"],\n        ),\n    }\n)\n\ndf2 = pd.DataFrame(\n    {\n        \"STD\": np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .std()[\"Predicted\"],\n                df.query('Context == \"Trained without orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .std()[\"Predicted\"],\n                df.query('Context == \"Trained with thresholding\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .std()[\"Predicted\"],\n            )\n        ),\n        \"Mean\": np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .mean()[\"Predicted\"],\n                df.query('Context == \"Trained without orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .mean()[\"Predicted\"],\n                df.query('Context == \"Trained with thresholding\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .mean()[\"Predicted\"],\n            )\n        ),\n        \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 3),\n        \"Context\": pd.Categorical(\n            [\"Trained with orientation\"] * 10 + [\"Trained without orientation\"] * 10 + [\"Trained with thresholding\"] * 10,\n            categories=[\"Trained with orientation\", \"Trained without orientation\", \"Trained with thresholding\"],\n        ),\n    }\n)\n\n\n\n\nCode\ndf.to_csv(\"cache/model_summary_hi.csv\")\ndf2.to_csv(\"cache/model_summary_std_hi.csv\")\n\n\n\n\nCode\ndel predictions_without_orientation\ndel actual_without_orientation\ndel predictions_with_orientation\ndel actual_with_orientation\ndel predictions_with_monochrome\ndel actual_with_monochrome\ndel df\ndel df2\ngc.collect()"
  },
  {
    "objectID": "training/training_summary_hi.html#cross-predictions",
    "href": "training/training_summary_hi.html#cross-predictions",
    "title": "Training summary (high density)",
    "section": "Cross predictions",
    "text": "Cross predictions\n\nMonochrome on orientation\n\n\nCode\ntumbles = np.logspace(-6, -1, 10, base=2) # here are all the alphas available\n\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=False, scrambled=False, series=\"validation_data\")\n_, _, x_val, y_val = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_with_orientation = [\n    \"helicopter1822\",\n    \"wardrobe9539\",\n    \"looper2409\",\n    \"potato8290\",\n    \"cells9177\",\n    \"hyphen1065\",\n    \"playground6730\",\n    \"blue9392\",\n    \"alkaline7391\",\n    \"cold6626\"\n]\n\npredictions_with_orientation, actual_with_orientation = predict_multi_by_name(model_names_with_orientation, x_val, y_val)\ndel x_val\ndel y_val\ngc.collect()\n\n\n\n\nCode\ngc.collect()\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=True, series=\"validation_data\")\n_, _, x_val2, y_val2 = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_without_orientation = [\n    \"boat1822\",\n    \"door9539\",\n    \"muffin2409\",\n    \"yam8290\",\n    \"bacteria9177\",\n    \"slash1065\",\n    \"pool6730\",\n    \"green9392\",\n    \"neutral7391\",\n    \"lukewarm6626\",\n]\n\npredictions_without_orientation, actual_without_orientation = predict_multi_by_name(model_names_without_orientation, x_val2, y_val2)\ndel x_val2\ndel y_val2\ngc.collect()\n\n\n\n\nCode\ndf = pd.DataFrame({\"Predicted\": np.concatenate((predictions_with_orientation-actual_with_orientation, predictions_without_orientation-actual_without_orientation)),\n                   \"Actual\": np.concatenate((actual_with_orientation,actual_without_orientation)),\n                   \"Context\": pd.Categorical([\"Trained with orientation\"]*len(actual_with_orientation)+[\"Trained with thresholding\"]*len(actual_without_orientation),\n                                             categories=[\"Trained with orientation\", \"Trained with thresholding\"])\n                  })\ndf2 = pd.DataFrame({\"STD\": np.concatenate((df.query('Context == \"Trained with orientation\"').groupby(\"Actual\", as_index=False)[\"Predicted\"].std()['Predicted'],\n                                           df.query('Context == \"Trained with thresholding\"').groupby(\"Actual\", as_index=False)[\"Predicted\"].std()['Predicted'])),\n                    \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 2),\n                    \"Context\": pd.Categorical([\"Trained with orientation\"]*10+[\"Trained with thresholding\"]*10,\n                                             categories=[\"Trained with orientation\", \"Trained with thresholding\"])\n                   })\n\n\n\n\nCode\ndf.to_csv(\"cache/model_summary_cross_2.csv\")\ndf2.to_csv(\"cache/model_summary_std_cross_2.csv\")\n\n\n\n\nScrambled on orientation\n\n\nCode\ntumbles = np.logspace(-6, -1, 10, base=2) # here are all the alphas available\n\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=False, scrambled=True, series=\"validation_data\")\n_, _, x_val, y_val = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_with_orientation = [\n    \"helicopter1822\",\n    \"wardrobe9539\",\n    \"looper2409\",\n    \"potato8290\",\n    \"cells9177\",\n    \"hyphen1065\",\n    \"playground6730\",\n    \"blue9392\",\n    \"alkaline7391\",\n    \"cold6626\"\n]\n\npredictions_with_orientation, actual_with_orientation = predict_multi_by_name(model_names_with_orientation, x_val, y_val)\ndel x_val\ndel y_val\ngc.collect()\n\n\n\n\nCode\ngc.collect()\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=True, series=\"validation_data\")\n_, _, x_val2, y_val2 = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_without_orientation = [\n    \"ice1822\",\n    \"house9539\",\n    \"cake2409\",\n    \"carrot8290\",\n    \"virus9177\",\n    \"comma1065\",\n    \"toys6730\",\n    \"red9392\",\n    \"acid7391\",\n    \"hot6626\",\n]\n\npredictions_without_orientation, actual_without_orientation = predict_multi_by_name(model_names_without_orientation, x_val2, y_val2)\ndel x_val2\ndel y_val2\ngc.collect()\n\n\n\n\nCode\ndf = pd.DataFrame({\"Predicted\": np.concatenate((predictions_with_orientation-actual_with_orientation, predictions_without_orientation-actual_without_orientation)),\n                   \"Actual\": np.concatenate((actual_with_orientation,actual_without_orientation)),\n                   \"Context\": pd.Categorical([\"Trained with orientation\"]*len(actual_with_orientation)+[\"Trained without orientation\"]*len(actual_without_orientation),\n                                             categories=[\"Trained with orientation\", \"Trained without orientation\"])\n                  })\ndf2 = pd.DataFrame({\"STD\": np.concatenate((df.query('Context == \"Trained with orientation\"').groupby(\"Actual\", as_index=False)[\"Predicted\"].std()['Predicted'],\n                                           df.query('Context == \"Trained without orientation\"').groupby(\"Actual\", as_index=False)[\"Predicted\"].std()['Predicted'])),\n                    \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 2),\n                    \"Context\": pd.Categorical([\"Trained with orientation\"]*10+[\"Trained without orientation\"]*10,\n                                             categories=[\"Trained with orientation\", \"Trained without orientation\"])\n                   })\n\n\n\n\nCode\ndf.to_csv(\"cache/model_summary_cross.csv\")\ndf2.to_csv(\"cache/model_summary_std_cross.csv\")\n\n\n\n\nCode\ndel predictions_without_orientation\ndel actual_without_orientation\ndel predictions_with_orientation\ndel actual_with_orientation\ndel df\ndel df2\ngc.collect()"
  },
  {
    "objectID": "training/training_summary_hi.html#plots",
    "href": "training/training_summary_hi.html#plots",
    "title": "Training summary (high density)",
    "section": "Plots",
    "text": "Plots\n\n\nCode\ndf = pd.read_csv(\"cache/model_summary_hi.csv\")\ndf2 = pd.read_csv(\"cache/model_summary_std_hi.csv\")\n#df3 = pd.read_csv(\"cache/model_summary_cross.csv\")\n#df4 = pd.read_csv(\"cache/model_summary_std_cross.csv\")\n#df5 = pd.read_csv(\"cache/model_summary_cross_2.csv\")\n#df6 = pd.read_csv(\"cache/model_summary_std_cross_2.csv\")\n\n\n\n\nCode\nplot_configs = get_plot_configs()\nsns.set(rc=plot_configs)\nsns.set_style(\"ticks\")\nsns.set_style({\"xtick.direction\": \"in\", \"ytick.direction\": \"in\"})\n\n\nplt.rcParams.update(plot_configs)\n\n\nfig, axes = plt.subplots(\n    3, 1, figsize=(4.25, 7), constrained_layout=True, sharex=True\n)\n(ax1, ax2, ax3) = axes\n\npalette ={\"Trained with orientation\": cm.glasgow(0), \"Trained without orientation\": cm.glasgow(60), \"Trained with thresholding\": cm.glasgow(200)}\n\nsns.boxplot(\n    ax=ax1,\n    data=df,\n    x=\"Actual\",\n    y=\"Predicted\",\n    hue=\"Context\",\n    palette=palette,\n    native_scale=True,\n    dodge=True,\n    whis=(0,100),\n    linecolor=(0,0,0,0),\n    log_scale=(True,False),\n    fill=True,\n    legend=False,\n)\nfor patch in ax1.patches:\n    r, g, b, a = patch.get_facecolor()\n    patch.set_facecolor((r, g, b, .5))\nsns.boxplot(\n    ax=ax1,\n    data=df,\n    x=\"Actual\",\n    y=\"Predicted\",\n    hue=\"Context\",\n    palette=palette,\n    native_scale=True,\n    dodge=True,\n    whis=(0,100),\n    log_scale=(True,False),\n    fill=False,\n    legend=False,\n)\n\nax2.axhline(0.015, c='0.9')\nax2.text(s=r\"$\\sigma = 0.15$\", x=0.014, y=0.016)\n\ncontexts = [\"Trained with orientation\", \"Trained without orientation\", \"Trained with thresholding\"]\nfor idx in range(3):\n    context = contexts[idx]\n    a, b = np.polyfit(np.log(df2[df2['Context'] == context]['Actual'][:6]),df2[df2['Context'] == context]['STD'][:6],1)\n    sns.lineplot(\n        ax=ax2,\n        x=df2[df2['Context'] == context]['Actual'][:6],\n        y=np.log(df2[df2['Context'] == context]['Actual'][:6])*a+b,\n        color=palette[context],\n        linestyle='-'\n    )\n    print(a,b)\n\n# ------------\n\ncontexts = [\"Trained with orientation\", \"Trained without orientation\", \"Trained with thresholding\"]\nfor idx in range(3):\n    context = contexts[idx]\n    a, b = np.polyfit(np.log(df2[df2['Context'] == context]['Actual'][6:]),df2[df2['Context'] == context]['STD'][6:],1)\n    sns.lineplot(\n        ax=ax2,\n        x=df2[df2['Context'] == context]['Actual'][6:],\n        y=np.log(df2[df2['Context'] == context]['Actual'][6:])*a+b,\n        color=palette[context],\n        linestyle='dashed'\n    )\n    print(a,b)\n\n\nsns.scatterplot(\n    ax=ax2,\n    data=df2,\n    x=\"Actual\",\n    y=\"STD\",\n    hue=\"Context\",\n    palette=palette,\n    alpha=.7,\n    marker='o',\n    ec='k',\n    legend=False,\n    zorder=10\n)\n\n\nsns.despine()\n\n\ntumbles = np.logspace(-6, -1, 10, base=2)\n\npalette2 ={\"None\": cm.glasgow(0), \"Random DOF\": cm.glasgow(60), \"Threshold\": cm.glasgow(200)}\nhandles = [\n    Patch(\n        edgecolor=color,\n        facecolor=(color[0], color[1], color[2], 0.5),\n        label=label,\n        linewidth=1.5\n    ) \n    for label, color in palette2.items()\n]\n\nax1.legend(handles=handles, frameon=False, loc='center left', fontsize=14, title=\"Data processing\");\n\nax1.set_xlim(left=0.012)\n\nfor idx, ax in enumerate(axes.ravel()):\n    ax.set_xlabel(r\"Actual tumbling rate, $\\alpha_a$\")\n    ax.set_xscale(\"log\")\n    ax.get_xaxis().set_major_formatter(ticker.ScalarFormatter())\n    ax.set_xticks(np.round(np.unique(tumbles)[::2],3))\n\ndfs = pd.read_csv(\"cache/cluster_count_size_0.25.csv\")\nsns.lineplot(ax=ax3, data=dfs, x=\"alpha\", y=\"bigsize\", errorbar=\"sd\", marker='o', c='darkred', legend=False)\nax1.set_ylabel(r\"Abs. error $|\\alpha_p - \\alpha_a|$\")\nax2.set_ylabel(r\"Std. of abs. error\")\nax3.set_yscale('log')\nax3.set_ylabel(r\"$V_{\\bf max}$ $/a^2$\")\n#ax3.set_yticks([10**1,10**2])\nfig.text(s=f\"(A)\", x=0.22, y=.96, fontsize='large')\nfig.text(s=f\"(B)\", x=0.22, y=.65, fontsize='large')\nfig.text(s=f\"(C)\", x=0.22, y=.33, fontsize='large', backgroundcolor=(1,1,1,0.7))\n\n\n0.0038699984365321983 0.02055735951378232\n0.004025508408667139 0.021039929460911523\n0.0033388582006959864 0.01836724020452017\n0.019757872291390102 0.056239914819598204\n0.018382425347697896 0.05453731644898653\n0.0190681707234639 0.05188576025888323\n\n\nText(0.22, 0.33, '(C)')\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig.savefig(\"plots/orientation_summary_box_0.5.pdf\")"
  },
  {
    "objectID": "training/training_with_orientation.html",
    "href": "training/training_with_orientation.html",
    "title": "Training with orientation",
    "section": "",
    "text": "Full code\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n0"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-1-helicopter1822",
    "href": "training/training_with_orientation.html#orientation-1-helicopter1822",
    "title": "Training with orientation",
    "section": "Orientation 1 (helicopter1822)",
    "text": "Orientation 1 (helicopter1822)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0\n0.041789744\n0.017508134\n0.9818550607118115"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-2-wardrobe9539",
    "href": "training/training_with_orientation.html#orientation-2-wardrobe9539",
    "title": "Training with orientation",
    "section": "Orientation 2 (wardrobe9539)",
    "text": "Orientation 2 (wardrobe9539)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.004203011\n0.055231284\n0.02021673\n0.9784101390618816"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-3-looper2409",
    "href": "training/training_with_orientation.html#orientation-3-looper2409",
    "title": "Training with orientation",
    "section": "Orientation 3 (looper2409)",
    "text": "Orientation 3 (looper2409)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.8\n1.8626451e-09\n0.0411429\n0.016491443\n0.9773964759075522"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-4-potato8290",
    "href": "training/training_with_orientation.html#orientation-4-potato8290",
    "title": "Training with orientation",
    "section": "Orientation 4 (potato8290)",
    "text": "Orientation 4 (potato8290)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0\n0.03934105\n0.015614207\n0.9826111274373339"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-5-cells9177",
    "href": "training/training_with_orientation.html#orientation-5-cells9177",
    "title": "Training with orientation",
    "section": "Orientation 5 (cells9177)",
    "text": "Orientation 5 (cells9177)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0039029366\n0.038392987\n0.016203437\n0.9814846496222708"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-6-hyphen1065",
    "href": "training/training_with_orientation.html#orientation-6-hyphen1065",
    "title": "Training with orientation",
    "section": "Orientation 6 (hyphen1065)",
    "text": "Orientation 6 (hyphen1065)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0035548492\n0.040151883\n0.016490512\n0.9840868974543233"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-7-playground6730",
    "href": "training/training_with_orientation.html#orientation-7-playground6730",
    "title": "Training with orientation",
    "section": "Orientation 7 (playground6730)",
    "text": "Orientation 7 (playground6730)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n1.8626451e-09\n0.035927635\n0.015298066\n0.9790607376113669"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-8-blue9392",
    "href": "training/training_with_orientation.html#orientation-8-blue9392",
    "title": "Training with orientation",
    "section": "Orientation 8 (blue9392)",
    "text": "Orientation 8 (blue9392)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0051142187\n0.058112416\n0.020683449\n0.9778491438550463"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-9-alkaline7391",
    "href": "training/training_with_orientation.html#orientation-9-alkaline7391",
    "title": "Training with orientation",
    "section": "Orientation 9 (alkaline7391)",
    "text": "Orientation 9 (alkaline7391)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.8\n0.00026018728\n0.040215496\n0.01770708\n0.9793763771740149"
  },
  {
    "objectID": "training/training_with_orientation.html#orientation-10-cold6626",
    "href": "training/training_with_orientation.html#orientation-10-cold6626",
    "title": "Training with orientation",
    "section": "Orientation 10 (cold6626)",
    "text": "Orientation 10 (cold6626)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.00089638744\n0.050202396\n0.020576788\n0.9768299044891678"
  },
  {
    "objectID": "training/visualize_with_thresholding.html",
    "href": "training/visualize_with_thresholding.html",
    "title": "Visualizing CNN layers with thresholding",
    "section": "",
    "text": "Code\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nos.chdir(\"/project/persistent-exclusion-process\")\n\nimport h5py\nimport numpy as np\n\nimport tensorflow as tf\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\nfrom numpy import expand_dims\n\nfrom src.utils import get_cluster_labels, get_ds_iters\nfrom src.training_utils import (\n    data_load,\n    split_dataset,\n)\nfrom src.plot_utils import get_plot_configs\n\n\n2024-03-22 17:48:08.188968: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-03-22 17:48:08.743283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\n\n\nCode\nhf = h5py.File(f\"no_roll_data/dataset_tumble_0.016_0.25.h5\", \"r\")\niters = get_ds_iters(hf.keys())\nimg = hf[f\"conf_{iters[300]}\"]\nimg = np.array(img)\nimg[img &gt; 0 ] = 1\nimg = img.reshape((img.shape[0], img.shape[1], 1))\n\nhf = h5py.File(f\"no_roll_data/dataset_tumble_0.500_0.25.h5\", \"r\")\niters = get_ds_iters(hf.keys())\nimg2 = hf[f\"conf_{iters[300]}\"]\nimg2 = np.array(img2)\nimg2[img2 &gt; 0 ] = 1\nimg2 = img2.reshape((img2.shape[0], img2.shape[1], 1))\n\n\n\n\nCode\nplt.matshow(img, cmap='gray')\nplt.matshow(img2, cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel = tf.keras.models.load_model('models/green9392.keras')\n\n\n2024-03-22 17:48:14.380316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:48:14.395317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:48:14.395574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:48:14.396352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:48:14.396550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:48:14.396718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:48:14.507285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:48:14.507447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:48:14.507577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n2024-03-22 17:48:14.507686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4366 MB memory:  -&gt; device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:07:00.0, compute capability: 7.5\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[0].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 3\nshift = None\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n2024-03-22 17:48:25.166494: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[1].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 3\nshift = 64\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[2].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 3\nshift = 64\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[4].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 4\nshift = 64\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[5].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 4\nshift = 32\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[6].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 4\nshift = 32\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[8].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 6\nshift = 32\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[9].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 6\nshift = 16\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[10].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\ni = 2\nj = 6\nshift = 16\nfor idx in range(i):\n    for jdx in range(j):\n        ax = plt.subplot(i, j, idx*j+jdx+1)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if idx == 0:\n            plt.imshow(feature_maps1[:shift, :, 0, jdx], cmap='gray')\n        else:\n            plt.imshow(feature_maps2[:shift, :, 0, jdx], cmap='gray')\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[12].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\n\nfeature_maps2 = model_mini.predict(img2, verbose=0)\n\nplt.matshow(np.rot90(feature_maps1[:, :]))\nplt.matshow(np.rot90(feature_maps2[:, :]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[14].output)\n\nfeature_maps1 = model_mini.predict(img, verbose=0)\nfeature_maps2 = model_mini.predict(img2, verbose=0)\n\nplt.matshow(feature_maps1[:, :])\nplt.matshow(feature_maps2[:, :])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[16].output)\n\nfeature_maps1 = model_mini.predict(x1[0], verbose=0)\nfeature_maps2 = model_mini.predict(x2[0], verbose=0)\n\nplt.matshow(np.rot90(feature_maps1[:, :]))\nplt.matshow(np.rot90(feature_maps2[:, :]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_mini = Model(inputs=model.inputs, outputs=model.layers[18].output)\n\nfeature_maps1 = model_mini.predict(x1[0], verbose=0)\nfeature_maps2 = model_mini.predict(x2[0], verbose=0)\n\nplt.matshow(np.rot90(feature_maps1[:, :]))\nplt.matshow(np.rot90(feature_maps2[:, :]))"
  },
  {
    "objectID": "training/landing.html",
    "href": "training/landing.html",
    "title": "CNN",
    "section": "",
    "text": "Prediction vs actual\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nTraining MSE\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nTraining summary\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nTraining summary (high density)\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nTraining with monochrome\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nTraining with monochrome (high density)\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nTraining with orientation\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nTraining with orientation (high density)\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nTraining without orientation\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nTraining without orientation (high density)\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing CNN layers with orientation\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing CNN layers with orientation\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing CNN layers with orientation\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing CNN layers with thresholding\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing CNN layers without orientation\n\n\n\n\n\n\n\n\n\n\n\nNP\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "training/training_summary.html",
    "href": "training/training_summary.html",
    "title": "Training summary",
    "section": "",
    "text": "Code\n%load_ext autoreload\n%autoreload 2\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport os\n\nos.chdir(\"/project/persistent-exclusion-process/\")\n\nimport gc\n\nimport numpy as np\nimport h5py\nimport glob\nimport re\nimport tensorflow as tf\nfrom cmcrameri import cm\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom matplotlib.patches import Patch\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.ticker as ticker\n\nfrom src.training_utils import (\n    extract_floats,\n    data_load,\n    split_dataset,\n    predict_multi_by_name,\n    predict_and_plot,\n    plot_violin_and_statistics\n)\nfrom src.models import make_net\nfrom src.plot_utils import get_plot_configs\n\nnp.set_printoptions(precision=3, suppress=True)\ngpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device, True)\nprint(gpu_devices)"
  },
  {
    "objectID": "training/training_summary.html#self-prediction",
    "href": "training/training_summary.html#self-prediction",
    "title": "Training summary",
    "section": "Self-prediction",
    "text": "Self-prediction\n\n\nCode\ntumbles = np.logspace(-6, -1, 10, base=2) # here are all the alphas available\n\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=True, series=\"validation_data\")\n_, _, x_val, y_val = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_with_orientation = [\n    \"helicopter1822\",\n    \"wardrobe9539\",\n    \"looper2409\",\n    \"potato8290\",\n    \"cells9177\",\n    \"hyphen1065\",\n    \"playground6730\",\n    \"blue9392\",\n    \"alkaline7391\",\n    \"cold6626\"\n]\n\npredictions_with_orientation, actual_with_orientation = predict_multi_by_name(model_names_with_orientation, x_val, y_val)\ndel x_val\ndel y_val\ngc.collect()\n\n\n\n\nCode\ngc.collect()\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=False, scrambled=True,  series=\"validation_data\")\n_, _, x_val2, y_val2 = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_without_orientation = [\n    \"ice1822\",\n    \"house9539\",\n    \"cake2409\",\n    \"carrot8290\",\n    \"virus9177\",\n    \"comma1065\",\n    \"toys6730\",\n    \"red9392\",\n    \"acid7391\",\n    \"hot6626\",\n]\n\npredictions_without_orientation, actual_without_orientation = predict_multi_by_name(model_names_without_orientation, x_val2, y_val2)\ndel x_val2\ndel y_val2\ngc.collect()\n\n\n\n\nCode\ngc.collect()\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=False, scrambled=False,  series=\"validation_data\")\n_, _, x_val2, y_val2 = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_with_monochrome = [\n    \"boat1822\",\n    \"door9539\",\n    \"muffin2409\",\n    \"yam8290\",\n    \"bacteria9177\",\n    \"slash1065\",\n    \"pool6730\",\n    \"green9392\",\n    \"neutral7391\",\n    \"lukewarm6626\",\n]\n\npredictions_with_monochrome, actual_with_monochrome = predict_multi_by_name(model_names_with_monochrome, x_val2, y_val2)\ndel x_val2\ndel y_val2\ngc.collect()\n\n\n\n\nCode\ndf = pd.DataFrame(\n    {\n        \"Predicted\": np.concatenate(\n            (\n                predictions_with_orientation,\n                predictions_without_orientation,\n                predictions_with_monochrome,\n            )\n        ),\n        \"Actual\": np.concatenate((actual_with_orientation, actual_without_orientation, actual_with_monochrome)),\n        \"Context\": pd.Categorical(\n            [\"Trained with orientation\"] * len(actual_with_orientation)\n            + [\"Trained without orientation\"] * len(actual_without_orientation)\n            + [\"Trained with thresholding\"] * len(actual_with_monochrome),\n            categories=[\"Trained with orientation\", \"Trained without orientation\", \"Trained with thresholding\"],\n        ),\n    }\n)\n\ndf2 = pd.DataFrame(\n    {\n        \"STD\": np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .std()[\"Predicted\"],\n                df.query('Context == \"Trained without orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .std()[\"Predicted\"],\n                df.query('Context == \"Trained with thresholding\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .std()[\"Predicted\"],\n            )\n        ),\n        \"Mean\": np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .mean()[\"Predicted\"],\n                df.query('Context == \"Trained without orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .mean()[\"Predicted\"],\n                df.query('Context == \"Trained with thresholding\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .mean()[\"Predicted\"],\n            )\n        ),\n        \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 3),\n        \"Context\": pd.Categorical(\n            [\"Trained with orientation\"] * 10 + [\"Trained without orientation\"] * 10 + [\"Trained with thresholding\"] * 10,\n            categories=[\"Trained with orientation\", \"Trained without orientation\", \"Trained with thresholding\"],\n        ),\n    }\n)\n\n\n\n\nCode\ndf.to_csv(\"cache/model_summary.csv\")\ndf2.to_csv(\"cache/model_summary_std.csv\")\n\n\n\n\nCode\ndel predictions_without_orientation\ndel actual_without_orientation\ndel predictions_with_orientation\ndel actual_with_orientation\ndel predictions_with_monochrome\ndel actual_with_monochrome\ndel df\ndel df2\ngc.collect()"
  },
  {
    "objectID": "training/training_summary.html#cross-predictions",
    "href": "training/training_summary.html#cross-predictions",
    "title": "Training summary",
    "section": "Cross predictions",
    "text": "Cross predictions\n\nMonochrome on orientation\n\n\nCode\ntumbles = np.logspace(-6, -1, 10, base=2) # here are all the alphas available\n\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=False, scrambled=False, series=\"validation_data\")\n_, _, x_val, y_val = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_with_orientation = [\n    \"helicopter1822\",\n    \"wardrobe9539\",\n    \"looper2409\",\n    \"potato8290\",\n    \"cells9177\",\n    \"hyphen1065\",\n    \"playground6730\",\n    \"blue9392\",\n    \"alkaline7391\",\n    \"cold6626\"\n]\n\npredictions_with_orientation, actual_with_orientation = predict_multi_by_name(model_names_with_orientation, x_val, y_val)\ndel x_val\ndel y_val\ngc.collect()\n\n\n\n\nCode\ngc.collect()\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=True, series=\"validation_data\")\n_, _, x_val2, y_val2 = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_without_orientation = [\n    \"boat1822\",\n    \"door9539\",\n    \"muffin2409\",\n    \"yam8290\",\n    \"bacteria9177\",\n    \"slash1065\",\n    \"pool6730\",\n    \"green9392\",\n    \"neutral7391\",\n    \"lukewarm6626\",\n]\n\npredictions_without_orientation, actual_without_orientation = predict_multi_by_name(model_names_without_orientation, x_val2, y_val2)\ndel x_val2\ndel y_val2\ngc.collect()\n\n\n\n\nCode\ndf = pd.DataFrame({\"Predicted\": np.concatenate((predictions_with_orientation, predictions_without_orientation)),\n                   \"Actual\": np.concatenate((actual_with_orientation,actual_without_orientation)),\n                   \"Context\": pd.Categorical([\"Trained with orientation\"]*len(actual_with_orientation)+[\"Trained with thresholding\"]*len(actual_without_orientation),\n                                             categories=[\"Trained with orientation\", \"Trained with thresholding\"])\n                  })\ndf2 = pd.DataFrame({\"STD\": np.concatenate((df.query('Context == \"Trained with orientation\"').groupby(\"Actual\", as_index=False)[\"Predicted\"].std()['Predicted'],\n                                           df.query('Context == \"Trained with thresholding\"').groupby(\"Actual\", as_index=False)[\"Predicted\"].std()['Predicted'])),\n                    \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 2),\n                    \"Context\": pd.Categorical([\"Trained with orientation\"]*10+[\"Trained with thresholding\"]*10,\n                                             categories=[\"Trained with orientation\", \"Trained with thresholding\"])\n                   })\n\n\n\n\nCode\ndf.to_csv(\"cache/model_summary_cross_2.csv\")\ndf2.to_csv(\"cache/model_summary_std_cross_2.csv\")\n\n\n\n\nScrambled on orientation\n\n\nCode\ntumbles = np.logspace(-6, -1, 10, base=2) # here are all the alphas available\n\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=False, scrambled=True, series=\"validation_data\")\n_, _, x_val, y_val = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_with_orientation = [\n    \"helicopter1822\",\n    \"wardrobe9539\",\n    \"looper2409\",\n    \"potato8290\",\n    \"cells9177\",\n    \"hyphen1065\",\n    \"playground6730\",\n    \"blue9392\",\n    \"alkaline7391\",\n    \"cold6626\"\n]\n\npredictions_with_orientation, actual_with_orientation = predict_multi_by_name(model_names_with_orientation, x_val, y_val)\ndel x_val\ndel y_val\ngc.collect()\n\n\n\n\nCode\ngc.collect()\nx,y,_ = data_load(alphas=tumbles, densities=[0.25], orientation=True, series=\"validation_data\")\n_, _, x_val2, y_val2 = split_dataset(x,y,last=int(len(x)*0.2))\ndel x\ndel y\ngc.collect()\nmodel_names_without_orientation = [\n    \"ice1822\",\n    \"house9539\",\n    \"cake2409\",\n    \"carrot8290\",\n    \"virus9177\",\n    \"comma1065\",\n    \"toys6730\",\n    \"red9392\",\n    \"acid7391\",\n    \"hot6626\",\n]\n\npredictions_without_orientation, actual_without_orientation = predict_multi_by_name(model_names_without_orientation, x_val2, y_val2)\ndel x_val2\ndel y_val2\ngc.collect()\n\n\n\n\nCode\ndf = pd.DataFrame({\"Predicted\": np.concatenate((predictions_with_orientation, predictions_without_orientation)),\n                   \"Actual\": np.concatenate((actual_with_orientation,actual_without_orientation)),\n                   \"Context\": pd.Categorical([\"Trained with orientation\"]*len(actual_with_orientation)+[\"Trained without orientation\"]*len(actual_without_orientation),\n                                             categories=[\"Trained with orientation\", \"Trained without orientation\"])\n                  })\ndf2 = pd.DataFrame({\"STD\": np.concatenate((df.query('Context == \"Trained with orientation\"').groupby(\"Actual\", as_index=False)[\"Predicted\"].std()['Predicted'],\n                                           df.query('Context == \"Trained without orientation\"').groupby(\"Actual\", as_index=False)[\"Predicted\"].std()['Predicted'])),\n                    \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 2),\n                    \"Context\": pd.Categorical([\"Trained with orientation\"]*10+[\"Trained without orientation\"]*10,\n                                             categories=[\"Trained with orientation\", \"Trained without orientation\"])\n                   })\n\n\n\n\nCode\ndf.to_csv(\"cache/model_summary_cross.csv\")\ndf2.to_csv(\"cache/model_summary_std_cross.csv\")\n\n\n\n\nCode\ndel predictions_without_orientation\ndel actual_without_orientation\ndel predictions_with_orientation\ndel actual_with_orientation\ndel df\ndel df2\ngc.collect()"
  },
  {
    "objectID": "training/training_summary.html#plotting-cross-predictions",
    "href": "training/training_summary.html#plotting-cross-predictions",
    "title": "Training summary",
    "section": "Plotting cross predictions",
    "text": "Plotting cross predictions\n\n\nCode\nfrom scipy.stats import iqr\n# | code-fold: true\ntumbles = np.logspace(-6, -1, 10, base=2) # here are all the alphas available\n\n\n\n\nCode\nimport matplotlib.cm as mcm\n\ndf = pd.read_csv(\"cache/model_summary_cross.csv\")\n\ndf2 = pd.DataFrame(\n    {\n        \"IQR\": np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .agg(iqr)[\"Predicted\"],\n                df.query('Context == \"Trained without orientation\"')\n                .groupby('Actual', as_index=False)['Predicted']\n                .agg(iqr)[\"Predicted\"],\n            )\n        ),\n        \"MedRes\": np.abs(np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .median()[\"Predicted\"] - tumbles,\n                df.query('Context == \"Trained without orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .median()[\"Predicted\"] - tumbles,\n        ))),\n        \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 2),\n        \"Context\": [\"Trained with orientation\"] * 10 + [\"Trained without orientation\"] * 10,\n    }\n)\n\nplot_configs = get_plot_configs()\nsns.set(rc=plot_configs)\nsns.set_style(\"ticks\")\nsns.set_style({\"xtick.direction\": \"in\", \"ytick.direction\": \"in\"})\n\n\nplt.rcParams.update(plot_configs)\n\nfig, (ax1, ax2) = plt.subplots(\n    1, 2, figsize=(10,5), constrained_layout=True, sharey=True\n)\n\nax1.axhline(0, c='.9', zorder=0, ls='--')\n\npalette ={\"Trained with orientation\": mcm.gnuplot2(30), \"Trained without orientation\":  mcm.gnuplot2(90), \"Trained with thresholding\": mcm.gnuplot(120)}\n\nsns.boxplot(\n    ax=ax1,\n    data=df,\n    x=\"Actual\",\n    y=\"Predicted\",\n    hue=\"Context\",\n    palette=palette,\n    native_scale=True,\n    dodge=True,\n    width=.85,\n    whis=2.5,\n    linecolor=(0,0,0,0),\n    showfliers = False,\n    log_scale=(True,False),\n    fill=True,\n)\nfor patch in ax1.patches:\n    r, g, b, a = patch.get_facecolor()\n    patch.set_facecolor((r, g, b, .5))\nsns.boxplot(\n    ax=ax1,\n    data=df,\n    x=\"Actual\",\n    y=\"Predicted\",\n    hue=\"Context\",\n    palette=palette,\n    native_scale=True,\n    dodge=True,\n    whis=2.5,\n    width=.85,\n    flierprops = dict(markersize = 2, alpha=0.2),\n    log_scale=(True,False),\n    fill=False,\n    legend=False,\n)\nsns.despine()\n\npalette2 ={\"None\": mcm.gnuplot2(30), \"Random DOF\": mcm.gnuplot2(90)}\nhandles = [\n    Patch(\n        edgecolor=color,\n        facecolor=(color[0], color[1], color[2], 0.7),\n        label=label,\n        linewidth=1.5\n    ) \n    for label, color in palette2.items()\n]\n\nax1.legend(handles=handles, frameon=False, loc='lower right', \n           fontsize=16, title=\"Model data filter\", title_fontsize=16);\n\nax1.set_xlim((0.012,0.64))\nax1.set_xscale(\"log\")\nax1.get_xaxis().set_major_formatter(ticker.ScalarFormatter())\nax1.set_xticks(np.round(np.unique(tumbles)[1::2],3))\n\ntumbles2 = np.logspace(-7, 0, 12, base=2)\n\nax1.plot(tumbles2,tumbles2, c='.9', zorder=0)\nax1.set_xlabel(r\"Target tumbling rate, $y$\")\nax1.set_yscale('log')\nax1.set_ylabel(r\"Predicted tumbling rate, $\\hat{y}_i$\")\n#ax1.text(s=r\"$\\phi = 0.25$\", x=0.016, y=.95, fontsize='large')\n\n#----\n\ndf = pd.read_csv(\"cache/model_summary_cross_2.csv\")\n\ndf2 = pd.DataFrame(\n    {\n        \"IQR\": np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .agg(iqr)[\"Predicted\"],\n                df.query('Context == \"Trained with thresholding\"')\n                .groupby('Actual', as_index=False)['Predicted']\n                .agg(iqr)[\"Predicted\"],\n            )\n        ),\n        \"MedRes\": np.abs(np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .median()[\"Predicted\"] - tumbles,\n                df.query('Context == \"Trained with thresholding\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .median()[\"Predicted\"] - tumbles,\n        ))),\n        \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 2),\n        \"Context\": [\"Trained with orientation\"] * 10 + [\"Trained without orientation\"] * 10,\n    }\n)\n\nax2.axhline(0, c='.9', zorder=0, ls='--')\n\npalette ={\"Trained with orientation\": mcm.gnuplot2(30), \"Trained without orientation\":  mcm.gnuplot2(90), \"Trained with thresholding\": mcm.gnuplot(120)}\n\nsns.boxplot(\n    ax=ax2,\n    data=df,\n    x=\"Actual\",\n    y=\"Predicted\",\n    hue=\"Context\",\n    palette=palette,\n    native_scale=True,\n    dodge=True,\n    width=.85,\n    whis=2.5,\n    linecolor=(0,0,0,0),\n    showfliers = False,\n    log_scale=(True,False),\n    fill=True,\n)\nfor patch in ax2.patches:\n    r, g, b, a = patch.get_facecolor()\n    patch.set_facecolor((r, g, b, .5))\nsns.boxplot(\n    ax=ax2,\n    data=df,\n    x=\"Actual\",\n    y=\"Predicted\",\n    hue=\"Context\",\n    palette=palette,\n    native_scale=True,\n    dodge=True,\n    whis=2.5,\n    width=.85,\n    flierprops = dict(markersize = 2, alpha=0.2),\n    log_scale=(True,False),\n    fill=False,\n    legend=False,\n)\nsns.despine()\n\npalette2 ={\"None\": mcm.gnuplot2(30), \"Threshold\": mcm.gnuplot(120)}\nhandles = [\n    Patch(\n        edgecolor=color,\n        facecolor=(color[0], color[1], color[2], 0.7),\n        label=label,\n        linewidth=1.5\n    ) \n    for label, color in palette2.items()\n]\n\nax2.legend(handles=handles, loc='lower right', fontsize=16, title=\"Model data filter\", title_fontsize=16);\n\nax2.set_xlim((0.012,0.64))\nax2.set_xlabel(r\"Target tumbling rate, $y$\")\nax2.set_xscale(\"log\")\nax2.get_xaxis().set_major_formatter(ticker.ScalarFormatter())\nax2.set_xticks(np.round(np.unique(tumbles)[1::2],3))\n\ntumbles2 = np.logspace(-7, 0, 12, base=2)\n\nax2.plot(tumbles2,tumbles2, c='.9', zorder=0)\n\nax2.set_yscale('log')\nax2.set_ylabel(r\"Predicted tumbling rate, $\\hat{y}_i$\")\nax1.text(s=\"(A)\", x=0.05, y=0.95, transform=ax1.transAxes)\nax2.text(s=\"(B)\", x=0.05, y=0.95, transform=ax2.transAxes)\n#ax2.text(s=r\"$\\phi = 0.25$\", x=0.016, y=.95, fontsize='large')\n\n\nText(0.05, 0.95, '(B)')\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf = pd.read_csv(\"cache/model_summary.csv\")\ndf3 = pd.DataFrame(\n    {\n        \"IQR\": np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .agg(iqr)[\"Predicted\"],\n                df.query('Context == \"Trained without orientation\"')\n                .groupby('Actual', as_index=False)['Predicted']\n                .agg(iqr)[\"Predicted\"],\n                df.query('Context == \"Trained with thresholding\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .agg(iqr)[\"Predicted\"],\n            )\n        ),\n        \"MedRes\": np.abs(np.concatenate(\n            (\n                df.query('Context == \"Trained with orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .median()[\"Predicted\"] - tumbles,\n                df.query('Context == \"Trained without orientation\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .median()[\"Predicted\"] - tumbles,\n                df.query('Context == \"Trained with thresholding\"')\n                .groupby(\"Actual\", as_index=False)[\"Predicted\"]\n                .median()[\"Predicted\"] - tumbles,\n            )\n        )),\n        \"Actual\": np.tile(np.logspace(-6, -1, 10, base=2), 3),\n        \"Context\": [\"Trained with orientation\"] * 10 + [\"Trained without orientation\"] * 10 + [\"Trained with thresholding\"] * 10,\n    }\n)\n\n\n\n\nCode\no_on_no = np.array(df2[df2[\"Context\"] == \"Trained with orientation\"][\"IQR\"])\no_on_o = np.array(df3[df3[\"Context\"] == \"Trained with orientation\"][\"IQR\"])\nprint((o_on_no))\nprint((o_on_o))\nprint(\n    np.max((o_on_no - o_on_o)/o_on_o),\n    np.mean((o_on_no - o_on_o)/o_on_o),\n    np.std((o_on_no - o_on_o)/o_on_o),\n    np.min((o_on_no - o_on_o)/o_on_o)\n)\n\n\n[0.069 0.148 0.279 0.455 0.635 0.788 0.865 0.897 0.897 0.882]\n[0.004 0.007 0.016 0.011 0.013 0.015 0.031 0.059 0.07  0.073]\n50.98521061810109 25.470724982249404 14.189871810630494 11.005069243662067\n\n\n\n\nCode\nno_on_o = np.array(df2[df2[\"Context\"] == \"Trained without orientation\"][\"IQR\"])\nno_on_no = np.array(df3[df3[\"Context\"] == \"Trained without orientation\"][\"IQR\"])\nprint((no_on_o))\nprint((no_on_no))\nprint(\n    np.max((no_on_o - no_on_no)/no_on_no),\n    np.mean((no_on_o - no_on_no)/no_on_no),\n    np.std((no_on_o - no_on_no)/no_on_no),\n    np.min((no_on_o - no_on_no)/no_on_no)\n)\n\n\n[0.17  0.184 0.165 0.154 0.165 0.21  0.296 0.387 0.455 0.479]\n[0.003 0.006 0.016 0.011 0.01  0.014 0.027 0.056 0.066 0.072]\n51.279031786113904 15.960653331321359 13.44323225487701 5.674001343189423\n\n\n\n\nCode\nfig.savefig(\"plots/cnn_summary_cross_0.25.pdf\")"
  },
  {
    "objectID": "training/training_summary.html#old-plot-experimentation",
    "href": "training/training_summary.html#old-plot-experimentation",
    "title": "Training summary",
    "section": "Old plot (experimentation)",
    "text": "Old plot (experimentation)\n\n\nCode\nplot_configs = get_plot_configs()\nsns.set(rc=plot_configs)\nsns.set_style(\"ticks\")\nsns.set_style({\"xtick.direction\": \"in\", \"ytick.direction\": \"in\"})\n\n\nplt.rcParams.update(plot_configs)\n\n\nfig, axes = plt.subplots(\n    3, 1, figsize=(4.25, 7), constrained_layout=True, sharex=True\n)\n(ax1, ax2, ax3) = axes\n\npalette ={\"Trained with orientation\": cm.glasgow(0), \"Trained without orientation\": cm.glasgow(60), \"Trained with thresholding\": cm.glasgow(200)}\n\nsns.boxplot(\n    ax=ax1,\n    data=df,\n    x=\"Actual\",\n    y=\"Predicted\",\n    hue=\"Context\",\n    palette=palette,\n    native_scale=True,\n    dodge=True,\n    whis=(0,100),\n    linecolor=(0,0,0,0),\n    log_scale=(True,False),\n    fill=True,\n    legend=False,\n)\nfor patch in ax1.patches:\n    r, g, b, a = patch.get_facecolor()\n    patch.set_facecolor((r, g, b, .5))\nsns.boxplot(\n    ax=ax1,\n    data=df,\n    x=\"Actual\",\n    y=\"Predicted\",\n    hue=\"Context\",\n    palette=palette,\n    native_scale=True,\n    dodge=True,\n    whis=(0,100),\n    log_scale=(True,False),\n    fill=False,\n    legend=False,\n)\n\nax1.plot(tumbles,tumbles)\n\nax2.axhline(0.015, c='0.9')\nax2.text(s=r\"$\\sigma = 0.15$\", x=0.014, y=0.016)\n\ncontexts = [\"Trained with orientation\", \"Trained without orientation\", \"Trained with thresholding\"]\nfor idx in range(3):\n    context = contexts[idx]\n    a, b = np.polyfit(np.log(df2[df2['Context'] == context]['Actual'][:6]),df2[df2['Context'] == context]['STD'][:6],1)\n    sns.lineplot(\n        ax=ax2,\n        x=df2[df2['Context'] == context]['Actual'][:6],\n        y=np.log(df2[df2['Context'] == context]['Actual'][:6])*a+b,\n        color=palette[context],\n        linestyle='-'\n    )\n    print(a,b)\n\n# ------------\n\ncontexts = [\"Trained with orientation\", \"Trained without orientation\", \"Trained with thresholding\"]\nfor idx in range(3):\n    context = contexts[idx]\n    a, b = np.polyfit(np.log(df2[df2['Context'] == context]['Actual'][6:]),df2[df2['Context'] == context]['STD'][6:],1)\n    sns.lineplot(\n        ax=ax2,\n        x=df2[df2['Context'] == context]['Actual'][6:],\n        y=np.log(df2[df2['Context'] == context]['Actual'][6:])*a+b,\n        color=palette[context],\n        linestyle='dashed'\n    )\n    print(a,b)\n\nsns.scatterplot(\n    ax=ax2,\n    data=df2,\n    x=\"Actual\",\n    y=\"STD\",\n    hue=\"Context\",\n    palette=palette,\n    alpha=.7,\n    marker='o',\n    ec='k',\n    legend=False,\n    zorder=10\n)\n\n\nsns.despine()\n\n\ntumbles = np.logspace(-6, -1, 10, base=2)\n\npalette2 ={\"None\": cm.glasgow(0), \"Random DOF\": cm.glasgow(60), \"Threshold\": cm.glasgow(200)}\nhandles = [\n    Patch(\n        edgecolor=color,\n        facecolor=(color[0], color[1], color[2], 0.5),\n        label=label,\n        linewidth=1.5\n    ) \n    for label, color in palette2.items()\n]\n\nax1.legend(handles=handles, frameon=False, loc='lower right', fontsize=12, title=\"Data processing\");\n\nax1.set_xlim(left=0.012)\n\nfor idx, ax in enumerate(axes.ravel()):\n    ax.set_xlabel(r\"(Actual) Tumbling rate, $\\alpha_a$\")\n    ax.set_xscale(\"log\")\n    ax.get_xaxis().set_major_formatter(ticker.ScalarFormatter())\n    ax.set_xticks(np.round(np.unique(tumbles)[::2],3))\n\ndfs = pd.read_csv(\"cache/cluster_count_size_0.25.csv\")\nsns.lineplot(ax=ax3, data=dfs, x=\"alpha\", y=\"bigsize\", errorbar=\"sd\", marker='o', c='darkred', legend=False)\nax1.set_yscale('log')\nax1.get_yaxis().set_major_formatter(ticker.ScalarFormatter())\nax1.set_yticks(np.round(np.unique(tumbles)[::2],3))\nax1.set_ylabel(r\"Predicted value, $\\alpha_p$\")\nax2.set_ylabel(r\"$\\sigma_{\\alpha_p}$\")\nax3.set_ylabel(r\"$V_{\\bf max}$ $/a^2$\")\n#ax3.set_yticks([10**1,10**2])\nfig.text(s=f\"(A)\", x=0.22, y=.96, fontsize='large')\nfig.text(s=f\"(B)\", x=0.22, y=.65, fontsize='large')\nfig.text(s=f\"(C)\", x=0.22, y=.33, fontsize='large', backgroundcolor=(1,1,1,0.7))\n\n\n0.004503738248810316 0.022652028724380956\n0.0038497000933606362 0.01983377747523809\n0.003522612455057669 0.018080066510476195\n0.020995983952850242 0.06854198798\n0.023085168040463743 0.07011854534\n0.021783351795216864 0.06384775828\n\n\nText(0.22, 0.33, '(C)')"
  },
  {
    "objectID": "training/training_without_orientation.html",
    "href": "training/training_without_orientation.html",
    "title": "Training without orientation",
    "section": "",
    "text": "Full code\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n0"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-1-ice1822",
    "href": "training/training_without_orientation.html#no-orientation-1-ice1822",
    "title": "Training without orientation",
    "section": "No-orientation 1 (ice1822)",
    "text": "No-orientation 1 (ice1822)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.8\n1.8626451e-09\n0.0424393\n0.0175994\n0.9802954780718554"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-2-house9539",
    "href": "training/training_without_orientation.html#no-orientation-2-house9539",
    "title": "Training without orientation",
    "section": "No-orientation 2 (house9539)",
    "text": "No-orientation 2 (house9539)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.004058853\n0.05232892\n0.019909954\n0.9781499804702691"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-3-cake2409",
    "href": "training/training_without_orientation.html#no-orientation-3-cake2409",
    "title": "Training without orientation",
    "section": "No-orientation 3 (cake2409)",
    "text": "No-orientation 3 (cake2409)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.8\n0.0\n0.043112654\n0.016793313\n0.9769899900283121"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-4-carrot8290",
    "href": "training/training_without_orientation.html#no-orientation-4-carrot8290",
    "title": "Training without orientation",
    "section": "No-orientation 4 (carrot8290)",
    "text": "No-orientation 4 (carrot8290)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n1.8626451e-09\n0.041985407\n0.01592515\n0.9794941948246966"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-5-virus9177",
    "href": "training/training_without_orientation.html#no-orientation-5-virus9177",
    "title": "Training without orientation",
    "section": "No-orientation 5 (virus9177)",
    "text": "No-orientation 5 (virus9177)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0036960836\n0.040402703\n0.016952809\n0.9797471674263254"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-6-comma1065",
    "href": "training/training_without_orientation.html#no-orientation-6-comma1065",
    "title": "Training without orientation",
    "section": "No-orientation 6 (comma1065)",
    "text": "No-orientation 6 (comma1065)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0028939936\n0.05089833\n0.019907434\n0.976472418522057"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-7-toys6730",
    "href": "training/training_without_orientation.html#no-orientation-7-toys6730",
    "title": "Training without orientation",
    "section": "No-orientation 7 (toys6730)",
    "text": "No-orientation 7 (toys6730)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n3.7252903e-09\n0.03729547\n0.016041566\n0.977662284587988"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-8-red9392",
    "href": "training/training_without_orientation.html#no-orientation-8-red9392",
    "title": "Training without orientation",
    "section": "No-orientation 8 (red9392)",
    "text": "No-orientation 8 (red9392)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0051062275\n0.05373082\n0.019618535\n0.9790157724220516"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-9-acid7391",
    "href": "training/training_without_orientation.html#no-orientation-9-acid7391",
    "title": "Training without orientation",
    "section": "No-orientation 9 (acid7391)",
    "text": "No-orientation 9 (acid7391)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n1.8626451e-09\n0.034938905\n0.014323948\n0.9827104520383487"
  },
  {
    "objectID": "training/training_without_orientation.html#no-orientation-10-hot6626",
    "href": "training/training_without_orientation.html#no-orientation-10-hot6626",
    "title": "Training without orientation",
    "section": "No-orientation 10 (hot6626)",
    "text": "No-orientation 10 (hot6626)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0018149534\n0.0497454\n0.019964295\n0.9785183278349752"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html",
    "href": "training/training_with_monochrome_hi.html",
    "title": "Training with monochrome (high density)",
    "section": "",
    "text": "Full code\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n0"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-1-hi_boat1822",
    "href": "training/training_with_monochrome_hi.html#monochrome-1-hi_boat1822",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 1 (hi_boat1822)",
    "text": "Monochrome 1 (hi_boat1822)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n1.8626451e-09\n0.031597264\n0.013428005\n0.9909712947885814"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-2-hi_door9539",
    "href": "training/training_with_monochrome_hi.html#monochrome-2-hi_door9539",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 2 (hi_door9539)",
    "text": "Monochrome 2 (hi_door9539)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0038098812\n0.033420183\n0.014755321\n0.9901548494329764"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-3-hi_muffin2409",
    "href": "training/training_with_monochrome_hi.html#monochrome-3-hi_muffin2409",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 3 (hi_muffin2409)",
    "text": "Monochrome 3 (hi_muffin2409)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0\n0.031058198\n0.013728833\n0.989845567758967"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-4-hi_yam8290",
    "href": "training/training_with_monochrome_hi.html#monochrome-4-hi_yam8290",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 4 (hi_yam8290)",
    "text": "Monochrome 4 (hi_yam8290)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0\n0.030259317\n0.01236204\n0.9905684683078677"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-5-hi_bacteria9177",
    "href": "training/training_with_monochrome_hi.html#monochrome-5-hi_bacteria9177",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 5 (hi_bacteria9177)",
    "text": "Monochrome 5 (hi_bacteria9177)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0038293186\n0.028684335\n0.012084039\n0.9924625719410229"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-6-hi_slash1065",
    "href": "training/training_with_monochrome_hi.html#monochrome-6-hi_slash1065",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 6 (hi_slash1065)",
    "text": "Monochrome 6 (hi_slash1065)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.004369769\n0.040989716\n0.015395319\n0.9899976878439395"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-7-hi_pool6730",
    "href": "training/training_with_monochrome_hi.html#monochrome-7-hi_pool6730",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 7 (hi_pool6730)",
    "text": "Monochrome 7 (hi_pool6730)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.8\n0.0\n0.024492702\n0.011296768\n0.9911378894317788"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-8-hi_green9392",
    "href": "training/training_with_monochrome_hi.html#monochrome-8-hi_green9392",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 8 (hi_green9392)",
    "text": "Monochrome 8 (hi_green9392)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.004941088\n0.039405227\n0.014285241\n0.9920701962491243"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-9-hi_neutral7391",
    "href": "training/training_with_monochrome_hi.html#monochrome-9-hi_neutral7391",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 9 (hi_neutral7391)",
    "text": "Monochrome 9 (hi_neutral7391)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n1.0\n0.0055710664\n0.028292915\n0.013002488\n0.9928750060181387"
  },
  {
    "objectID": "training/training_with_monochrome_hi.html#monochrome-10-hi_lukewarm6626",
    "href": "training/training_with_monochrome_hi.html#monochrome-10-hi_lukewarm6626",
    "title": "Training with monochrome (high density)",
    "section": "Monochrome 10 (hi_lukewarm6626)",
    "text": "Monochrome 10 (hi_lukewarm6626)\n\n\nText(0.5, 1.0, 'Training and Validation MAE')\n\n\n\n\n\n\n\n\n\n\n\n0.9\n0.0004156949\n0.0348751\n0.014959496\n0.9902986572402251\n\n\n\n\n\n\n\n\n\n\n\nNumber of unique alpha:  10\nShape of x:  (30000, 128, 128, 1)\nShape of y:  (30000,)\nSize of training data:  24000\nSize of validation data:  6000\n\n\n0\n\n\n\n\n1.0\n0.038567666\n0.1815722\n0.10893637\n0.28910587702764307"
  },
  {
    "objectID": "writing/motivation.html",
    "href": "writing/motivation.html",
    "title": "What is active matter and why do we study it?",
    "section": "",
    "text": "This first part aims to address generalities surrounding the studies of active matter, providing motivations from both practical and theoretical domains."
  },
  {
    "objectID": "writing/motivation.html#introduction",
    "href": "writing/motivation.html#introduction",
    "title": "What is active matter and why do we study it?",
    "section": "Introduction",
    "text": "Introduction\nAn active matter system is characterised by its constituent self-propelling and self-directional units that are individually capable of extracting and dissipating free energy to result in complex, systematic behaviours¬†[1]. The context of which these active systems emerge has been found in disordered systems, soft matter, as well as statistical mechanics, both at and out of equilibrium.\nNumerous examples of active systems can be found in biological systems at all scales, from fish in a school¬†[2] and birds in a flock, to algae, bacteria, proteins¬†[3] and actin and microtubules in subcellular domains¬†[1]. The general properties of active systems are often emergent collective properties that provide intriguing phenomena, from self-motility, synchronous dynamics¬†[3], order-disorder transitions, pattern formation, swarming, and lots more."
  },
  {
    "objectID": "writing/motivation.html#real-world-applications",
    "href": "writing/motivation.html#real-world-applications",
    "title": "What is active matter and why do we study it?",
    "section": "Real-world applications",
    "text": "Real-world applications\nFirst, in practical applications, we might want borrow or mimic strategies from biological systems, with the goal of creating new synthetic materials, devices, robotics and medicine¬†[4]. Here, the use of models is integral to provide insight into how to engineer synthetic systems. For this, the models are performed both in vitro (nanomachines) and in silico (numerical modelling). Although active systems have a parameter space far from minimal, by using appropriate approximations to form our models, even with minimal ones, we can seek to derive large-scale generality¬†[1,5]. These systems have group-level properties derived from macroscopic orders, phases, and phase transitions, that are independent of the scale of its constituents.\nFor instance, a good yet minimal approximation would be a model by Viscek et. al.¬†[6,7]. Here, clustering is induced through a combination of self-propulsion and self-orientation in response to its neighbours. The system evolves with a two-step iteration process, and the whole system is controlled by 3 parameters. Yet, its central prediction shows phase transition from disordered, individual motion to ordered, collective motion, dictated through its minimal set of parameters¬†[6].\nWhile it cannot be assumed that the models used in vitro translate directly to what is observed in reality, they are still crucial components that when combined with more sophisticated rules or understanding from other fields, would enable useful real-world applications, an example being controlling insect pest outbreaks¬†[6]."
  },
  {
    "objectID": "writing/motivation.html#new-physics-at-non-equilibrium",
    "href": "writing/motivation.html#new-physics-at-non-equilibrium",
    "title": "What is active matter and why do we study it?",
    "section": "New physics at non-equilibrium",
    "text": "New physics at non-equilibrium\nFirst, while we can study emergent behaviours, one challenge out of these models is to address the inverse problem; to determine the rules that lead to a desired collective state¬†[8]. In this domain, powerful tools like machine learning can be deployed to build a robust framework analogous to equilibrium statistical thermodynamics, ultimately with the aim of providing fundamental insight into a microscopic-emergent connection¬†[9].\nSecondly, non-equilibrium results when energy exchanges and dissipation at the level of individual particles‚Äô contribution lead to irreversibility within¬†[4,10]. This is contrasted with at-equilibrium systems, where energy effects are found at the system‚Äôs boundaries¬†[1]. Whereas we have the laws of thermodynamics and statistical mechanics in the latter type of systems that tell us about their macrostates (from their energy) and likelihood (from their Boltzmann distribution), it is not clear for the former type of systems. The difficulty lies in constructing analogues to these theories using quantities equivalent to the system‚Äôs free energies. With new theoretical analogues, new ways of understanding this regime.\n\n\n\n\n[1] M. C. Marchetti, J. F. Joanny, S. Ramaswamy, T. B. Liverpool, J. Prost, M. Rao, and R. A. Simha, Hydrodynamics of Soft Active Matter, Reviews of Modern Physics 85, 1143 (2013).\n\n\n[2] Y. Yang, F. Turci, E. Kague, C. L. Hammond, J. Russo, and C. P. Royall, Dominating Lengthscales of Zebrafish Collective Behaviour, PLOS Computational Biology 18, e1009394 (2022).\n\n\n[3] S. Decamp, What Is Active Matter?, Stephen j. Decamp (n.d.).\n\n\n[4] C. Bechinger, R. Di Leonardo, H. L√∂wen, C. Reichhardt, G. Volpe, and G. Volpe, Active Particles in Complex and Crowded Environments, Reviews of Modern Physics 88, 045006 (2016).\n\n\n[5] E. Flenner and G. Szamel, Active Matter: Quantifying the Departure from Equilibrium, Physical Review E 102, 022607 (2020).\n\n\n[6] J. Buhl, D. J. T. Sumpter, I. D. Couzin, J. J. Hale, E. Despland, E. R. Miller, and S. J. Simpson, From Disorder to Order in Marching Locusts, Science 312, 1402 (2006).\n\n\n[7] T. Vicsek, A. Czir√≥k, E. Ben-Jacob, I. Cohen, and O. Shochet, Novel Type of Phase Transition in a System of Self-Driven Particles, 75, 1226 (1995).\n\n\n[8] G. Gompper et al., The 2020 Motile Active Matter Roadmap, Journal of Physics: Condensed Matter 32, 193001 (2020).\n\n\n[9] G. Rassolov, L. Tociu, √â. Fodor, and S. Vaikuntanathan, From Predicting to Learning Dissipation from Pair Correlations of Active Liquids, The Journal of Chemical Physics 157, 054901 (2022).\n\n\n[10] S. Ramaswamy, The Mechanics and Statistics of Active Matter, Annual Review of Condensed Matter Physics 1, 323 (2010)."
  },
  {
    "objectID": "writing/prepatory_work.html",
    "href": "writing/prepatory_work.html",
    "title": "Prepratory work, discussion, and plan for the future",
    "section": "",
    "text": "The last section aims to detail progress made up to now, a discussion on the results from this preparatory work, and from this, plan for how the project will proceed going forward."
  },
  {
    "objectID": "writing/prepatory_work.html#current-progress",
    "href": "writing/prepatory_work.html#current-progress",
    "title": "Prepratory work, discussion, and plan for the future",
    "section": "Current progress",
    "text": "Current progress\nOver the initial 7 weeks of the project, we have worked through the in-house code package¬†[1] (referred to as the PEP code here onwards), annotating and documenting what it does step by step. The code is a Python implementation (with ctypes) of the PEP process (see the PEP section). In short, it is a stochastic, lattice implementation where every particle has 4 degrees of freedom (up, down, left, right). Its robustness is controlled by the lattice size, LL (or density œï\\phi), as well as the tumbling rate Œ±\\alpha. In each iteration, each particle either stays in its run state, or has a chance of undergoing tumbling, where it changes direction (with uniform probability for all 4 degrees of freedom). Each lattice site can have exactly one occupancy, that is, multiple particles cannot be on the same site at once.\nThe PEP code was validated and tested at a range of values for each of Œ±\\alpha and œï\\phi. Specifically, Œ±\\alpha was chosen to be within the range 2n,n‚àà[‚àí6..‚àí1]2^{n},\\, n\n\\in [-6 \\mathrel{{.}\\,{.}} -1], and œï\\phi was chosen to be within the range 0.05m,m‚àà[1..10]0.05 m,\\, m \\in [1 \\mathrel{{.}\\,{.}} 10]. A grid of various pairs of (Œ±,œï)(\\alpha,\n\\phi) is plotted below in Fig. XYZ. For all datasets, snapshots are saved, spaced proportional to the activity (which is proportional to Œ±\\alpha), so for low values of Œ±\\alpha, the system underwent more iterations. This is so that ‚Äústeady-state‚Äù regimes in lower Œ±\\alpha can be observed, as it is expected that systems with lower activity will take longer to reach some sort of ‚Äústeady-state‚Äù.\nSome measurements were taken, these would be (1) mean system orientation (Fig. XYZ) (characterised as the average over NN iterations), (2) the cluster size distributions at different (Œ±,œï)(\\alpha, \\phi) (Fig. XYZ), and (3), the number of cluster (Fig. XYZ).\n\n\n\n\n[1] Persistent Exclusion Process, (2023)."
  },
  {
    "objectID": "literature_notes/motile-active-matter-intro.html",
    "href": "literature_notes/motile-active-matter-intro.html",
    "title": "2020 Motile Active Matter Introduction",
    "section": "",
    "text": "Theories of active matter have to be constructed on the basis of symmetries, conservation laws, and dynamic rules.\nMethods involved simulations, field-theoretical methods, dynamic density-functional theory."
  },
  {
    "objectID": "literature_notes/motile-active-matter-intro.html#general-principles-and-methods",
    "href": "literature_notes/motile-active-matter-intro.html#general-principles-and-methods",
    "title": "2020 Motile Active Matter Introduction",
    "section": "",
    "text": "Theories of active matter have to be constructed on the basis of symmetries, conservation laws, and dynamic rules.\nMethods involved simulations, field-theoretical methods, dynamic density-functional theory."
  },
  {
    "objectID": "literature_notes/motile-active-matter-intro.html#micronano-swimmers",
    "href": "literature_notes/motile-active-matter-intro.html#micronano-swimmers",
    "title": "2020 Motile Active Matter Introduction",
    "section": "Micro/nano swimmers",
    "text": "Micro/nano swimmers\nBiological swimmers can employ cilia or flagella or changes in body shape to propel to towards a target.\nAdditionally, another point of interest would be search strategies: like chemotaxis (orientation/movement away or from stimulus, along a chemical concentration gradien) and photoaxis (orientation/movement away or from light).\n\nHow small a swimmer can be to still display directed motion?"
  },
  {
    "objectID": "literature_notes/motile-active-matter-intro.html#synthetic-micronano-machines",
    "href": "literature_notes/motile-active-matter-intro.html#synthetic-micronano-machines",
    "title": "2020 Motile Active Matter Introduction",
    "section": "Synthetic micro/nano machines",
    "text": "Synthetic micro/nano machines\nVarious strategies for autonomous machines\nDiffusiophoresis - motion of species A in response to the concentration gradient of species B (both in a colloid)\nThermophoresis - motion in mixture of particles along temperature gradient.\nAn important model to study collective motion far from equilibrium: a mixtrue of semiflexible polar filaments and motor proteins.\nActive nematic theory (??) is fruitful in modelling many observed phenomena."
  },
  {
    "objectID": "literature_notes/motile-active-matter-intro.html#swarming",
    "href": "literature_notes/motile-active-matter-intro.html#swarming",
    "title": "2020 Motile Active Matter Introduction",
    "section": "Swarming",
    "text": "Swarming\nInterests in observing reaction of swarms to external signals.\n\nReaction of bird flocks to predators\nAlgae in gravitational field\n\nInterests in light control of synthetic systems"
  },
  {
    "objectID": "literature_notes/landing.html",
    "href": "literature_notes/landing.html",
    "title": "Literature notes",
    "section": "",
    "text": "Run-and-tumble dynamics in a crowded environment: PEP for swimmers\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2023\n\n\nSoto, Golestanian\n\n\n\n\n\n\n\n\n\n\n\n\nActive Brownian particles: from collective phenomona to fundamental physics\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2023\n\n\nGompper, Winkler\n\n\n\n\n\n\n\n\n\n\n\n\n2020 Motile Active Matter Introduction\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2023\n\n\nGompper, Winkler\n\n\n\n\n\n\nNo matching items"
  }
]